{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adaptative-guide-net.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"eUKnB3_Kf2nw","colab_type":"text"},"cell_type":"markdown","source":["## Adaptative Guide-net"]},{"metadata":{"id":"g4kw7gLefk1I","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z49ZaCkofk1U","colab_type":"code","outputId":"c65a3a45-edc4-46a3-d15d-d1cad7f85c15","executionInfo":{"status":"ok","timestamp":1544218087993,"user_tz":120,"elapsed":5306,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n"],"name":"stdout"}]},{"metadata":{"id":"Q9i0kVvPfk1i","colab_type":"text"},"cell_type":"markdown","source":["## Loading the data"]},{"metadata":{"id":"eKoyWRCOfk1l","colab_type":"code","outputId":"04bda6ea-285b-4474-afda-11dcf0fa4b15","executionInfo":{"status":"ok","timestamp":1544237447987,"user_tz":120,"elapsed":1775,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["from time import time\n","import os\n","import gzip\n","import numpy as np\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import cifar100"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"r295GDqKfk10","colab_type":"code","colab":{}},"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n","                                                  test_size=0.1, \n","                                                  random_state=1974,\n","                                                  stratify = y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fu3pH4M4fk15","colab_type":"code","colab":{}},"cell_type":"code","source":["train_features = X_train.reshape(X_train.shape[0], 32, 32, 3)/255\n","vali_features = X_val.reshape(X_val.shape[0], 32, 32, 3)/255\n","test_features = X_test.reshape(X_test.shape[0], 32, 32, 3)/255\n","\n","y_train_cat = np_utils.to_categorical(y_train)\n","y_val_cat = np_utils.to_categorical(y_val)\n","y_test_cat = np_utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3ED5tc9Cfk2H","colab_type":"text"},"cell_type":"markdown","source":["## Defining coarse labels"]},{"metadata":{"id":"uIT8HRXGfk2L","colab_type":"code","colab":{}},"cell_type":"code","source":["dict_coarse2 = {0: 4,  1: 1,  2: 14,  3: 8,  4: 12,  5: 6,  6: 7,  7: 7,  8: 18,  9: 3,  10: 3,\n","                11: 14,  12: 9,  13: 18,  14: 7,  15: 11,  16: 3,  17: 9,  18: 7,  19: 11,  20: 6,\n","                21: 11,  22: 5,  23: 10,  24: 7,  25: 6,  26: 13,  27: 15,  28: 3,  29: 15,  30: 0,\n","                31: 11,  32: 1,  33: 10,  34: 12,  35: 14,  36: 16,  37: 9,  38: 11,  39: 5,  40: 5,\n","                41: 18,  42: 8,  43: 8,  44: 15,  45: 13,  46: 14,  47: 17,  48: 18,  49: 10,  50: 16,\n","                51: 4,  52: 17,  53: 4,  54: 2,  55: 12,  56: 17,  57: 4,  58: 18,  59: 17,  60: 10,\n","                61: 3,  62: 2,  63: 12,  64: 12,  65: 16,  66: 12,  67: 1,  68: 9,  69: 18,  70: 2,\n","                71: 10,  72: 12,  73: 1,  74: 16,  75: 12,  76: 9,  77: 13,  78: 15,  79: 13,  80: 16,\n","                81: 18,  82: 2,  83: 4,  84: 6,  85: 18,  86: 5,  87: 5,  88: 8,  89: 18,  90: 18,\n","                91: 1,  92: 2,  93: 15,  94: 6,  95: 0,  96: 17,  97: 8,  98: 14,  99: 13}\n","\n","\n","dict_coarse1 = {0: 0,\n","              1: 0,\n","              2: 1,\n","              3: 2,\n","              4: 1,\n","              5: 2,\n","              6: 2,\n","              7: 3,\n","              8: 4,\n","              9: 5,\n","              10: 5,\n","              11: 4,\n","              12: 4,\n","              13: 3,\n","              14: 6,\n","              15: 7,\n","              16: 4,\n","              17: 1,\n","              18: 8}\n","\n","y_train_coarse2 = np.vectorize(dict_coarse2.get)(y_train)\n","y_val_coarse2 = np.vectorize(dict_coarse2.get)(y_val)\n","y_test_coarse2 = np.vectorize(dict_coarse2.get)(y_test)\n","\n","y_train_coarse1 = np.vectorize(dict_coarse1.get)(y_train_coarse2)\n","y_val_coarse1 = np.vectorize(dict_coarse1.get)(y_val_coarse2)\n","y_test_coarse1 = np.vectorize(dict_coarse1.get)(y_test_coarse2)\n","\n","\n","y_train_c_cat1 = np_utils.to_categorical(y_train_coarse1)\n","y_val_c_cat1 = np_utils.to_categorical(y_val_coarse1)\n","y_test_c_cat1 = np_utils.to_categorical(y_test_coarse1)\n","\n","y_train_c_cat2 = np_utils.to_categorical(y_train_coarse2)\n","y_val_c_cat2 = np_utils.to_categorical(y_val_coarse2)\n","y_test_c_cat2 = np_utils.to_categorical(y_test_coarse2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aH6u_LmMfk2W","colab_type":"text"},"cell_type":"markdown","source":["## Training the model"]},{"metadata":{"id":"YCg3M4BJfk2a","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, Input\n","from keras import optimizers\n","from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger\n","from keras.layers.normalization import BatchNormalization\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bYV1g0qbfk2x","colab_type":"code","colab":{}},"cell_type":"code","source":["class TimingCallback(keras.callbacks.Callback):\n","  \"\"\"Callback that saves the time elapsed of each epoch to the log.\n","  \"\"\"  \n","  def on_epoch_begin(self, epoch, logs={}):\n","    self.starttime=time()\n","  def on_epoch_end(self, epoch, logs={}):\n","    logs['time_elapsed'] = (time()-self.starttime)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J8sBqu1Afk27","colab_type":"code","colab":{}},"cell_type":"code","source":["class AdaptativeLossWeightsModifier3Vars(keras.callbacks.Callback):\n","  def __init__(self, alpha, beta, gamma, decay_rate=0.5):\n","    self.alpha = alpha\n","    self.beta = beta\n","    self.gamma = gamma\n","    self.decay_rate = decay_rate\n","    self.offset_epoch = 0\n","    self.par_reduce = [0, 1]\n","  \n","  def calculate_exponential(self, ratio, decay_rate, epoch):\n","    return np.exp(-ratio*decay_rate*epoch)\n","\n","  def on_epoch_end(self, epoch, logs={}):\n","    list_vars = [K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)]\n","    if epoch < 1:\n","      pass\n","    \n","    else:\n","      loss_coarse1 = self.model.history.history['predictions_coarse1_loss'][-1]\n","      loss_coarse2 = self.model.history.history['predictions_coarse2_loss'][-1]\n","      loss_fine = self.model.history.history['predictions_fine_loss'][-1]\n","      \n","      losses_classes = [loss_coarse1, loss_coarse2, loss_fine]\n","      ratio = losses_classes[self.par_reduce[0]] / losses_classes[self.par_reduce[1]] *(epoch + 1 - self.offset_epoch) \n","      \n","      decaying = self.calculate_exponential(ratio, self.decay_rate/(max(self.par_reduce)**2), epoch)\n","      increasing = 1 - decaying\n","    \n","    \n","      if (1 - increasing) < 0.1 and (self.par_reduce[1] < len(list_vars) - 1):\n","        list_vars[self.par_reduce[0]] = 0\n","        list_vars[self.par_reduce[1]] = 1\n","        self.par_reduce = [i + 1 for i in self.par_reduce]\n","        self.offset_epoch = self.offset_epoch + epoch\n","\n","      else:\n","       list_vars[self.par_reduce[0]] = decaying\n","       list_vars[self.par_reduce[1]] = increasing\n","\n","        \n","      K.set_value(self.alpha, list_vars[0])\n","      K.set_value(self.beta, list_vars[1])\n","      K.set_value(self.gamma, list_vars[2])\n","        \n","      print('Changing loss weights to: coarse1 = {}, coarse2 = {}, fine = {}'.format(K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)))\n","    \n","    logs['alpha'] = K.eval(self.alpha)\n","    logs['beta'] = K.eval(self.beta) \n","    logs['gamma'] = K.eval(self.gamma) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"JyX0adEjfk3N","colab_type":"code","colab":{}},"cell_type":"code","source":["img_rows, img_cols = 32, 32\n","input_shape = (img_rows, img_cols, 3)\n","\n","num_classes_coarse1 = 9\n","num_classes_coarse2 = 19\n","num_classes_fine = 100\n","\n","img_input = Input(shape=input_shape, name='input')\n","\n","# coarse 1 network\n","coarse1 = Conv2D(64, (3, 3), activation='relu', name='c1_block1_conv1', padding='same')(img_input)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Conv2D(64, (3, 3), activation='relu', name='c1_block1_conv2', padding='same')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = MaxPooling2D((2, 2), name='c1_block1_pool')(coarse1)\n","\n","coarse1 = Conv2D(128, (3, 3), activation='relu', name='c1_block1_conv3', padding='same')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Conv2D(128, (3, 3), activation='relu', name='c1_block1_conv4', padding='same')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = MaxPooling2D((2, 2), name='c1_block2_pool')(coarse1)\n","\n","coarse1 = Conv2D(256, (3, 3), activation='relu', name='c1_block1_conv5', padding='same')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Conv2D(256, (3, 3), activation='relu', name='c1_block1_conv6', padding='same')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = MaxPooling2D((2, 2), name='c1_block3_pool')(coarse1)\n","\n","coarse1 = Conv2D(512, (3, 3), activation='relu', name='c1_block1_conv7', padding='same')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Conv2D(512, (3, 3), activation='relu', name='c1_block1_conv8', padding='same')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","\n","coarse1 = Flatten(name='c1_flatten')(coarse1)\n","coarse1 = Dense(1024, name='c1_fc_1')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","coarse1 = Dense(1024, name='c1_fc_2')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","\n","\n","# coarse 2 network\n","coarse2 = Conv2D(64, (3, 3), activation='relu', name='c2_block1_conv1', padding='same')(img_input)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Conv2D(64, (3, 3), activation='relu', name='c2_block1_conv2', padding='same')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = MaxPooling2D((2, 2), name='c2_block1_pool')(coarse2)\n","\n","coarse2 = Conv2D(128, (3, 3), activation='relu', name='c2_block1_conv3', padding='same')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Conv2D(128, (3, 3), activation='relu', name='c2_block1_conv4', padding='same')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = MaxPooling2D((2, 2), name='c2_block2_pool')(coarse2)\n","\n","coarse2 = Conv2D(256, (3, 3), activation='relu', name='c2_block1_conv5', padding='same')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Conv2D(256, (3, 3), activation='relu', name='c2_block1_conv6', padding='same')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = MaxPooling2D((2, 2), name='c2_block3_pool')(coarse2)\n","\n","coarse2 = Conv2D(512, (3, 3), activation='relu', name='c2_block1_conv7', padding='same')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Conv2D(512, (3, 3), activation='relu', name='c2_block1_conv8', padding='same')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","\n","coarse2 = Flatten(name='c2_flatten')(coarse2)\n","coarse2 = Dense(1024, name='c2_fc_1')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","coarse2 = Dense(1024, name='c2_fc_2')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","coarse2 = keras.layers.concatenate([coarse2, coarse1])\n","\n","\n","# fine network\n","fine = Conv2D(64, (3, 3), activation='relu', name='block1_conv1', padding='same')(img_input)\n","fine = BatchNormalization()(fine)\n","fine = Conv2D(64, (3, 3), activation='relu', name='block1_conv2', padding='same')(fine)\n","fine = BatchNormalization()(fine)\n","fine = MaxPooling2D((2, 2), name='block1_pool')(fine)\n","\n","fine = Conv2D(128, (3, 3), activation='relu', name='block1_conv3', padding='same')(fine)\n","fine = BatchNormalization()(fine)\n","fine = Conv2D(128, (3, 3), activation='relu', name='block1_conv4', padding='same')(fine)\n","fine = BatchNormalization()(fine)\n","fine = MaxPooling2D((2, 2), name='block2_pool')(fine)\n","\n","fine = Conv2D(256, (3, 3), activation='relu', name='block1_conv5', padding='same')(fine)\n","fine = BatchNormalization()(fine)\n","fine = Conv2D(256, (3, 3), activation='relu', name='block1_conv6', padding='same')(fine)\n","fine = BatchNormalization()(fine)\n","fine = MaxPooling2D((2, 2), name='block3_pool')(fine)\n","\n","fine = Conv2D(512, (3, 3), activation='relu', name='block1_conv7', padding='same')(fine)\n","fine = BatchNormalization()(fine)\n","fine = Conv2D(512, (3, 3), activation='relu', name='block1_conv8', padding='same')(fine)\n","fine = BatchNormalization()(fine)\n","\n","fine = Flatten(name='flatten')(fine)\n","fine = Dense(1024, name='fc_1')(fine)\n","fine = BatchNormalization()(fine)\n","fine = Activation('relu')(fine)\n","fine = Dropout(0.5)(fine)\n","\n","fine = Dense(1024, name='fc_2')(fine)\n","fine = BatchNormalization()(fine)\n","fine = Activation('relu')(fine)\n","fine = Dropout(0.5)(fine)\n","\n","fine = keras.layers.concatenate([fine, coarse2])\n","\n","coarse_pred1 = Dense(num_classes_coarse1, activation='softmax', name='predictions_coarse1')(coarse1)\n","coarse_pred2 = Dense(num_classes_coarse2, activation='softmax', name='predictions_coarse2')(coarse2)\n","fine_pred = Dense(num_classes_fine, activation='softmax', name='predictions_fine')(fine)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"taLUCrQIfk3X","colab_type":"code","outputId":"6c45fb7a-6da6-42b4-d408-f2311631b021","executionInfo":{"status":"ok","timestamp":1544237477196,"user_tz":120,"elapsed":5539,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":3571}},"cell_type":"code","source":["model = Model(inputs=img_input, outputs= [coarse_pred1, coarse_pred2, fine_pred], name='adaptative_guide_net')\n","\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input (InputLayer)              (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","c1_block1_conv1 (Conv2D)        (None, 32, 32, 64)   1792        input[0][0]                      \n","__________________________________________________________________________________________________\n","c2_block1_conv1 (Conv2D)        (None, 32, 32, 64)   1792        input[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         c1_block1_conv1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         c2_block1_conv1[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input[0][0]                      \n","__________________________________________________________________________________________________\n","c1_block1_conv2 (Conv2D)        (None, 32, 32, 64)   36928       batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","c2_block1_conv2 (Conv2D)        (None, 32, 32, 64)   36928       batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         c1_block1_conv2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 32, 32, 64)   256         c2_block1_conv2[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","c1_block1_pool (MaxPooling2D)   (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","c2_block1_pool (MaxPooling2D)   (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","c1_block1_conv3 (Conv2D)        (None, 16, 16, 128)  73856       c1_block1_pool[0][0]             \n","__________________________________________________________________________________________________\n","c2_block1_conv3 (Conv2D)        (None, 16, 16, 128)  73856       c2_block1_pool[0][0]             \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         c1_block1_conv3[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         c2_block1_conv3[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv3 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","c1_block1_conv4 (Conv2D)        (None, 16, 16, 128)  147584      batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","c2_block1_conv4 (Conv2D)        (None, 16, 16, 128)  147584      batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 16, 16, 128)  512         block1_conv3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 16, 16, 128)  512         c1_block1_conv4[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         c2_block1_conv4[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv4 (Conv2D)           (None, 16, 16, 128)  147584      batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","c1_block2_pool (MaxPooling2D)   (None, 8, 8, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","c2_block2_pool (MaxPooling2D)   (None, 8, 8, 128)    0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 16, 16, 128)  512         block1_conv4[0][0]               \n","__________________________________________________________________________________________________\n","c1_block1_conv5 (Conv2D)        (None, 8, 8, 256)    295168      c1_block2_pool[0][0]             \n","__________________________________________________________________________________________________\n","c2_block1_conv5 (Conv2D)        (None, 8, 8, 256)    295168      c2_block2_pool[0][0]             \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 8, 8, 256)    1024        c1_block1_conv5[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 8, 8, 256)    1024        c2_block1_conv5[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv5 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","c1_block1_conv6 (Conv2D)        (None, 8, 8, 256)    590080      batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","c2_block1_conv6 (Conv2D)        (None, 8, 8, 256)    590080      batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        block1_conv5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        c1_block1_conv6[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 8, 8, 256)    1024        c2_block1_conv6[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv6 (Conv2D)           (None, 8, 8, 256)    590080      batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","c1_block3_pool (MaxPooling2D)   (None, 4, 4, 256)    0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","c2_block3_pool (MaxPooling2D)   (None, 4, 4, 256)    0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 8, 8, 256)    1024        block1_conv6[0][0]               \n","__________________________________________________________________________________________________\n","c1_block1_conv7 (Conv2D)        (None, 4, 4, 512)    1180160     c1_block3_pool[0][0]             \n","__________________________________________________________________________________________________\n","c2_block1_conv7 (Conv2D)        (None, 4, 4, 512)    1180160     c2_block3_pool[0][0]             \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 4, 4, 512)    2048        c1_block1_conv7[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 4, 4, 512)    2048        c2_block1_conv7[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv7 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","c1_block1_conv8 (Conv2D)        (None, 4, 4, 512)    2359808     batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","c2_block1_conv8 (Conv2D)        (None, 4, 4, 512)    2359808     batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 4, 4, 512)    2048        block1_conv7[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 4, 4, 512)    2048        c1_block1_conv8[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 4, 4, 512)    2048        c2_block1_conv8[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv8 (Conv2D)           (None, 4, 4, 512)    2359808     batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","c1_flatten (Flatten)            (None, 8192)         0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","c2_flatten (Flatten)            (None, 8192)         0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 4, 4, 512)    2048        block1_conv8[0][0]               \n","__________________________________________________________________________________________________\n","c1_fc_1 (Dense)                 (None, 1024)         8389632     c1_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","c2_fc_1 (Dense)                 (None, 1024)         8389632     c2_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 8192)         0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 1024)         4096        c1_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 1024)         4096        c2_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","fc_1 (Dense)                    (None, 1024)         8389632     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 1024)         0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 1024)         0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 1024)         4096        fc_1[0][0]                       \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 1024)         0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 1024)         0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 1024)         0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","c1_fc_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","c2_fc_2 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 1024)         0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 1024)         4096        c1_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 1024)         4096        c2_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","fc_2 (Dense)                    (None, 1024)         1049600     dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 1024)         0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 1024)         0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 1024)         4096        fc_2[0][0]                       \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 1024)         0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 1024)         0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 2048)         0           dropout_4[0][0]                  \n","                                                                 dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 1024)         0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 3072)         0           dropout_6[0][0]                  \n","                                                                 concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","predictions_coarse1 (Dense)     (None, 9)            9225        dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","predictions_coarse2 (Dense)     (None, 19)           38931       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","predictions_fine (Dense)        (None, 100)          307300      concatenate_2[0][0]              \n","==================================================================================================\n","Total params: 42,776,896\n","Trainable params: 42,753,088\n","Non-trainable params: 23,808\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"kyk-6ImMfk37","colab_type":"code","colab":{}},"cell_type":"code","source":["alpha = K.variable(value=0.9, dtype=\"float32\", name=\"alpha\") \n","beta = K.variable(value=0.1, dtype=\"float32\", name=\"beta\") \n","gamma = K.variable(value=0, dtype=\"float32\", name=\"gamma\") \n","\n","sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=sgd,\n","              loss_weights=[alpha, beta, gamma],\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gnv5m8Pdfk4d","colab_type":"code","colab":{}},"cell_type":"code","source":["clr_cb = ReduceLROnPlateau(monitor='val_predictions_fine_loss', factor=0.5, patience=10, verbose=1, min_lr=3.125e-05)\n","time_cb = TimingCallback()\n","change_lw = AdaptativeLossWeightsModifier3Vars(alpha, beta, gamma, decay_rate=0.1)\n","csv_cb = CSVLogger('drive/TCC-ITAU/cifar-100/training-data/guide-net/adaptative-guide-net.csv', separator=',', append=False)\n","\n","\n","cbks = [clr_cb, time_cb, change_lw, csv_cb]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JKWSYhQ2fk5D","colab_type":"code","outputId":"4686d731-ada2-455d-b62b-62f863d5a232","executionInfo":{"status":"ok","timestamp":1544242312929,"user_tz":120,"elapsed":4832530,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":2879}},"cell_type":"code","source":["epochs = 50\n","start_time = time()\n","training = model.fit(train_features, [y_train_c_cat1, y_train_c_cat2, y_train_cat],\n","                     validation_data=(vali_features, [y_val_c_cat1, y_val_c_cat2, y_val_cat]),\n","                     epochs=epochs,\n","                     batch_size=256, \n","                     callbacks=cbks,\n","                     verbose=1)\n","training_time = time() - start_time"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Train on 45000 samples, validate on 5000 samples\n","Epoch 1/50\n","45000/45000 [==============================] - 107s 2ms/step - loss: 2.1809 - predictions_coarse1_loss: 2.0489 - predictions_coarse2_loss: 3.3695 - predictions_fine_loss: 5.5435 - predictions_coarse1_acc: 0.3404 - predictions_coarse2_acc: 0.0917 - predictions_fine_acc: 0.0101 - val_loss: 1.7546 - val_predictions_coarse1_loss: 1.6575 - val_predictions_coarse2_loss: 2.6282 - val_predictions_fine_loss: 4.8846 - val_predictions_coarse1_acc: 0.4608 - val_predictions_coarse2_acc: 0.2148 - val_predictions_fine_acc: 0.0086\n","Epoch 2/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.7857 - predictions_coarse1_loss: 1.6581 - predictions_coarse2_loss: 2.9344 - predictions_fine_loss: 5.5167 - predictions_coarse1_acc: 0.4499 - predictions_coarse2_acc: 0.1615 - predictions_fine_acc: 0.0095 - val_loss: 1.5755 - val_predictions_coarse1_loss: 1.4809 - val_predictions_coarse2_loss: 2.4275 - val_predictions_fine_loss: 4.8132 - val_predictions_coarse1_acc: 0.4946 - val_predictions_coarse2_acc: 0.2558 - val_predictions_fine_acc: 0.0082\n","Changing loss weights to: coarse1 = 0.8854929208755493, coarse2 = 0.11450705677270889, fine = 0.0\n","Epoch 3/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.6377 - predictions_coarse1_loss: 1.4968 - predictions_coarse2_loss: 2.7272 - predictions_fine_loss: 5.5069 - predictions_coarse1_acc: 0.5006 - predictions_coarse2_acc: 0.2059 - predictions_fine_acc: 0.0104 - val_loss: 1.5380 - val_predictions_coarse1_loss: 1.4381 - val_predictions_coarse2_loss: 2.3106 - val_predictions_fine_loss: 4.8198 - val_predictions_coarse1_acc: 0.5108 - val_predictions_coarse2_acc: 0.2988 - val_predictions_fine_acc: 0.0086\n","Changing loss weights to: coarse1 = 0.7124508023262024, coarse2 = 0.2875491976737976, fine = 0.0\n","Epoch 4/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.7083 - predictions_coarse1_loss: 1.3801 - predictions_coarse2_loss: 2.5215 - predictions_fine_loss: 5.5036 - predictions_coarse1_acc: 0.5434 - predictions_coarse2_acc: 0.2577 - predictions_fine_acc: 0.0104 - val_loss: 1.5376 - val_predictions_coarse1_loss: 1.2851 - val_predictions_coarse2_loss: 2.1631 - val_predictions_fine_loss: 4.8484 - val_predictions_coarse1_acc: 0.5680 - val_predictions_coarse2_acc: 0.3442 - val_predictions_fine_acc: 0.0108\n","Changing loss weights to: coarse1 = 0.5175707936286926, coarse2 = 0.4824292063713074, fine = 0.0\n","Epoch 5/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.7803 - predictions_coarse1_loss: 1.2912 - predictions_coarse2_loss: 2.3050 - predictions_fine_loss: 5.5103 - predictions_coarse1_acc: 0.5701 - predictions_coarse2_acc: 0.3055 - predictions_fine_acc: 0.0095 - val_loss: 1.5905 - val_predictions_coarse1_loss: 1.2281 - val_predictions_coarse2_loss: 1.9793 - val_predictions_fine_loss: 4.8313 - val_predictions_coarse1_acc: 0.5936 - val_predictions_coarse2_acc: 0.3904 - val_predictions_fine_acc: 0.0074\n","Changing loss weights to: coarse1 = 0.33464518189430237, coarse2 = 0.6653547883033752, fine = 0.0\n","Epoch 6/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.8086 - predictions_coarse1_loss: 1.2384 - predictions_coarse2_loss: 2.0954 - predictions_fine_loss: 5.5068 - predictions_coarse1_acc: 0.5909 - predictions_coarse2_acc: 0.3598 - predictions_fine_acc: 0.0104 - val_loss: 1.7611 - val_predictions_coarse1_loss: 1.3203 - val_predictions_coarse2_loss: 1.9828 - val_predictions_fine_loss: 4.8973 - val_predictions_coarse1_acc: 0.5526 - val_predictions_coarse2_acc: 0.3944 - val_predictions_fine_acc: 0.0086\n","Changing loss weights to: coarse1 = 0.1862913817167282, coarse2 = 0.8137086033821106, fine = 0.0\n","Epoch 7/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.8090 - predictions_coarse1_loss: 1.1913 - predictions_coarse2_loss: 1.9504 - predictions_fine_loss: 5.5266 - predictions_coarse1_acc: 0.6031 - predictions_coarse2_acc: 0.3993 - predictions_fine_acc: 0.0095 - val_loss: 1.6801 - val_predictions_coarse1_loss: 1.1787 - val_predictions_coarse2_loss: 1.7949 - val_predictions_fine_loss: 4.8681 - val_predictions_coarse1_acc: 0.6056 - val_predictions_coarse2_acc: 0.4452 - val_predictions_fine_acc: 0.0060\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0, fine = 0.0\n","Epoch 8/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.8194 - predictions_coarse1_loss: 1.1657 - predictions_coarse2_loss: 1.8194 - predictions_fine_loss: 5.5204 - predictions_coarse1_acc: 0.6162 - predictions_coarse2_acc: 0.4346 - predictions_fine_acc: 0.0096 - val_loss: 1.7383 - val_predictions_coarse1_loss: 1.1799 - val_predictions_coarse2_loss: 1.7383 - val_predictions_fine_loss: 4.8529 - val_predictions_coarse1_acc: 0.6078 - val_predictions_coarse2_acc: 0.4620 - val_predictions_fine_acc: 0.0080\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8838049173355103, fine = 0.11619507521390915\n","Epoch 9/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.1075 - predictions_coarse1_loss: 1.1449 - predictions_coarse2_loss: 1.6993 - predictions_fine_loss: 5.2120 - predictions_coarse1_acc: 0.6172 - predictions_coarse2_acc: 0.4676 - predictions_fine_acc: 0.0161 - val_loss: 2.1774 - val_predictions_coarse1_loss: 1.3957 - val_predictions_coarse2_loss: 1.8859 - val_predictions_fine_loss: 4.3948 - val_predictions_coarse1_acc: 0.5450 - val_predictions_coarse2_acc: 0.4372 - val_predictions_fine_acc: 0.0514\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8205729126930237, fine = 0.17942708730697632\n","Epoch 10/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.1569 - predictions_coarse1_loss: 1.1172 - predictions_coarse2_loss: 1.5994 - predictions_fine_loss: 4.7064 - predictions_coarse1_acc: 0.6290 - predictions_coarse2_acc: 0.4969 - predictions_fine_acc: 0.0416 - val_loss: 2.0466 - val_predictions_coarse1_loss: 1.1736 - val_predictions_coarse2_loss: 1.6146 - val_predictions_fine_loss: 4.0222 - val_predictions_coarse1_acc: 0.6060 - val_predictions_coarse2_acc: 0.4996 - val_predictions_fine_acc: 0.1194\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.7456957101821899, fine = 0.25430431962013245\n","Epoch 11/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.2167 - predictions_coarse1_loss: 1.0822 - predictions_coarse2_loss: 1.5135 - predictions_fine_loss: 4.2787 - predictions_coarse1_acc: 0.6400 - predictions_coarse2_acc: 0.5197 - predictions_fine_acc: 0.0833 - val_loss: 2.1092 - val_predictions_coarse1_loss: 1.0879 - val_predictions_coarse2_loss: 1.5651 - val_predictions_fine_loss: 3.7047 - val_predictions_coarse1_acc: 0.6334 - val_predictions_coarse2_acc: 0.5148 - val_predictions_fine_acc: 0.1718\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.6539068818092346, fine = 0.346093088388443\n","Epoch 12/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.3032 - predictions_coarse1_loss: 1.0562 - predictions_coarse2_loss: 1.4458 - predictions_fine_loss: 3.9231 - predictions_coarse1_acc: 0.6450 - predictions_coarse2_acc: 0.5360 - predictions_fine_acc: 0.1244 - val_loss: 2.1884 - val_predictions_coarse1_loss: 1.0994 - val_predictions_coarse2_loss: 1.5429 - val_predictions_fine_loss: 3.4081 - val_predictions_coarse1_acc: 0.6298 - val_predictions_coarse2_acc: 0.5182 - val_predictions_fine_acc: 0.2236\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.5578622817993164, fine = 0.442137748003006\n","Epoch 13/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.3638 - predictions_coarse1_loss: 1.0368 - predictions_coarse2_loss: 1.3811 - predictions_fine_loss: 3.6038 - predictions_coarse1_acc: 0.6538 - predictions_coarse2_acc: 0.5527 - predictions_fine_acc: 0.1668 - val_loss: 2.2914 - val_predictions_coarse1_loss: 1.1620 - val_predictions_coarse2_loss: 1.5940 - val_predictions_fine_loss: 3.1713 - val_predictions_coarse1_acc: 0.6114 - val_predictions_coarse2_acc: 0.5162 - val_predictions_fine_acc: 0.2500\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.46120700240135193, fine = 0.5387929677963257\n","Epoch 14/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.4042 - predictions_coarse1_loss: 1.0148 - predictions_coarse2_loss: 1.3381 - predictions_fine_loss: 3.3168 - predictions_coarse1_acc: 0.6596 - predictions_coarse2_acc: 0.5667 - predictions_fine_acc: 0.2072 - val_loss: 2.2760 - val_predictions_coarse1_loss: 1.0441 - val_predictions_coarse2_loss: 1.4809 - val_predictions_fine_loss: 2.9566 - val_predictions_coarse1_acc: 0.6516 - val_predictions_coarse2_acc: 0.5458 - val_predictions_fine_acc: 0.2920\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.36921024322509766, fine = 0.6307897567749023\n","Epoch 15/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.4231 - predictions_coarse1_loss: 0.9998 - predictions_coarse2_loss: 1.2969 - predictions_fine_loss: 3.0823 - predictions_coarse1_acc: 0.6664 - predictions_coarse2_acc: 0.5775 - predictions_fine_acc: 0.2430 - val_loss: 2.3118 - val_predictions_coarse1_loss: 1.0603 - val_predictions_coarse2_loss: 1.4562 - val_predictions_fine_loss: 2.8126 - val_predictions_coarse1_acc: 0.6360 - val_predictions_coarse2_acc: 0.5466 - val_predictions_fine_acc: 0.3082\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.2805953323841095, fine = 0.7194046974182129\n","Epoch 16/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.4275 - predictions_coarse1_loss: 0.9925 - predictions_coarse2_loss: 1.2691 - predictions_fine_loss: 2.8793 - predictions_coarse1_acc: 0.6661 - predictions_coarse2_acc: 0.5878 - predictions_fine_acc: 0.2800 - val_loss: 2.3716 - val_predictions_coarse1_loss: 1.0756 - val_predictions_coarse2_loss: 1.4925 - val_predictions_fine_loss: 2.7145 - val_predictions_coarse1_acc: 0.6444 - val_predictions_coarse2_acc: 0.5364 - val_predictions_fine_acc: 0.3222\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.2064281404018402, fine = 0.7935718297958374\n","Epoch 17/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.3967 - predictions_coarse1_loss: 0.9792 - predictions_coarse2_loss: 1.2435 - predictions_fine_loss: 2.6967 - predictions_coarse1_acc: 0.6698 - predictions_coarse2_acc: 0.5961 - predictions_fine_acc: 0.3074 - val_loss: 2.3804 - val_predictions_coarse1_loss: 1.0504 - val_predictions_coarse2_loss: 1.4707 - val_predictions_fine_loss: 2.6171 - val_predictions_coarse1_acc: 0.6524 - val_predictions_coarse2_acc: 0.5422 - val_predictions_fine_acc: 0.3454\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.14379192888736725, fine = 0.856208086013794\n","Epoch 18/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.3525 - predictions_coarse1_loss: 0.9670 - predictions_coarse2_loss: 1.2214 - predictions_fine_loss: 2.5425 - predictions_coarse1_acc: 0.6795 - predictions_coarse2_acc: 0.6006 - predictions_fine_acc: 0.3399 - val_loss: 2.4060 - val_predictions_coarse1_loss: 1.0929 - val_predictions_coarse2_loss: 1.5106 - val_predictions_fine_loss: 2.5564 - val_predictions_coarse1_acc: 0.6444 - val_predictions_coarse2_acc: 0.5462 - val_predictions_fine_acc: 0.3544\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.09521492570638657, fine = 0.9047850966453552\n","Epoch 19/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.2852 - predictions_coarse1_loss: 0.9630 - predictions_coarse2_loss: 1.2045 - predictions_fine_loss: 2.3989 - predictions_coarse1_acc: 0.6776 - predictions_coarse2_acc: 0.6038 - predictions_fine_acc: 0.3671 - val_loss: 2.3555 - val_predictions_coarse1_loss: 1.0593 - val_predictions_coarse2_loss: 1.4431 - val_predictions_fine_loss: 2.4516 - val_predictions_coarse1_acc: 0.6494 - val_predictions_coarse2_acc: 0.5560 - val_predictions_fine_acc: 0.3710\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.060181137174367905, fine = 0.9398188591003418\n","Epoch 20/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.2057 - predictions_coarse1_loss: 0.9518 - predictions_coarse2_loss: 1.1887 - predictions_fine_loss: 2.2709 - predictions_coarse1_acc: 0.6817 - predictions_coarse2_acc: 0.6111 - predictions_fine_acc: 0.3945 - val_loss: 2.3300 - val_predictions_coarse1_loss: 1.0433 - val_predictions_coarse2_loss: 1.4100 - val_predictions_fine_loss: 2.3889 - val_predictions_coarse1_acc: 0.6550 - val_predictions_coarse2_acc: 0.5598 - val_predictions_fine_acc: 0.3872\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.03547181561589241, fine = 0.9645282030105591\n","Epoch 21/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.1133 - predictions_coarse1_loss: 0.9360 - predictions_coarse2_loss: 1.1637 - predictions_fine_loss: 2.1482 - predictions_coarse1_acc: 0.6879 - predictions_coarse2_acc: 0.6173 - predictions_fine_acc: 0.4178 - val_loss: 2.3674 - val_predictions_coarse1_loss: 1.0474 - val_predictions_coarse2_loss: 1.4817 - val_predictions_fine_loss: 2.4000 - val_predictions_coarse1_acc: 0.6572 - val_predictions_coarse2_acc: 0.5488 - val_predictions_fine_acc: 0.3806\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.019722014665603638, fine = 0.980277955532074\n","Epoch 22/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 2.0103 - predictions_coarse1_loss: 0.9209 - predictions_coarse2_loss: 1.1380 - predictions_fine_loss: 2.0278 - predictions_coarse1_acc: 0.6906 - predictions_coarse2_acc: 0.6210 - predictions_fine_acc: 0.4481 - val_loss: 2.3330 - val_predictions_coarse1_loss: 1.1595 - val_predictions_coarse2_loss: 1.4943 - val_predictions_fine_loss: 2.3499 - val_predictions_coarse1_acc: 0.6132 - val_predictions_coarse2_acc: 0.5430 - val_predictions_fine_acc: 0.4000\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.010564158670604229, fine = 0.9894358515739441\n","Epoch 23/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.9165 - predictions_coarse1_loss: 0.9036 - predictions_coarse2_loss: 1.1171 - predictions_fine_loss: 1.9250 - predictions_coarse1_acc: 0.6992 - predictions_coarse2_acc: 0.6302 - predictions_fine_acc: 0.4704 - val_loss: 2.2598 - val_predictions_coarse1_loss: 1.0745 - val_predictions_coarse2_loss: 1.4288 - val_predictions_fine_loss: 2.2687 - val_predictions_coarse1_acc: 0.6470 - val_predictions_coarse2_acc: 0.5604 - val_predictions_fine_acc: 0.4072\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.005261832382529974, fine = 0.9947381615638733\n","Epoch 24/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.8070 - predictions_coarse1_loss: 0.8856 - predictions_coarse2_loss: 1.0882 - predictions_fine_loss: 1.8108 - predictions_coarse1_acc: 0.7029 - predictions_coarse2_acc: 0.6383 - predictions_fine_acc: 0.4965 - val_loss: 2.2263 - val_predictions_coarse1_loss: 1.0559 - val_predictions_coarse2_loss: 1.4016 - val_predictions_fine_loss: 2.2307 - val_predictions_coarse1_acc: 0.6576 - val_predictions_coarse2_acc: 0.5708 - val_predictions_fine_acc: 0.4200\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0024641535710543394, fine = 0.9975358247756958\n","Epoch 25/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.7196 - predictions_coarse1_loss: 0.8777 - predictions_coarse2_loss: 1.0714 - predictions_fine_loss: 1.7212 - predictions_coarse1_acc: 0.7086 - predictions_coarse2_acc: 0.6437 - predictions_fine_acc: 0.5179 - val_loss: 2.2498 - val_predictions_coarse1_loss: 1.1610 - val_predictions_coarse2_loss: 1.4799 - val_predictions_fine_loss: 2.2517 - val_predictions_coarse1_acc: 0.6092 - val_predictions_coarse2_acc: 0.5498 - val_predictions_fine_acc: 0.4216\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0010588477598503232, fine = 0.9989411234855652\n","Epoch 26/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.6091 - predictions_coarse1_loss: 0.8496 - predictions_coarse2_loss: 1.0451 - predictions_fine_loss: 1.6097 - predictions_coarse1_acc: 0.7171 - predictions_coarse2_acc: 0.6510 - predictions_fine_acc: 0.5465 - val_loss: 2.2256 - val_predictions_coarse1_loss: 1.0658 - val_predictions_coarse2_loss: 1.4485 - val_predictions_fine_loss: 2.2264 - val_predictions_coarse1_acc: 0.6498 - val_predictions_coarse2_acc: 0.5542 - val_predictions_fine_acc: 0.4192\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.00041770358802750707, fine = 0.9995822906494141\n","Epoch 27/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.5153 - predictions_coarse1_loss: 0.8342 - predictions_coarse2_loss: 1.0208 - predictions_fine_loss: 1.5155 - predictions_coarse1_acc: 0.7218 - predictions_coarse2_acc: 0.6608 - predictions_fine_acc: 0.5678 - val_loss: 2.1902 - val_predictions_coarse1_loss: 1.0730 - val_predictions_coarse2_loss: 1.4270 - val_predictions_fine_loss: 2.1905 - val_predictions_coarse1_acc: 0.6512 - val_predictions_coarse2_acc: 0.5618 - val_predictions_fine_acc: 0.4356\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.00014161597937345505, fine = 0.9998583793640137\n","Epoch 28/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.4225 - predictions_coarse1_loss: 0.8120 - predictions_coarse2_loss: 0.9929 - predictions_fine_loss: 1.4226 - predictions_coarse1_acc: 0.7330 - predictions_coarse2_acc: 0.6722 - predictions_fine_acc: 0.5929 - val_loss: 2.1624 - val_predictions_coarse1_loss: 1.0568 - val_predictions_coarse2_loss: 1.4189 - val_predictions_fine_loss: 2.1625 - val_predictions_coarse1_acc: 0.6564 - val_predictions_coarse2_acc: 0.5622 - val_predictions_fine_acc: 0.4442\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.5270895498106256e-05, fine = 0.9999547004699707\n","Epoch 29/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.3363 - predictions_coarse1_loss: 0.7985 - predictions_coarse2_loss: 0.9710 - predictions_fine_loss: 1.3363 - predictions_coarse1_acc: 0.7344 - predictions_coarse2_acc: 0.6754 - predictions_fine_acc: 0.6168 - val_loss: 2.1283 - val_predictions_coarse1_loss: 1.0290 - val_predictions_coarse2_loss: 1.3878 - val_predictions_fine_loss: 2.1284 - val_predictions_coarse1_acc: 0.6618 - val_predictions_coarse2_acc: 0.5756 - val_predictions_fine_acc: 0.4468\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.3169217709219083e-05, fine = 0.9999868273735046\n","Epoch 30/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.2467 - predictions_coarse1_loss: 0.7792 - predictions_coarse2_loss: 0.9473 - predictions_fine_loss: 1.2467 - predictions_coarse1_acc: 0.7436 - predictions_coarse2_acc: 0.6799 - predictions_fine_acc: 0.6416 - val_loss: 2.1733 - val_predictions_coarse1_loss: 1.1050 - val_predictions_coarse2_loss: 1.4544 - val_predictions_fine_loss: 2.1733 - val_predictions_coarse1_acc: 0.6370 - val_predictions_coarse2_acc: 0.5554 - val_predictions_fine_acc: 0.4420\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.2306936645909445e-06, fine = 0.9999967813491821\n","Epoch 31/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.1510 - predictions_coarse1_loss: 0.7642 - predictions_coarse2_loss: 0.9246 - predictions_fine_loss: 1.1510 - predictions_coarse1_acc: 0.7488 - predictions_coarse2_acc: 0.6871 - predictions_fine_acc: 0.6676 - val_loss: 2.1336 - val_predictions_coarse1_loss: 1.1024 - val_predictions_coarse2_loss: 1.4310 - val_predictions_fine_loss: 2.1336 - val_predictions_coarse1_acc: 0.6398 - val_predictions_coarse2_acc: 0.5600 - val_predictions_fine_acc: 0.4452\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 6.492401780633372e-07, fine = 0.9999993443489075\n","Epoch 32/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 1.0768 - predictions_coarse1_loss: 0.7478 - predictions_coarse2_loss: 0.8986 - predictions_fine_loss: 1.0768 - predictions_coarse1_acc: 0.7562 - predictions_coarse2_acc: 0.6986 - predictions_fine_acc: 0.6884 - val_loss: 2.0898 - val_predictions_coarse1_loss: 1.0664 - val_predictions_coarse2_loss: 1.4025 - val_predictions_fine_loss: 2.0898 - val_predictions_coarse1_acc: 0.6486 - val_predictions_coarse2_acc: 0.5652 - val_predictions_fine_acc: 0.4560\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.336318385066988e-08, fine = 0.9999998807907104\n","Epoch 33/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.9913 - predictions_coarse1_loss: 0.7332 - predictions_coarse2_loss: 0.8739 - predictions_fine_loss: 0.9913 - predictions_coarse1_acc: 0.7610 - predictions_coarse2_acc: 0.7076 - predictions_fine_acc: 0.7147 - val_loss: 2.1160 - val_predictions_coarse1_loss: 1.0782 - val_predictions_coarse2_loss: 1.4256 - val_predictions_fine_loss: 2.1160 - val_predictions_coarse1_acc: 0.6450 - val_predictions_coarse2_acc: 0.5634 - val_predictions_fine_acc: 0.4512\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.4872352238626263e-08, fine = 1.0\n","Epoch 34/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.9211 - predictions_coarse1_loss: 0.7203 - predictions_coarse2_loss: 0.8594 - predictions_fine_loss: 0.9211 - predictions_coarse1_acc: 0.7652 - predictions_coarse2_acc: 0.7134 - predictions_fine_acc: 0.7386 - val_loss: 2.1159 - val_predictions_coarse1_loss: 1.0893 - val_predictions_coarse2_loss: 1.4301 - val_predictions_fine_loss: 2.1159 - val_predictions_coarse1_acc: 0.6444 - val_predictions_coarse2_acc: 0.5648 - val_predictions_fine_acc: 0.4602\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.4304423201494387e-09, fine = 1.0\n","Epoch 35/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.8564 - predictions_coarse1_loss: 0.7094 - predictions_coarse2_loss: 0.8375 - predictions_fine_loss: 0.8564 - predictions_coarse1_acc: 0.7707 - predictions_coarse2_acc: 0.7214 - predictions_fine_acc: 0.7560 - val_loss: 2.1427 - val_predictions_coarse1_loss: 1.1085 - val_predictions_coarse2_loss: 1.4403 - val_predictions_fine_loss: 2.1427 - val_predictions_coarse1_acc: 0.6450 - val_predictions_coarse2_acc: 0.5646 - val_predictions_fine_acc: 0.4560\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0273887296463613e-10, fine = 1.0\n","Epoch 36/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.7807 - predictions_coarse1_loss: 0.6975 - predictions_coarse2_loss: 0.8239 - predictions_fine_loss: 0.7807 - predictions_coarse1_acc: 0.7755 - predictions_coarse2_acc: 0.7265 - predictions_fine_acc: 0.7797 - val_loss: 2.1074 - val_predictions_coarse1_loss: 1.0848 - val_predictions_coarse2_loss: 1.4233 - val_predictions_fine_loss: 2.1074 - val_predictions_coarse1_acc: 0.6558 - val_predictions_coarse2_acc: 0.5660 - val_predictions_fine_acc: 0.4550\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 7.11602218123053e-12, fine = 1.0\n","Epoch 37/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.7227 - predictions_coarse1_loss: 0.6883 - predictions_coarse2_loss: 0.8049 - predictions_fine_loss: 0.7227 - predictions_coarse1_acc: 0.7799 - predictions_coarse2_acc: 0.7328 - predictions_fine_acc: 0.8005 - val_loss: 2.1629 - val_predictions_coarse1_loss: 1.1559 - val_predictions_coarse2_loss: 1.4739 - val_predictions_fine_loss: 2.1629 - val_predictions_coarse1_acc: 0.6284 - val_predictions_coarse2_acc: 0.5552 - val_predictions_fine_acc: 0.4486\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.631563943194428e-13, fine = 1.0\n","Epoch 38/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.6532 - predictions_coarse1_loss: 0.6795 - predictions_coarse2_loss: 0.7880 - predictions_fine_loss: 0.6532 - predictions_coarse1_acc: 0.7799 - predictions_coarse2_acc: 0.7384 - predictions_fine_acc: 0.8214 - val_loss: 2.1192 - val_predictions_coarse1_loss: 1.0964 - val_predictions_coarse2_loss: 1.4239 - val_predictions_fine_loss: 2.1192 - val_predictions_coarse1_acc: 0.6458 - val_predictions_coarse2_acc: 0.5678 - val_predictions_fine_acc: 0.4632\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.8248351928320554e-15, fine = 1.0\n","Epoch 39/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.6036 - predictions_coarse1_loss: 0.6657 - predictions_coarse2_loss: 0.7723 - predictions_fine_loss: 0.6036 - predictions_coarse1_acc: 0.7851 - predictions_coarse2_acc: 0.7458 - predictions_fine_acc: 0.8395 - val_loss: 2.1130 - val_predictions_coarse1_loss: 1.1329 - val_predictions_coarse2_loss: 1.4431 - val_predictions_fine_loss: 2.1130 - val_predictions_coarse1_acc: 0.6262 - val_predictions_coarse2_acc: 0.5668 - val_predictions_fine_acc: 0.4638\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.758529370684156e-17, fine = 1.0\n","Epoch 40/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.5516 - predictions_coarse1_loss: 0.6634 - predictions_coarse2_loss: 0.7616 - predictions_fine_loss: 0.5516 - predictions_coarse1_acc: 0.7889 - predictions_coarse2_acc: 0.7492 - predictions_fine_acc: 0.8554 - val_loss: 2.1535 - val_predictions_coarse1_loss: 1.1271 - val_predictions_coarse2_loss: 1.4508 - val_predictions_fine_loss: 2.1535 - val_predictions_coarse1_acc: 0.6330 - val_predictions_coarse2_acc: 0.5646 - val_predictions_fine_acc: 0.4544\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.7818258166224006e-19, fine = 1.0\n","Epoch 41/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.5056 - predictions_coarse1_loss: 0.6614 - predictions_coarse2_loss: 0.7483 - predictions_fine_loss: 0.5056 - predictions_coarse1_acc: 0.7895 - predictions_coarse2_acc: 0.7541 - predictions_fine_acc: 0.8713 - val_loss: 2.1302 - val_predictions_coarse1_loss: 1.1472 - val_predictions_coarse2_loss: 1.4579 - val_predictions_fine_loss: 2.1302 - val_predictions_coarse1_acc: 0.6268 - val_predictions_coarse2_acc: 0.5592 - val_predictions_fine_acc: 0.4570\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.03363275634792e-21, fine = 1.0\n","Epoch 42/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.4629 - predictions_coarse1_loss: 0.6527 - predictions_coarse2_loss: 0.7390 - predictions_fine_loss: 0.4629 - predictions_coarse1_acc: 0.7921 - predictions_coarse2_acc: 0.7588 - predictions_fine_acc: 0.8838 - val_loss: 2.1684 - val_predictions_coarse1_loss: 1.1194 - val_predictions_coarse2_loss: 1.4566 - val_predictions_fine_loss: 2.1684 - val_predictions_coarse1_acc: 0.6412 - val_predictions_coarse2_acc: 0.5612 - val_predictions_fine_acc: 0.4522\n","\n","Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.9203633474095438e-24, fine = 1.0\n","Epoch 43/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.3948 - predictions_coarse1_loss: 0.6272 - predictions_coarse2_loss: 0.7056 - predictions_fine_loss: 0.3948 - predictions_coarse1_acc: 0.8037 - predictions_coarse2_acc: 0.7738 - predictions_fine_acc: 0.9072 - val_loss: 2.1105 - val_predictions_coarse1_loss: 1.1125 - val_predictions_coarse2_loss: 1.4353 - val_predictions_fine_loss: 2.1105 - val_predictions_coarse1_acc: 0.6416 - val_predictions_coarse2_acc: 0.5636 - val_predictions_fine_acc: 0.4672\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.1554241145012066e-27, fine = 1.0\n","Epoch 44/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.3604 - predictions_coarse1_loss: 0.6223 - predictions_coarse2_loss: 0.6944 - predictions_fine_loss: 0.3604 - predictions_coarse1_acc: 0.8045 - predictions_coarse2_acc: 0.7782 - predictions_fine_acc: 0.9181 - val_loss: 2.1305 - val_predictions_coarse1_loss: 1.0986 - val_predictions_coarse2_loss: 1.4359 - val_predictions_fine_loss: 2.1305 - val_predictions_coarse1_acc: 0.6478 - val_predictions_coarse2_acc: 0.5604 - val_predictions_fine_acc: 0.4628\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.9668424375204302e-32, fine = 1.0\n","Epoch 45/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.3368 - predictions_coarse1_loss: 0.6206 - predictions_coarse2_loss: 0.6812 - predictions_fine_loss: 0.3368 - predictions_coarse1_acc: 0.8087 - predictions_coarse2_acc: 0.7802 - predictions_fine_acc: 0.9273 - val_loss: 2.1174 - val_predictions_coarse1_loss: 1.1294 - val_predictions_coarse2_loss: 1.4446 - val_predictions_fine_loss: 2.1174 - val_predictions_coarse1_acc: 0.6364 - val_predictions_coarse2_acc: 0.5616 - val_predictions_fine_acc: 0.4638\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.2796963395591084e-36, fine = 1.0\n","Epoch 46/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.3172 - predictions_coarse1_loss: 0.6160 - predictions_coarse2_loss: 0.6751 - predictions_fine_loss: 0.3172 - predictions_coarse1_acc: 0.8079 - predictions_coarse2_acc: 0.7840 - predictions_fine_acc: 0.9334 - val_loss: 2.1244 - val_predictions_coarse1_loss: 1.1152 - val_predictions_coarse2_loss: 1.4383 - val_predictions_fine_loss: 2.1244 - val_predictions_coarse1_acc: 0.6426 - val_predictions_coarse2_acc: 0.5676 - val_predictions_fine_acc: 0.4700\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.927480647790262e-40, fine = 1.0\n","Epoch 47/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.2992 - predictions_coarse1_loss: 0.6184 - predictions_coarse2_loss: 0.6724 - predictions_fine_loss: 0.2992 - predictions_coarse1_acc: 0.8064 - predictions_coarse2_acc: 0.7879 - predictions_fine_acc: 0.9389 - val_loss: 2.1427 - val_predictions_coarse1_loss: 1.1237 - val_predictions_coarse2_loss: 1.4493 - val_predictions_fine_loss: 2.1427 - val_predictions_coarse1_acc: 0.6420 - val_predictions_coarse2_acc: 0.5622 - val_predictions_fine_acc: 0.4592\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.5223372357846707e-44, fine = 1.0\n","Epoch 48/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.2849 - predictions_coarse1_loss: 0.6110 - predictions_coarse2_loss: 0.6688 - predictions_fine_loss: 0.2849 - predictions_coarse1_acc: 0.8093 - predictions_coarse2_acc: 0.7872 - predictions_fine_acc: 0.9429 - val_loss: 2.1338 - val_predictions_coarse1_loss: 1.1214 - val_predictions_coarse2_loss: 1.4449 - val_predictions_fine_loss: 2.1338 - val_predictions_coarse1_acc: 0.6408 - val_predictions_coarse2_acc: 0.5624 - val_predictions_fine_acc: 0.4676\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0, fine = 1.0\n","Epoch 49/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.2728 - predictions_coarse1_loss: 0.6066 - predictions_coarse2_loss: 0.6631 - predictions_fine_loss: 0.2728 - predictions_coarse1_acc: 0.8103 - predictions_coarse2_acc: 0.7886 - predictions_fine_acc: 0.9470 - val_loss: 2.1303 - val_predictions_coarse1_loss: 1.1126 - val_predictions_coarse2_loss: 1.4393 - val_predictions_fine_loss: 2.1303 - val_predictions_coarse1_acc: 0.6416 - val_predictions_coarse2_acc: 0.5626 - val_predictions_fine_acc: 0.4668\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0, fine = 1.0\n","Epoch 50/50\n","45000/45000 [==============================] - 95s 2ms/step - loss: 0.2627 - predictions_coarse1_loss: 0.6095 - predictions_coarse2_loss: 0.6593 - predictions_fine_loss: 0.2627 - predictions_coarse1_acc: 0.8112 - predictions_coarse2_acc: 0.7900 - predictions_fine_acc: 0.9492 - val_loss: 2.1404 - val_predictions_coarse1_loss: 1.1370 - val_predictions_coarse2_loss: 1.4573 - val_predictions_fine_loss: 2.1404 - val_predictions_coarse1_acc: 0.6296 - val_predictions_coarse2_acc: 0.5620 - val_predictions_fine_acc: 0.4664\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0, fine = 1.0\n"],"name":"stdout"}]},{"metadata":{"id":"nS5DnAtyfk5P","colab_type":"code","outputId":"9cebb0aa-bc74-4534-a19c-dec10c380b5c","executionInfo":{"status":"ok","timestamp":1544242348385,"user_tz":120,"elapsed":13384,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"cell_type":"code","source":["model.evaluate(test_features, [y_test_c_cat1,y_test_c_cat2, y_test_cat])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 13s 1ms/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[2.081061706352234,\n"," 1.117843085002899,\n"," 1.4172348230361937,\n"," 2.081061706352234,\n"," 0.6323,\n"," 0.5681,\n"," 0.4812]"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"9FfKMwTxfk56","colab_type":"code","outputId":"08234097-385a-49ed-e02f-220c3f217fa1","executionInfo":{"status":"ok","timestamp":1544242369125,"user_tz":120,"elapsed":783,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["print('Total training time: {}'.format(training_time))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Total training time: 4831.6615426540375\n"],"name":"stdout"}]},{"metadata":{"id":"CDU9_2B6fk6E","colab_type":"code","outputId":"2353917e-5864-460d-9dde-36b77be30524","executionInfo":{"status":"error","timestamp":1544242393739,"user_tz":120,"elapsed":14547,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":1111}},"cell_type":"code","source":["model.save('drive/TCC-ITAU/cifar-100/models/adaptative-guide-net.h5')"],"execution_count":15,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-de4d5207ced3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/TCC-ITAU/cifar-100/models/adaptative-guide-net.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;34m'sample_weight_mode'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0;34m'loss_weights'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             }, default=get_json_type).encode('utf8')\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msymbolic_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Not JSON Serializable: <tf.Variable 'alpha:0' shape=() dtype=float32_ref>"]}]},{"metadata":{"id":"8pGBC_BGfk6V","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}