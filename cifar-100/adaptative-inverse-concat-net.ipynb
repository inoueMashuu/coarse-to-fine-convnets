{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adaptative-inverse-concat-net.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"eUKnB3_Kf2nw","colab_type":"text"},"cell_type":"markdown","source":["## Adaptative Inverse Concat-net"]},{"metadata":{"id":"g4kw7gLefk1I","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z49ZaCkofk1U","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q9i0kVvPfk1i","colab_type":"text"},"cell_type":"markdown","source":["## Loading the data"]},{"metadata":{"id":"eKoyWRCOfk1l","colab_type":"code","outputId":"b2bf4d4b-a939-4f00-ea79-759b770a0b32","executionInfo":{"status":"ok","timestamp":1544227656854,"user_tz":120,"elapsed":1955,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["from time import time\n","import os\n","import gzip\n","import numpy as np\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import cifar100"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"r295GDqKfk10","colab_type":"code","colab":{}},"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n","                                                  test_size=0.1, \n","                                                  random_state=1974,\n","                                                  stratify = y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fu3pH4M4fk15","colab_type":"code","colab":{}},"cell_type":"code","source":["train_features = X_train.reshape(X_train.shape[0], 32, 32, 3)/255\n","vali_features = X_val.reshape(X_val.shape[0], 32, 32, 3)/255\n","test_features = X_test.reshape(X_test.shape[0], 32, 32, 3)/255\n","\n","y_train_cat = np_utils.to_categorical(y_train)\n","y_val_cat = np_utils.to_categorical(y_val)\n","y_test_cat = np_utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3ED5tc9Cfk2H","colab_type":"text"},"cell_type":"markdown","source":["## Defining coarse labels"]},{"metadata":{"id":"uIT8HRXGfk2L","colab_type":"code","colab":{}},"cell_type":"code","source":["dict_coarse2 = {0: 4,  1: 1,  2: 14,  3: 8,  4: 12,  5: 6,  6: 7,  7: 7,  8: 18,  9: 3,  10: 3,\n","                11: 14,  12: 9,  13: 18,  14: 7,  15: 11,  16: 3,  17: 9,  18: 7,  19: 11,  20: 6,\n","                21: 11,  22: 5,  23: 10,  24: 7,  25: 6,  26: 13,  27: 15,  28: 3,  29: 15,  30: 0,\n","                31: 11,  32: 1,  33: 10,  34: 12,  35: 14,  36: 16,  37: 9,  38: 11,  39: 5,  40: 5,\n","                41: 18,  42: 8,  43: 8,  44: 15,  45: 13,  46: 14,  47: 17,  48: 18,  49: 10,  50: 16,\n","                51: 4,  52: 17,  53: 4,  54: 2,  55: 12,  56: 17,  57: 4,  58: 18,  59: 17,  60: 10,\n","                61: 3,  62: 2,  63: 12,  64: 12,  65: 16,  66: 12,  67: 1,  68: 9,  69: 18,  70: 2,\n","                71: 10,  72: 12,  73: 1,  74: 16,  75: 12,  76: 9,  77: 13,  78: 15,  79: 13,  80: 16,\n","                81: 18,  82: 2,  83: 4,  84: 6,  85: 18,  86: 5,  87: 5,  88: 8,  89: 18,  90: 18,\n","                91: 1,  92: 2,  93: 15,  94: 6,  95: 0,  96: 17,  97: 8,  98: 14,  99: 13}\n","\n","\n","dict_coarse1 = {0: 0,\n","              1: 0,\n","              2: 1,\n","              3: 2,\n","              4: 1,\n","              5: 2,\n","              6: 2,\n","              7: 3,\n","              8: 4,\n","              9: 5,\n","              10: 5,\n","              11: 4,\n","              12: 4,\n","              13: 3,\n","              14: 6,\n","              15: 7,\n","              16: 4,\n","              17: 1,\n","              18: 8}\n","\n","y_train_coarse2 = np.vectorize(dict_coarse2.get)(y_train)\n","y_val_coarse2 = np.vectorize(dict_coarse2.get)(y_val)\n","y_test_coarse2 = np.vectorize(dict_coarse2.get)(y_test)\n","\n","y_train_coarse1 = np.vectorize(dict_coarse1.get)(y_train_coarse2)\n","y_val_coarse1 = np.vectorize(dict_coarse1.get)(y_val_coarse2)\n","y_test_coarse1 = np.vectorize(dict_coarse1.get)(y_test_coarse2)\n","\n","\n","y_train_c_cat1 = np_utils.to_categorical(y_train_coarse1)\n","y_val_c_cat1 = np_utils.to_categorical(y_val_coarse1)\n","y_test_c_cat1 = np_utils.to_categorical(y_test_coarse1)\n","\n","y_train_c_cat2 = np_utils.to_categorical(y_train_coarse2)\n","y_val_c_cat2 = np_utils.to_categorical(y_val_coarse2)\n","y_test_c_cat2 = np_utils.to_categorical(y_test_coarse2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aH6u_LmMfk2W","colab_type":"text"},"cell_type":"markdown","source":["## Training the model"]},{"metadata":{"id":"YCg3M4BJfk2a","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, Input\n","from keras import optimizers\n","from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger\n","from keras.layers.normalization import BatchNormalization\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bYV1g0qbfk2x","colab_type":"code","colab":{}},"cell_type":"code","source":["class TimingCallback(keras.callbacks.Callback):\n","  \"\"\"Callback that saves the time elapsed of each epoch to the log.\n","  \"\"\"  \n","  def on_epoch_begin(self, epoch, logs={}):\n","    self.starttime=time()\n","  def on_epoch_end(self, epoch, logs={}):\n","    logs['time_elapsed'] = (time()-self.starttime)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J8sBqu1Afk27","colab_type":"code","colab":{}},"cell_type":"code","source":["class AdaptativeLossWeightsModifier3Vars(keras.callbacks.Callback):\n","  def __init__(self, alpha, beta, gamma, decay_rate=0.5):\n","    self.alpha = alpha\n","    self.beta = beta\n","    self.gamma = gamma\n","    self.decay_rate = decay_rate\n","    self.offset_epoch = 0\n","    self.par_reduce = [0, 1]\n","  \n","  def calculate_exponential(self, ratio, decay_rate, epoch):\n","    return np.exp(-ratio*decay_rate*epoch)\n","\n","  def on_epoch_end(self, epoch, logs={}):\n","    list_vars = [K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)]\n","    if epoch < 1:\n","      pass\n","    \n","    else:\n","      loss_coarse1 = self.model.history.history['predictions_coarse1_loss'][-1]\n","      loss_coarse2 = self.model.history.history['predictions_coarse2_loss'][-1]\n","      loss_fine = self.model.history.history['predictions_fine_loss'][-1]\n","      \n","      losses_classes = [loss_coarse1, loss_coarse2, loss_fine]\n","      ratio = losses_classes[self.par_reduce[0]] / losses_classes[self.par_reduce[1]] *(epoch + 1 - self.offset_epoch) \n","      \n","      decaying = self.calculate_exponential(ratio, self.decay_rate/(max(self.par_reduce)**2), epoch)\n","      increasing = 1 - decaying\n","    \n","    \n","      if (1 - increasing) < 0.1 and (self.par_reduce[1] < len(list_vars) - 1):\n","        list_vars[self.par_reduce[0]] = 0\n","        list_vars[self.par_reduce[1]] = 1\n","        self.par_reduce = [i + 1 for i in self.par_reduce]\n","        self.offset_epoch = self.offset_epoch + epoch\n","\n","      else:\n","       list_vars[self.par_reduce[0]] = decaying\n","       list_vars[self.par_reduce[1]] = increasing\n","\n","        \n","      K.set_value(self.alpha, list_vars[0])\n","      K.set_value(self.beta, list_vars[1])\n","      K.set_value(self.gamma, list_vars[2])\n","        \n","      print('Changing loss weights to: coarse1 = {}, coarse2 = {}, fine = {}'.format(K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)))\n","    \n","    logs['alpha'] = K.eval(self.alpha)\n","    logs['beta'] = K.eval(self.beta) \n","    logs['gamma'] = K.eval(self.gamma) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"JyX0adEjfk3N","colab_type":"code","colab":{}},"cell_type":"code","source":["img_rows, img_cols = 32, 32\n","input_shape = (img_rows, img_cols, 3)\n","\n","num_classes_coarse1 = 9\n","num_classes_coarse2 = 19\n","num_classes_fine = 100\n","\n","img_input = Input(shape=input_shape, name='input')\n","\n","\n","\n","x = Conv2D(64, (3, 3), activation='relu', name='block1_conv1', padding='same')(img_input)\n","x = BatchNormalization()(x)\n","x = Conv2D(64, (3, 3), activation='relu', name='block1_conv2', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block1_pool')(x)\n","\n","x = Conv2D(128, (3, 3), activation='relu', name='block1_conv3', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(128, (3, 3), activation='relu', name='block1_conv4', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block2_pool')(x)\n","\n","\n","#---- coarse branch 1 ----\n","coarse1 = Flatten(name='c1_flatten')(x)\n","coarse1 = Dense(256, name='c1_fc_1')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","coarse1 = Dense(256, name='c1_fc_2')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","\n","x = Conv2D(256, (3, 3), activation='relu', name='block1_conv5', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(256, (3, 3), activation='relu', name='block1_conv6', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block3_pool')(x)\n","\n","\n","#---- coarse branch 2 ----\n","coarse2 = Flatten(name='c2_flatten')(x)\n","coarse2 = Dense(512, name='c2_fc_1')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","coarse2 = Dense(512, name='c2_fc_2')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","\n","x = Conv2D(512, (3, 3), activation='relu', name='block1_conv7', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(512, (3, 3), activation='relu', name='block1_conv8', padding='same')(x)\n","x = BatchNormalization()(x)\n","\n","\n","x = Flatten(name='flatten')(x)\n","x = Dense(1024, name='fc_1')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","\n","x = Dense(1024, name='fc_2')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","\n","fine_pred = Dense(num_classes_fine, activation='softmax', name='predictions_fine')(x)\n","\n","coarse2 = keras.layers.concatenate([coarse2, x])\n","coarse_pred2 = Dense(num_classes_coarse2, activation='softmax', name='predictions_coarse2')(coarse2)\n","\n","coarse1 = keras.layers.concatenate([coarse1, coarse2])\n","coarse_pred1 = Dense(num_classes_coarse1, activation='softmax', name='predictions_coarse1')(coarse1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"taLUCrQIfk3X","colab_type":"code","outputId":"53ed16ad-843d-4fe1-f001-30d1200e14fb","executionInfo":{"status":"ok","timestamp":1544229720613,"user_tz":120,"elapsed":2344,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":2150}},"cell_type":"code","source":["model = Model(inputs=img_input, outputs= [coarse_pred1, coarse_pred2, fine_pred], name='adaptative_inverse_concat_net')\n","\n","model.summary()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input (InputLayer)              (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 32, 32, 64)   256         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 32, 32, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","block1_conv3 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         block1_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv4 (Conv2D)           (None, 16, 16, 128)  147584      batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 16, 16, 128)  512         block1_conv4[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","block1_conv5 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 8, 8, 256)    1024        block1_conv5[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv6 (Conv2D)           (None, 8, 8, 256)    590080      batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 8, 8, 256)    1024        block1_conv6[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","block1_conv7 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 4, 4, 512)    2048        block1_conv7[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv8 (Conv2D)           (None, 4, 4, 512)    2359808     batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 4, 4, 512)    2048        block1_conv8[0][0]               \n","__________________________________________________________________________________________________\n","c2_flatten (Flatten)            (None, 4096)         0           block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 8192)         0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","c1_flatten (Flatten)            (None, 8192)         0           block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","c2_fc_1 (Dense)                 (None, 512)          2097664     c2_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","fc_1 (Dense)                    (None, 1024)         8389632     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","c1_fc_1 (Dense)                 (None, 256)          2097408     c1_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 512)          2048        c2_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 1024)         4096        fc_1[0][0]                       \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 256)          1024        c1_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 512)          0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 1024)         0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 256)          0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","dropout_15 (Dropout)            (None, 512)          0           activation_15[0][0]              \n","__________________________________________________________________________________________________\n","dropout_17 (Dropout)            (None, 1024)         0           activation_17[0][0]              \n","__________________________________________________________________________________________________\n","dropout_13 (Dropout)            (None, 256)          0           activation_13[0][0]              \n","__________________________________________________________________________________________________\n","c2_fc_2 (Dense)                 (None, 512)          262656      dropout_15[0][0]                 \n","__________________________________________________________________________________________________\n","fc_2 (Dense)                    (None, 1024)         1049600     dropout_17[0][0]                 \n","__________________________________________________________________________________________________\n","c1_fc_2 (Dense)                 (None, 256)          65792       dropout_13[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 512)          2048        c2_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 1024)         4096        fc_2[0][0]                       \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 256)          1024        c1_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 512)          0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 1024)         0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 256)          0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","dropout_16 (Dropout)            (None, 512)          0           activation_16[0][0]              \n","__________________________________________________________________________________________________\n","dropout_18 (Dropout)            (None, 1024)         0           activation_18[0][0]              \n","__________________________________________________________________________________________________\n","dropout_14 (Dropout)            (None, 256)          0           activation_14[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 1536)         0           dropout_16[0][0]                 \n","                                                                 dropout_18[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 1792)         0           dropout_14[0][0]                 \n","                                                                 concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","predictions_coarse1 (Dense)     (None, 9)            16137       concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","predictions_coarse2 (Dense)     (None, 19)           29203       concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","predictions_fine (Dense)        (None, 100)          102500      dropout_18[0][0]                 \n","==================================================================================================\n","Total params: 18,817,984\n","Trainable params: 18,806,976\n","Non-trainable params: 11,008\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"kyk-6ImMfk37","colab_type":"code","colab":{}},"cell_type":"code","source":["alpha = K.variable(value=0.9, dtype=\"float32\", name=\"alpha\") \n","beta = K.variable(value=0.1, dtype=\"float32\", name=\"beta\") \n","gamma = K.variable(value=0, dtype=\"float32\", name=\"gamma\") \n","\n","sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=sgd,\n","              loss_weights=[alpha, beta, gamma],\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gnv5m8Pdfk4d","colab_type":"code","colab":{}},"cell_type":"code","source":["clr_cb = ReduceLROnPlateau(monitor='val_predictions_fine_loss', factor=0.5, patience=10, verbose=1, min_lr=3.125e-05)\n","time_cb = TimingCallback()\n","change_lw = AdaptativeLossWeightsModifier3Vars(alpha, beta, gamma, decay_rate=0.1)\n","csv_cb = CSVLogger('drive/TCC-ITAU/cifar-100/training-data/concat-net/adaptative-inverse-concat-net.csv', separator=',', append=False)\n","\n","\n","cbks = [clr_cb, time_cb, change_lw, csv_cb]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JKWSYhQ2fk5D","colab_type":"code","outputId":"7c5e0f5a-26ec-422f-926f-762564ce17d4","executionInfo":{"status":"ok","timestamp":1544231597170,"user_tz":120,"elapsed":1875119,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":2879}},"cell_type":"code","source":["epochs = 50\n","start_time = time()\n","training = model.fit(train_features, [y_train_c_cat1, y_train_c_cat2, y_train_cat],\n","                     validation_data=(vali_features, [y_val_c_cat1, y_val_c_cat2, y_val_cat]),\n","                     epochs=epochs,\n","                     batch_size=256, \n","                     callbacks=cbks,\n","                     verbose=1)\n","training_time = time() - start_time"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train on 45000 samples, validate on 5000 samples\n","Epoch 1/50\n","45000/45000 [==============================] - 41s 914us/step - loss: 2.2258 - predictions_coarse1_loss: 2.0975 - predictions_coarse2_loss: 3.3805 - predictions_fine_loss: 5.4520 - predictions_coarse1_acc: 0.3294 - predictions_coarse2_acc: 0.0872 - predictions_fine_acc: 0.0101 - val_loss: 1.8884 - val_predictions_coarse1_loss: 1.7937 - val_predictions_coarse2_loss: 2.7410 - val_predictions_fine_loss: 4.8971 - val_predictions_coarse1_acc: 0.4220 - val_predictions_coarse2_acc: 0.1726 - val_predictions_fine_acc: 0.0128\n","Epoch 2/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.8443 - predictions_coarse1_loss: 1.7193 - predictions_coarse2_loss: 2.9695 - predictions_fine_loss: 5.3806 - predictions_coarse1_acc: 0.4344 - predictions_coarse2_acc: 0.1462 - predictions_fine_acc: 0.0102 - val_loss: 1.6303 - val_predictions_coarse1_loss: 1.5314 - val_predictions_coarse2_loss: 2.5203 - val_predictions_fine_loss: 4.8236 - val_predictions_coarse1_acc: 0.4832 - val_predictions_coarse2_acc: 0.2446 - val_predictions_fine_acc: 0.0128\n","Changing loss weights to: coarse1 = 0.8832973837852478, coarse2 = 0.1167026162147522, fine = 0.0\n","Epoch 3/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 1.7021 - predictions_coarse1_loss: 1.5624 - predictions_coarse2_loss: 2.7597 - predictions_fine_loss: 5.3530 - predictions_coarse1_acc: 0.4793 - predictions_coarse2_acc: 0.1958 - predictions_fine_acc: 0.0097 - val_loss: 1.5611 - val_predictions_coarse1_loss: 1.4555 - val_predictions_coarse2_loss: 2.3605 - val_predictions_fine_loss: 4.7883 - val_predictions_coarse1_acc: 0.5100 - val_predictions_coarse2_acc: 0.2864 - val_predictions_fine_acc: 0.0108\n","Changing loss weights to: coarse1 = 0.7065358757972717, coarse2 = 0.29346412420272827, fine = 0.0\n","Epoch 4/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.7662 - predictions_coarse1_loss: 1.4466 - predictions_coarse2_loss: 2.5356 - predictions_fine_loss: 5.3414 - predictions_coarse1_acc: 0.5186 - predictions_coarse2_acc: 0.2501 - predictions_fine_acc: 0.0094 - val_loss: 1.6204 - val_predictions_coarse1_loss: 1.3773 - val_predictions_coarse2_loss: 2.2056 - val_predictions_fine_loss: 4.7904 - val_predictions_coarse1_acc: 0.5348 - val_predictions_coarse2_acc: 0.3240 - val_predictions_fine_acc: 0.0102\n","Changing loss weights to: coarse1 = 0.5069384574890137, coarse2 = 0.49306154251098633, fine = 0.0\n","Epoch 5/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 1.8362 - predictions_coarse1_loss: 1.3723 - predictions_coarse2_loss: 2.3131 - predictions_fine_loss: 5.3405 - predictions_coarse1_acc: 0.5416 - predictions_coarse2_acc: 0.3032 - predictions_fine_acc: 0.0103 - val_loss: 1.6854 - val_predictions_coarse1_loss: 1.3301 - val_predictions_coarse2_loss: 2.0508 - val_predictions_fine_loss: 4.7788 - val_predictions_coarse1_acc: 0.5544 - val_predictions_coarse2_acc: 0.3674 - val_predictions_fine_acc: 0.0140\n","Changing loss weights to: coarse1 = 0.3194962441921234, coarse2 = 0.680503785610199, fine = 0.0\n","Epoch 6/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.8656 - predictions_coarse1_loss: 1.3064 - predictions_coarse2_loss: 2.1282 - predictions_fine_loss: 5.3415 - predictions_coarse1_acc: 0.5676 - predictions_coarse2_acc: 0.3514 - predictions_fine_acc: 0.0104 - val_loss: 1.8067 - val_predictions_coarse1_loss: 1.3474 - val_predictions_coarse2_loss: 2.0223 - val_predictions_fine_loss: 4.7646 - val_predictions_coarse1_acc: 0.5536 - val_predictions_coarse2_acc: 0.3740 - val_predictions_fine_acc: 0.0162\n","Changing loss weights to: coarse1 = 0.16867117583751678, coarse2 = 0.831328809261322, fine = 0.0\n","Epoch 7/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 1.8669 - predictions_coarse1_loss: 1.2646 - predictions_coarse2_loss: 1.9891 - predictions_fine_loss: 5.3432 - predictions_coarse1_acc: 0.5778 - predictions_coarse2_acc: 0.3871 - predictions_fine_acc: 0.0104 - val_loss: 1.7865 - val_predictions_coarse1_loss: 1.2572 - val_predictions_coarse2_loss: 1.8939 - val_predictions_fine_loss: 4.8192 - val_predictions_coarse1_acc: 0.5794 - val_predictions_coarse2_acc: 0.4166 - val_predictions_fine_acc: 0.0118\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0, fine = 0.0\n","Epoch 8/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.8737 - predictions_coarse1_loss: 1.2371 - predictions_coarse2_loss: 1.8737 - predictions_fine_loss: 5.3543 - predictions_coarse1_acc: 0.5858 - predictions_coarse2_acc: 0.4169 - predictions_fine_acc: 0.0103 - val_loss: 1.9189 - val_predictions_coarse1_loss: 1.3482 - val_predictions_coarse2_loss: 1.9189 - val_predictions_fine_loss: 4.8400 - val_predictions_coarse1_acc: 0.5462 - val_predictions_coarse2_acc: 0.4250 - val_predictions_fine_acc: 0.0138\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8778373599052429, fine = 0.12216263264417648\n","Epoch 9/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 2.1732 - predictions_coarse1_loss: 1.2180 - predictions_coarse2_loss: 1.7623 - predictions_fine_loss: 5.1264 - predictions_coarse1_acc: 0.5974 - predictions_coarse2_acc: 0.4469 - predictions_fine_acc: 0.0148 - val_loss: 2.1104 - val_predictions_coarse1_loss: 1.2289 - val_predictions_coarse2_loss: 1.7853 - val_predictions_fine_loss: 4.4465 - val_predictions_coarse1_acc: 0.5946 - val_predictions_coarse2_acc: 0.4386 - val_predictions_fine_acc: 0.0508\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8106169104576111, fine = 0.18938305974006653\n","Epoch 10/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 2.2543 - predictions_coarse1_loss: 1.1901 - predictions_coarse2_loss: 1.6737 - predictions_fine_loss: 4.7397 - predictions_coarse1_acc: 0.6064 - predictions_coarse2_acc: 0.4736 - predictions_fine_acc: 0.0340 - val_loss: 2.1348 - val_predictions_coarse1_loss: 1.1593 - val_predictions_coarse2_loss: 1.6647 - val_predictions_fine_loss: 4.1470 - val_predictions_coarse1_acc: 0.6200 - val_predictions_coarse2_acc: 0.4802 - val_predictions_fine_acc: 0.1054\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.7338957190513611, fine = 0.2661042809486389\n","Epoch 11/50\n","45000/45000 [==============================] - 36s 809us/step - loss: 2.3404 - predictions_coarse1_loss: 1.1720 - predictions_coarse2_loss: 1.6040 - predictions_fine_loss: 4.3716 - predictions_coarse1_acc: 0.6087 - predictions_coarse2_acc: 0.4934 - predictions_fine_acc: 0.0671 - val_loss: 2.2025 - val_predictions_coarse1_loss: 1.1425 - val_predictions_coarse2_loss: 1.6220 - val_predictions_fine_loss: 3.8035 - val_predictions_coarse1_acc: 0.6220 - val_predictions_coarse2_acc: 0.4954 - val_predictions_fine_acc: 0.1630\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.6431335210800171, fine = 0.3568665087223053\n","Epoch 12/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 2.4387 - predictions_coarse1_loss: 1.1571 - predictions_coarse2_loss: 1.5526 - predictions_fine_loss: 4.0354 - predictions_coarse1_acc: 0.6139 - predictions_coarse2_acc: 0.5087 - predictions_fine_acc: 0.1072 - val_loss: 2.3287 - val_predictions_coarse1_loss: 1.1731 - val_predictions_coarse2_loss: 1.6427 - val_predictions_fine_loss: 3.5650 - val_predictions_coarse1_acc: 0.6080 - val_predictions_coarse2_acc: 0.4880 - val_predictions_fine_acc: 0.2076\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.5458559989929199, fine = 0.4541440010070801\n","Epoch 13/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.5094 - predictions_coarse1_loss: 1.1483 - predictions_coarse2_loss: 1.5029 - predictions_fine_loss: 3.7192 - predictions_coarse1_acc: 0.6159 - predictions_coarse2_acc: 0.5228 - predictions_fine_acc: 0.1490 - val_loss: 2.3328 - val_predictions_coarse1_loss: 1.1040 - val_predictions_coarse2_loss: 1.5450 - val_predictions_fine_loss: 3.2797 - val_predictions_coarse1_acc: 0.6370 - val_predictions_coarse2_acc: 0.5212 - val_predictions_fine_acc: 0.2548\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.4457547664642334, fine = 0.5542452335357666\n","Epoch 14/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.5675 - predictions_coarse1_loss: 1.1502 - predictions_coarse2_loss: 1.4779 - predictions_fine_loss: 3.4439 - predictions_coarse1_acc: 0.6158 - predictions_coarse2_acc: 0.5285 - predictions_fine_acc: 0.1891 - val_loss: 2.4150 - val_predictions_coarse1_loss: 1.1119 - val_predictions_coarse2_loss: 1.5974 - val_predictions_fine_loss: 3.0725 - val_predictions_coarse1_acc: 0.6268 - val_predictions_coarse2_acc: 0.5070 - val_predictions_fine_acc: 0.2728\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.3497125208377838, fine = 0.6502875089645386\n","Epoch 15/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.5864 - predictions_coarse1_loss: 1.1395 - predictions_coarse2_loss: 1.4411 - predictions_fine_loss: 3.2023 - predictions_coarse1_acc: 0.6166 - predictions_coarse2_acc: 0.5400 - predictions_fine_acc: 0.2236 - val_loss: 2.4122 - val_predictions_coarse1_loss: 1.1038 - val_predictions_coarse2_loss: 1.5234 - val_predictions_fine_loss: 2.8902 - val_predictions_coarse1_acc: 0.6278 - val_predictions_coarse2_acc: 0.5284 - val_predictions_fine_acc: 0.3086\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.2587946355342865, fine = 0.7412053346633911\n","Epoch 16/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 2.5886 - predictions_coarse1_loss: 1.1483 - predictions_coarse2_loss: 1.4248 - predictions_fine_loss: 2.9949 - predictions_coarse1_acc: 0.6166 - predictions_coarse2_acc: 0.5448 - predictions_fine_acc: 0.2588 - val_loss: 2.5655 - val_predictions_coarse1_loss: 1.2091 - val_predictions_coarse2_loss: 1.6496 - val_predictions_fine_loss: 2.8853 - val_predictions_coarse1_acc: 0.5864 - val_predictions_coarse2_acc: 0.4888 - val_predictions_fine_acc: 0.3010\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.18495656549930573, fine = 0.8150434494018555\n","Epoch 17/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 2.5650 - predictions_coarse1_loss: 1.1372 - predictions_coarse2_loss: 1.4029 - predictions_fine_loss: 2.8287 - predictions_coarse1_acc: 0.6193 - predictions_coarse2_acc: 0.5500 - predictions_fine_acc: 0.2862 - val_loss: 2.5050 - val_predictions_coarse1_loss: 1.0836 - val_predictions_coarse2_loss: 1.5695 - val_predictions_fine_loss: 2.7173 - val_predictions_coarse1_acc: 0.6414 - val_predictions_coarse2_acc: 0.5162 - val_predictions_fine_acc: 0.3172\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.12329479306936264, fine = 0.8767052292823792\n","Epoch 18/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.5223 - predictions_coarse1_loss: 1.1359 - predictions_coarse2_loss: 1.3915 - predictions_fine_loss: 2.6813 - predictions_coarse1_acc: 0.6210 - predictions_coarse2_acc: 0.5550 - predictions_fine_acc: 0.3119 - val_loss: 2.5906 - val_predictions_coarse1_loss: 1.1652 - val_predictions_coarse2_loss: 1.6293 - val_predictions_fine_loss: 2.7257 - val_predictions_coarse1_acc: 0.6072 - val_predictions_coarse2_acc: 0.4918 - val_predictions_fine_acc: 0.3310\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.07971212267875671, fine = 0.9202878475189209\n","Epoch 19/50\n","45000/45000 [==============================] - 36s 811us/step - loss: 2.4616 - predictions_coarse1_loss: 1.1307 - predictions_coarse2_loss: 1.3641 - predictions_fine_loss: 2.5567 - predictions_coarse1_acc: 0.6216 - predictions_coarse2_acc: 0.5607 - predictions_fine_acc: 0.3382 - val_loss: 2.4175 - val_predictions_coarse1_loss: 1.0783 - val_predictions_coarse2_loss: 1.4792 - val_predictions_fine_loss: 2.4987 - val_predictions_coarse1_acc: 0.6486 - val_predictions_coarse2_acc: 0.5370 - val_predictions_fine_acc: 0.3758\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.048030413687229156, fine = 0.951969563961029\n","Epoch 20/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 2.3842 - predictions_coarse1_loss: 1.1315 - predictions_coarse2_loss: 1.3525 - predictions_fine_loss: 2.4363 - predictions_coarse1_acc: 0.6178 - predictions_coarse2_acc: 0.5649 - predictions_fine_acc: 0.3632 - val_loss: 2.4135 - val_predictions_coarse1_loss: 1.1021 - val_predictions_coarse2_loss: 1.4843 - val_predictions_fine_loss: 2.4604 - val_predictions_coarse1_acc: 0.6364 - val_predictions_coarse2_acc: 0.5390 - val_predictions_fine_acc: 0.3772\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.028778083622455597, fine = 0.971221923828125\n","Epoch 21/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 2.2869 - predictions_coarse1_loss: 1.1334 - predictions_coarse2_loss: 1.3225 - predictions_fine_loss: 2.3155 - predictions_coarse1_acc: 0.6196 - predictions_coarse2_acc: 0.5767 - predictions_fine_acc: 0.3873 - val_loss: 2.3946 - val_predictions_coarse1_loss: 1.0928 - val_predictions_coarse2_loss: 1.4529 - val_predictions_fine_loss: 2.4225 - val_predictions_coarse1_acc: 0.6472 - val_predictions_coarse2_acc: 0.5440 - val_predictions_fine_acc: 0.3868\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.015550853684544563, fine = 0.9844491481781006\n","Epoch 22/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.1925 - predictions_coarse1_loss: 1.1294 - predictions_coarse2_loss: 1.3070 - predictions_fine_loss: 2.2065 - predictions_coarse1_acc: 0.6226 - predictions_coarse2_acc: 0.5760 - predictions_fine_acc: 0.4108 - val_loss: 2.3328 - val_predictions_coarse1_loss: 1.0936 - val_predictions_coarse2_loss: 1.4364 - val_predictions_fine_loss: 2.3469 - val_predictions_coarse1_acc: 0.6362 - val_predictions_coarse2_acc: 0.5478 - val_predictions_fine_acc: 0.3986\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.008247863501310349, fine = 0.9917521476745605\n","Epoch 23/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 2.0997 - predictions_coarse1_loss: 1.1186 - predictions_coarse2_loss: 1.2844 - predictions_fine_loss: 2.1065 - predictions_coarse1_acc: 0.6245 - predictions_coarse2_acc: 0.5840 - predictions_fine_acc: 0.4348 - val_loss: 2.2818 - val_predictions_coarse1_loss: 1.0876 - val_predictions_coarse2_loss: 1.4180 - val_predictions_fine_loss: 2.2890 - val_predictions_coarse1_acc: 0.6498 - val_predictions_coarse2_acc: 0.5508 - val_predictions_fine_acc: 0.4180\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.003931823652237654, fine = 0.9960681796073914\n","Epoch 24/50\n","45000/45000 [==============================] - 37s 817us/step - loss: 2.0014 - predictions_coarse1_loss: 1.1138 - predictions_coarse2_loss: 1.2706 - predictions_fine_loss: 2.0043 - predictions_coarse1_acc: 0.6251 - predictions_coarse2_acc: 0.5865 - predictions_fine_acc: 0.4580 - val_loss: 2.2480 - val_predictions_coarse1_loss: 1.0653 - val_predictions_coarse2_loss: 1.3985 - val_predictions_fine_loss: 2.2514 - val_predictions_coarse1_acc: 0.6546 - val_predictions_coarse2_acc: 0.5626 - val_predictions_fine_acc: 0.4214\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0018168319948017597, fine = 0.9981831908226013\n","Epoch 25/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.9072 - predictions_coarse1_loss: 1.1023 - predictions_coarse2_loss: 1.2490 - predictions_fine_loss: 1.9084 - predictions_coarse1_acc: 0.6289 - predictions_coarse2_acc: 0.5946 - predictions_fine_acc: 0.4791 - val_loss: 2.2538 - val_predictions_coarse1_loss: 1.0792 - val_predictions_coarse2_loss: 1.4089 - val_predictions_fine_loss: 2.2554 - val_predictions_coarse1_acc: 0.6450 - val_predictions_coarse2_acc: 0.5522 - val_predictions_fine_acc: 0.4178\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0007269743946380913, fine = 0.9992730021476746\n","Epoch 26/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.8150 - predictions_coarse1_loss: 1.1045 - predictions_coarse2_loss: 1.2293 - predictions_fine_loss: 1.8155 - predictions_coarse1_acc: 0.6299 - predictions_coarse2_acc: 0.6006 - predictions_fine_acc: 0.5032 - val_loss: 2.2251 - val_predictions_coarse1_loss: 1.0776 - val_predictions_coarse2_loss: 1.4029 - val_predictions_fine_loss: 2.2257 - val_predictions_coarse1_acc: 0.6484 - val_predictions_coarse2_acc: 0.5558 - val_predictions_fine_acc: 0.4274\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0002800228539854288, fine = 0.9997199773788452\n","Epoch 27/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 1.7253 - predictions_coarse1_loss: 1.0967 - predictions_coarse2_loss: 1.2007 - predictions_fine_loss: 1.7254 - predictions_coarse1_acc: 0.6324 - predictions_coarse2_acc: 0.6099 - predictions_fine_acc: 0.5237 - val_loss: 2.1491 - val_predictions_coarse1_loss: 1.0603 - val_predictions_coarse2_loss: 1.3600 - val_predictions_fine_loss: 2.1493 - val_predictions_coarse1_acc: 0.6556 - val_predictions_coarse2_acc: 0.5644 - val_predictions_fine_acc: 0.4472\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.677321941126138e-05, fine = 0.9999032020568848\n","Epoch 28/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 1.6364 - predictions_coarse1_loss: 1.0904 - predictions_coarse2_loss: 1.1940 - predictions_fine_loss: 1.6365 - predictions_coarse1_acc: 0.6364 - predictions_coarse2_acc: 0.6104 - predictions_fine_acc: 0.5467 - val_loss: 2.1296 - val_predictions_coarse1_loss: 1.0710 - val_predictions_coarse2_loss: 1.3696 - val_predictions_fine_loss: 2.1296 - val_predictions_coarse1_acc: 0.6578 - val_predictions_coarse2_acc: 0.5676 - val_predictions_fine_acc: 0.4450\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.249988003517501e-05, fine = 0.9999675154685974\n","Epoch 29/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 1.5571 - predictions_coarse1_loss: 1.0827 - predictions_coarse2_loss: 1.1614 - predictions_fine_loss: 1.5571 - predictions_coarse1_acc: 0.6376 - predictions_coarse2_acc: 0.6212 - predictions_fine_acc: 0.5661 - val_loss: 2.1627 - val_predictions_coarse1_loss: 1.0737 - val_predictions_coarse2_loss: 1.3923 - val_predictions_fine_loss: 2.1628 - val_predictions_coarse1_acc: 0.6514 - val_predictions_coarse2_acc: 0.5606 - val_predictions_fine_acc: 0.4362\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 7.914193702163175e-06, fine = 0.9999920725822449\n","Epoch 30/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.4625 - predictions_coarse1_loss: 1.0801 - predictions_coarse2_loss: 1.1400 - predictions_fine_loss: 1.4625 - predictions_coarse1_acc: 0.6402 - predictions_coarse2_acc: 0.6280 - predictions_fine_acc: 0.5908 - val_loss: 2.1335 - val_predictions_coarse1_loss: 1.0807 - val_predictions_coarse2_loss: 1.3782 - val_predictions_fine_loss: 2.1335 - val_predictions_coarse1_acc: 0.6580 - val_predictions_coarse2_acc: 0.5614 - val_predictions_fine_acc: 0.4462\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.311181560799014e-06, fine = 0.9999976754188538\n","Epoch 31/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 1.3752 - predictions_coarse1_loss: 1.0655 - predictions_coarse2_loss: 1.1233 - predictions_fine_loss: 1.3752 - predictions_coarse1_acc: 0.6449 - predictions_coarse2_acc: 0.6355 - predictions_fine_acc: 0.6117 - val_loss: 2.0941 - val_predictions_coarse1_loss: 1.0663 - val_predictions_coarse2_loss: 1.3646 - val_predictions_fine_loss: 2.0941 - val_predictions_coarse1_acc: 0.6600 - val_predictions_coarse2_acc: 0.5722 - val_predictions_fine_acc: 0.4510\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.4953958422411233e-07, fine = 0.9999995231628418\n","Epoch 32/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.2940 - predictions_coarse1_loss: 1.0655 - predictions_coarse2_loss: 1.1060 - predictions_fine_loss: 1.2940 - predictions_coarse1_acc: 0.6471 - predictions_coarse2_acc: 0.6432 - predictions_fine_acc: 0.6342 - val_loss: 2.1286 - val_predictions_coarse1_loss: 1.0924 - val_predictions_coarse2_loss: 1.3892 - val_predictions_fine_loss: 2.1286 - val_predictions_coarse1_acc: 0.6472 - val_predictions_coarse2_acc: 0.5660 - val_predictions_fine_acc: 0.4552\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 7.107878019496638e-08, fine = 0.9999999403953552\n","Epoch 33/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 1.2176 - predictions_coarse1_loss: 1.0576 - predictions_coarse2_loss: 1.0895 - predictions_fine_loss: 1.2176 - predictions_coarse1_acc: 0.6494 - predictions_coarse2_acc: 0.6457 - predictions_fine_acc: 0.6565 - val_loss: 2.0784 - val_predictions_coarse1_loss: 1.0814 - val_predictions_coarse2_loss: 1.3576 - val_predictions_fine_loss: 2.0784 - val_predictions_coarse1_acc: 0.6632 - val_predictions_coarse2_acc: 0.5686 - val_predictions_fine_acc: 0.4516\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.59375690001707e-09, fine = 1.0\n","Epoch 34/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 1.1347 - predictions_coarse1_loss: 1.0475 - predictions_coarse2_loss: 1.0637 - predictions_fine_loss: 1.1347 - predictions_coarse1_acc: 0.6530 - predictions_coarse2_acc: 0.6566 - predictions_fine_acc: 0.6794 - val_loss: 2.0954 - val_predictions_coarse1_loss: 1.0786 - val_predictions_coarse2_loss: 1.3560 - val_predictions_fine_loss: 2.0954 - val_predictions_coarse1_acc: 0.6554 - val_predictions_coarse2_acc: 0.5722 - val_predictions_fine_acc: 0.4588\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0563939722985083e-09, fine = 1.0\n","Epoch 35/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 1.0538 - predictions_coarse1_loss: 1.0425 - predictions_coarse2_loss: 1.0508 - predictions_fine_loss: 1.0538 - predictions_coarse1_acc: 0.6560 - predictions_coarse2_acc: 0.6606 - predictions_fine_acc: 0.7021 - val_loss: 2.0525 - val_predictions_coarse1_loss: 1.0788 - val_predictions_coarse2_loss: 1.3437 - val_predictions_fine_loss: 2.0525 - val_predictions_coarse1_acc: 0.6596 - val_predictions_coarse2_acc: 0.5760 - val_predictions_fine_acc: 0.4638\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.218655699916312e-11, fine = 1.0\n","Epoch 36/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 0.9812 - predictions_coarse1_loss: 1.0381 - predictions_coarse2_loss: 1.0354 - predictions_fine_loss: 0.9812 - predictions_coarse1_acc: 0.6559 - predictions_coarse2_acc: 0.6650 - predictions_fine_acc: 0.7227 - val_loss: 2.0733 - val_predictions_coarse1_loss: 1.0767 - val_predictions_coarse2_loss: 1.3497 - val_predictions_fine_loss: 2.0733 - val_predictions_coarse1_acc: 0.6662 - val_predictions_coarse2_acc: 0.5746 - val_predictions_fine_acc: 0.4590\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.293727699777872e-12, fine = 1.0\n","Epoch 37/50\n","45000/45000 [==============================] - 37s 816us/step - loss: 0.9121 - predictions_coarse1_loss: 1.0340 - predictions_coarse2_loss: 1.0146 - predictions_fine_loss: 0.9121 - predictions_coarse1_acc: 0.6594 - predictions_coarse2_acc: 0.6730 - predictions_fine_acc: 0.7458 - val_loss: 2.0904 - val_predictions_coarse1_loss: 1.0876 - val_predictions_coarse2_loss: 1.3776 - val_predictions_fine_loss: 2.0904 - val_predictions_coarse1_acc: 0.6548 - val_predictions_coarse2_acc: 0.5676 - val_predictions_fine_acc: 0.4574\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.6354994615552787e-13, fine = 1.0\n","Epoch 38/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 0.8416 - predictions_coarse1_loss: 1.0272 - predictions_coarse2_loss: 0.9957 - predictions_fine_loss: 0.8416 - predictions_coarse1_acc: 0.6622 - predictions_coarse2_acc: 0.6802 - predictions_fine_acc: 0.7661 - val_loss: 2.0647 - val_predictions_coarse1_loss: 1.0918 - val_predictions_coarse2_loss: 1.3490 - val_predictions_fine_loss: 2.0647 - val_predictions_coarse1_acc: 0.6598 - val_predictions_coarse2_acc: 0.5794 - val_predictions_fine_acc: 0.4672\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 5.018873923905544e-15, fine = 1.0\n","Epoch 39/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 0.7705 - predictions_coarse1_loss: 1.0285 - predictions_coarse2_loss: 0.9808 - predictions_fine_loss: 0.7705 - predictions_coarse1_acc: 0.6607 - predictions_coarse2_acc: 0.6829 - predictions_fine_acc: 0.7880 - val_loss: 2.0549 - val_predictions_coarse1_loss: 1.0891 - val_predictions_coarse2_loss: 1.3509 - val_predictions_fine_loss: 2.0549 - val_predictions_coarse1_acc: 0.6612 - val_predictions_coarse2_acc: 0.5788 - val_predictions_fine_acc: 0.4718\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 7.798570141388279e-17, fine = 1.0\n","Epoch 40/50\n","45000/45000 [==============================] - 37s 817us/step - loss: 0.7106 - predictions_coarse1_loss: 1.0205 - predictions_coarse2_loss: 0.9672 - predictions_fine_loss: 0.7106 - predictions_coarse1_acc: 0.6641 - predictions_coarse2_acc: 0.6911 - predictions_fine_acc: 0.8068 - val_loss: 2.0646 - val_predictions_coarse1_loss: 1.0767 - val_predictions_coarse2_loss: 1.3476 - val_predictions_fine_loss: 2.0646 - val_predictions_coarse1_acc: 0.6624 - val_predictions_coarse2_acc: 0.5812 - val_predictions_fine_acc: 0.4666\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.700281673867592e-19, fine = 1.0\n","Epoch 41/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 0.6523 - predictions_coarse1_loss: 1.0125 - predictions_coarse2_loss: 0.9522 - predictions_fine_loss: 0.6523 - predictions_coarse1_acc: 0.6657 - predictions_coarse2_acc: 0.6948 - predictions_fine_acc: 0.8260 - val_loss: 2.0711 - val_predictions_coarse1_loss: 1.1001 - val_predictions_coarse2_loss: 1.3654 - val_predictions_fine_loss: 2.0711 - val_predictions_coarse1_acc: 0.6596 - val_predictions_coarse2_acc: 0.5724 - val_predictions_fine_acc: 0.4680\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.0421310158603054e-21, fine = 1.0\n","Epoch 42/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 0.5984 - predictions_coarse1_loss: 1.0124 - predictions_coarse2_loss: 0.9460 - predictions_fine_loss: 0.5984 - predictions_coarse1_acc: 0.6679 - predictions_coarse2_acc: 0.7007 - predictions_fine_acc: 0.8436 - val_loss: 2.1071 - val_predictions_coarse1_loss: 1.1169 - val_predictions_coarse2_loss: 1.3864 - val_predictions_fine_loss: 2.1071 - val_predictions_coarse1_acc: 0.6490 - val_predictions_coarse2_acc: 0.5718 - val_predictions_fine_acc: 0.4672\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.061893315928661e-24, fine = 1.0\n","Epoch 43/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 0.5484 - predictions_coarse1_loss: 1.0165 - predictions_coarse2_loss: 0.9288 - predictions_fine_loss: 0.5484 - predictions_coarse1_acc: 0.6658 - predictions_coarse2_acc: 0.7068 - predictions_fine_acc: 0.8593 - val_loss: 2.0975 - val_predictions_coarse1_loss: 1.1052 - val_predictions_coarse2_loss: 1.3623 - val_predictions_fine_loss: 2.0975 - val_predictions_coarse1_acc: 0.6554 - val_predictions_coarse2_acc: 0.5810 - val_predictions_fine_acc: 0.4666\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.128143536677157e-27, fine = 1.0\n","Epoch 44/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 0.4990 - predictions_coarse1_loss: 1.0072 - predictions_coarse2_loss: 0.9155 - predictions_fine_loss: 0.4990 - predictions_coarse1_acc: 0.6674 - predictions_coarse2_acc: 0.7140 - predictions_fine_acc: 0.8740 - val_loss: 2.0945 - val_predictions_coarse1_loss: 1.0953 - val_predictions_coarse2_loss: 1.3520 - val_predictions_fine_loss: 2.0945 - val_predictions_coarse1_acc: 0.6536 - val_predictions_coarse2_acc: 0.5760 - val_predictions_fine_acc: 0.4716\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 8.936599881787414e-31, fine = 1.0\n","Epoch 45/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 0.4624 - predictions_coarse1_loss: 1.0083 - predictions_coarse2_loss: 0.9077 - predictions_fine_loss: 0.4624 - predictions_coarse1_acc: 0.6696 - predictions_coarse2_acc: 0.7163 - predictions_fine_acc: 0.8844 - val_loss: 2.1637 - val_predictions_coarse1_loss: 1.1010 - val_predictions_coarse2_loss: 1.3771 - val_predictions_fine_loss: 2.1637 - val_predictions_coarse1_acc: 0.6468 - val_predictions_coarse2_acc: 0.5708 - val_predictions_fine_acc: 0.4650\n","\n","Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 6.584458711705968e-35, fine = 1.0\n","Epoch 46/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 0.3872 - predictions_coarse1_loss: 0.9910 - predictions_coarse2_loss: 0.8742 - predictions_fine_loss: 0.3872 - predictions_coarse1_acc: 0.6755 - predictions_coarse2_acc: 0.7295 - predictions_fine_acc: 0.9116 - val_loss: 2.1000 - val_predictions_coarse1_loss: 1.1059 - val_predictions_coarse2_loss: 1.3549 - val_predictions_fine_loss: 2.1000 - val_predictions_coarse1_acc: 0.6468 - val_predictions_coarse2_acc: 0.5788 - val_predictions_fine_acc: 0.4638\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.3361891783944285e-39, fine = 1.0\n","Epoch 47/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 0.3460 - predictions_coarse1_loss: 0.9902 - predictions_coarse2_loss: 0.8578 - predictions_fine_loss: 0.3460 - predictions_coarse1_acc: 0.6763 - predictions_coarse2_acc: 0.7387 - predictions_fine_acc: 0.9252 - val_loss: 2.0860 - val_predictions_coarse1_loss: 1.1026 - val_predictions_coarse2_loss: 1.3517 - val_predictions_fine_loss: 2.0860 - val_predictions_coarse1_acc: 0.6506 - val_predictions_coarse2_acc: 0.5792 - val_predictions_fine_acc: 0.4732\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0, fine = 1.0\n","Epoch 48/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 0.3305 - predictions_coarse1_loss: 0.9912 - predictions_coarse2_loss: 0.8533 - predictions_fine_loss: 0.3305 - predictions_coarse1_acc: 0.6756 - predictions_coarse2_acc: 0.7413 - predictions_fine_acc: 0.9286 - val_loss: 2.1129 - val_predictions_coarse1_loss: 1.1046 - val_predictions_coarse2_loss: 1.3593 - val_predictions_fine_loss: 2.1129 - val_predictions_coarse1_acc: 0.6522 - val_predictions_coarse2_acc: 0.5798 - val_predictions_fine_acc: 0.4648\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0, fine = 1.0\n","Epoch 49/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 0.3049 - predictions_coarse1_loss: 0.9874 - predictions_coarse2_loss: 0.8508 - predictions_fine_loss: 0.3049 - predictions_coarse1_acc: 0.6782 - predictions_coarse2_acc: 0.7410 - predictions_fine_acc: 0.9360 - val_loss: 2.0983 - val_predictions_coarse1_loss: 1.1051 - val_predictions_coarse2_loss: 1.3482 - val_predictions_fine_loss: 2.0983 - val_predictions_coarse1_acc: 0.6510 - val_predictions_coarse2_acc: 0.5792 - val_predictions_fine_acc: 0.4746\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0, fine = 1.0\n","Epoch 50/50\n","45000/45000 [==============================] - 37s 814us/step - loss: 0.2963 - predictions_coarse1_loss: 0.9874 - predictions_coarse2_loss: 0.8390 - predictions_fine_loss: 0.2963 - predictions_coarse1_acc: 0.6779 - predictions_coarse2_acc: 0.7457 - predictions_fine_acc: 0.9401 - val_loss: 2.1019 - val_predictions_coarse1_loss: 1.1075 - val_predictions_coarse2_loss: 1.3618 - val_predictions_fine_loss: 2.1019 - val_predictions_coarse1_acc: 0.6546 - val_predictions_coarse2_acc: 0.5782 - val_predictions_fine_acc: 0.4680\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0, fine = 1.0\n"],"name":"stdout"}]},{"metadata":{"id":"nS5DnAtyfk5P","colab_type":"code","outputId":"08978f61-511b-4565-f8b8-5caec302ced4","executionInfo":{"status":"ok","timestamp":1544231619698,"user_tz":120,"elapsed":6381,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"cell_type":"code","source":["model.evaluate(test_features, [y_test_c_cat1,y_test_c_cat2, y_test_cat])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 6s 575us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[2.0417761869430544,\n"," 1.0897213447570802,\n"," 1.3542106847763062,\n"," 2.0417761869430544,\n"," 0.6714,\n"," 0.5768,\n"," 0.4882]"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"9FfKMwTxfk56","colab_type":"code","outputId":"589b9e0d-a7f6-4f90-bb1d-079967df0147","executionInfo":{"status":"ok","timestamp":1544231642390,"user_tz":120,"elapsed":836,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["print('Total training time: {}'.format(training_time))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Total training time: 1874.2980651855469\n"],"name":"stdout"}]},{"metadata":{"id":"CDU9_2B6fk6E","colab_type":"code","outputId":"9bf24bb8-f4b4-4f36-a60b-50080ee673e0","executionInfo":{"status":"error","timestamp":1544231665790,"user_tz":120,"elapsed":11770,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":1111}},"cell_type":"code","source":["model.save('drive/TCC-ITAU/cifar-100/models/adaptative-inverse-concat-net.h5')"],"execution_count":26,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-b48413ff5c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/TCC-ITAU/cifar-100/models/adaptative-inverse-concat-net.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;34m'sample_weight_mode'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0;34m'loss_weights'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             }, default=get_json_type).encode('utf8')\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msymbolic_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Not JSON Serializable: <tf.Variable 'alpha_2:0' shape=() dtype=float32_ref>"]}]},{"metadata":{"id":"8pGBC_BGfk6V","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}