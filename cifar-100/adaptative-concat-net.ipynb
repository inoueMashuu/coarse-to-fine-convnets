{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adaptative-concat-net.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"eUKnB3_Kf2nw","colab_type":"text"},"cell_type":"markdown","source":["## Adaptative Concat-net"]},{"metadata":{"id":"g4kw7gLefk1I","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z49ZaCkofk1U","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q9i0kVvPfk1i","colab_type":"text"},"cell_type":"markdown","source":["## Loading the data"]},{"metadata":{"id":"eKoyWRCOfk1l","colab_type":"code","outputId":"3c39c646-afae-4f9b-d5b2-427b8136ce19","executionInfo":{"status":"ok","timestamp":1544209673113,"user_tz":120,"elapsed":1944,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["from time import time\n","import os\n","import gzip\n","import numpy as np\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import cifar100"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"r295GDqKfk10","colab_type":"code","colab":{}},"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n","                                                  test_size=0.1, \n","                                                  random_state=1974,\n","                                                  stratify = y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fu3pH4M4fk15","colab_type":"code","colab":{}},"cell_type":"code","source":["train_features = X_train.reshape(X_train.shape[0], 32, 32, 3)/255\n","vali_features = X_val.reshape(X_val.shape[0], 32, 32, 3)/255\n","test_features = X_test.reshape(X_test.shape[0], 32, 32, 3)/255\n","\n","y_train_cat = np_utils.to_categorical(y_train)\n","y_val_cat = np_utils.to_categorical(y_val)\n","y_test_cat = np_utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3ED5tc9Cfk2H","colab_type":"text"},"cell_type":"markdown","source":["## Defining coarse labels"]},{"metadata":{"id":"uIT8HRXGfk2L","colab_type":"code","colab":{}},"cell_type":"code","source":["dict_coarse2 = {0: 4,  1: 1,  2: 14,  3: 8,  4: 12,  5: 6,  6: 7,  7: 7,  8: 18,  9: 3,  10: 3,\n","                11: 14,  12: 9,  13: 18,  14: 7,  15: 11,  16: 3,  17: 9,  18: 7,  19: 11,  20: 6,\n","                21: 11,  22: 5,  23: 10,  24: 7,  25: 6,  26: 13,  27: 15,  28: 3,  29: 15,  30: 0,\n","                31: 11,  32: 1,  33: 10,  34: 12,  35: 14,  36: 16,  37: 9,  38: 11,  39: 5,  40: 5,\n","                41: 18,  42: 8,  43: 8,  44: 15,  45: 13,  46: 14,  47: 17,  48: 18,  49: 10,  50: 16,\n","                51: 4,  52: 17,  53: 4,  54: 2,  55: 12,  56: 17,  57: 4,  58: 18,  59: 17,  60: 10,\n","                61: 3,  62: 2,  63: 12,  64: 12,  65: 16,  66: 12,  67: 1,  68: 9,  69: 18,  70: 2,\n","                71: 10,  72: 12,  73: 1,  74: 16,  75: 12,  76: 9,  77: 13,  78: 15,  79: 13,  80: 16,\n","                81: 18,  82: 2,  83: 4,  84: 6,  85: 18,  86: 5,  87: 5,  88: 8,  89: 18,  90: 18,\n","                91: 1,  92: 2,  93: 15,  94: 6,  95: 0,  96: 17,  97: 8,  98: 14,  99: 13}\n","\n","\n","dict_coarse1 = {0: 0,\n","              1: 0,\n","              2: 1,\n","              3: 2,\n","              4: 1,\n","              5: 2,\n","              6: 2,\n","              7: 3,\n","              8: 4,\n","              9: 5,\n","              10: 5,\n","              11: 4,\n","              12: 4,\n","              13: 3,\n","              14: 6,\n","              15: 7,\n","              16: 4,\n","              17: 1,\n","              18: 8}\n","\n","y_train_coarse2 = np.vectorize(dict_coarse2.get)(y_train)\n","y_val_coarse2 = np.vectorize(dict_coarse2.get)(y_val)\n","y_test_coarse2 = np.vectorize(dict_coarse2.get)(y_test)\n","\n","y_train_coarse1 = np.vectorize(dict_coarse1.get)(y_train_coarse2)\n","y_val_coarse1 = np.vectorize(dict_coarse1.get)(y_val_coarse2)\n","y_test_coarse1 = np.vectorize(dict_coarse1.get)(y_test_coarse2)\n","\n","\n","y_train_c_cat1 = np_utils.to_categorical(y_train_coarse1)\n","y_val_c_cat1 = np_utils.to_categorical(y_val_coarse1)\n","y_test_c_cat1 = np_utils.to_categorical(y_test_coarse1)\n","\n","y_train_c_cat2 = np_utils.to_categorical(y_train_coarse2)\n","y_val_c_cat2 = np_utils.to_categorical(y_val_coarse2)\n","y_test_c_cat2 = np_utils.to_categorical(y_test_coarse2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aH6u_LmMfk2W","colab_type":"text"},"cell_type":"markdown","source":["## Training the model"]},{"metadata":{"id":"YCg3M4BJfk2a","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, Input\n","from keras import optimizers\n","from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger\n","from keras.layers.normalization import BatchNormalization\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bYV1g0qbfk2x","colab_type":"code","colab":{}},"cell_type":"code","source":["class TimingCallback(keras.callbacks.Callback):\n","  \"\"\"Callback that saves the time elapsed of each epoch to the log.\n","  \"\"\"  \n","  def on_epoch_begin(self, epoch, logs={}):\n","    self.starttime=time()\n","  def on_epoch_end(self, epoch, logs={}):\n","    logs['time_elapsed'] = (time()-self.starttime)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J8sBqu1Afk27","colab_type":"code","colab":{}},"cell_type":"code","source":["class AdaptativeLossWeightsModifier3Vars(keras.callbacks.Callback):\n","  def __init__(self, alpha, beta, gamma, decay_rate=0.5):\n","    self.alpha = alpha\n","    self.beta = beta\n","    self.gamma = gamma\n","    self.decay_rate = decay_rate\n","    self.offset_epoch = 0\n","    self.par_reduce = [0, 1]\n","  \n","  def calculate_exponential(self, ratio, decay_rate, epoch):\n","    return np.exp(-ratio*decay_rate*epoch)\n","\n","  def on_epoch_end(self, epoch, logs={}):\n","    list_vars = [K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)]\n","    if epoch < 1:\n","      pass\n","    \n","    else:\n","      loss_coarse1 = self.model.history.history['predictions_coarse1_loss'][-1]\n","      loss_coarse2 = self.model.history.history['predictions_coarse2_loss'][-1]\n","      loss_fine = self.model.history.history['predictions_fine_loss'][-1]\n","      \n","      losses_classes = [loss_coarse1, loss_coarse2, loss_fine]\n","      ratio = losses_classes[self.par_reduce[0]] / losses_classes[self.par_reduce[1]] *(epoch + 1 - self.offset_epoch) \n","      \n","      decaying = self.calculate_exponential(ratio, self.decay_rate/(max(self.par_reduce)**2), epoch)\n","      increasing = 1 - decaying\n","    \n","    \n","      if (1 - increasing) < 0.1 and (self.par_reduce[1] < len(list_vars) - 1):\n","        list_vars[self.par_reduce[0]] = 0\n","        list_vars[self.par_reduce[1]] = 1\n","        self.par_reduce = [i + 1 for i in self.par_reduce]\n","        self.offset_epoch = self.offset_epoch + epoch\n","\n","      else:\n","       list_vars[self.par_reduce[0]] = decaying\n","       list_vars[self.par_reduce[1]] = increasing\n","\n","        \n","      K.set_value(self.alpha, list_vars[0])\n","      K.set_value(self.beta, list_vars[1])\n","      K.set_value(self.gamma, list_vars[2])\n","        \n","      print('Changing loss weights to: coarse1 = {}, coarse2 = {}, fine = {}'.format(K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)))\n","    \n","    logs['alpha'] = K.eval(self.alpha)\n","    logs['beta'] = K.eval(self.beta) \n","    logs['gamma'] = K.eval(self.gamma) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"JyX0adEjfk3N","colab_type":"code","colab":{}},"cell_type":"code","source":["img_rows, img_cols = 32, 32\n","input_shape = (img_rows, img_cols, 3)\n","\n","num_classes_coarse1 = 9\n","num_classes_coarse2 = 19\n","num_classes_fine = 100\n","\n","img_input = Input(shape=input_shape, name='input')\n","\n","\n","\n","x = Conv2D(64, (3, 3), activation='relu', name='block1_conv1', padding='same')(img_input)\n","x = BatchNormalization()(x)\n","x = Conv2D(64, (3, 3), activation='relu', name='block1_conv2', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block1_pool')(x)\n","\n","x = Conv2D(128, (3, 3), activation='relu', name='block1_conv3', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(128, (3, 3), activation='relu', name='block1_conv4', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block2_pool')(x)\n","\n","\n","#---- coarse branch 1 ----\n","coarse1 = Flatten(name='c1_flatten')(x)\n","coarse1 = Dense(256, name='c1_fc_1')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","coarse1 = Dense(256, name='c1_fc_2')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","coarse_pred1 = Dense(num_classes_coarse1, activation='softmax', name='predictions_coarse1')(coarse1)\n","\n","\n","x = Conv2D(256, (3, 3), activation='relu', name='block1_conv5', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(256, (3, 3), activation='relu', name='block1_conv6', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block3_pool')(x)\n","\n","\n","#---- coarse branch 2 ----\n","coarse2 = Flatten(name='c2_flatten')(x)\n","coarse2 = Dense(512, name='c2_fc_1')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","coarse2 = Dense(512, name='c2_fc_2')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","coarse2 = keras.layers.concatenate([coarse2, coarse1])\n","coarse_pred2 = Dense(num_classes_coarse2, activation='softmax', name='predictions_coarse2')(coarse2)\n","\n","\n","x = Conv2D(512, (3, 3), activation='relu', name='block1_conv7', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(512, (3, 3), activation='relu', name='block1_conv8', padding='same')(x)\n","x = BatchNormalization()(x)\n","\n","\n","x = Flatten(name='flatten')(x)\n","x = Dense(1024, name='fc_1')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","\n","x = Dense(1024, name='fc_2')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","\n","x = keras.layers.concatenate([x, coarse2])\n","fine_pred = Dense(num_classes_fine, activation='softmax', name='predictions_fine')(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"taLUCrQIfk3X","colab_type":"code","outputId":"a2f2b9bf-0365-4f9b-f582-309587d7a419","executionInfo":{"status":"ok","timestamp":1544215538853,"user_tz":120,"elapsed":789,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":2150}},"cell_type":"code","source":["model = Model(inputs=img_input, outputs= [coarse_pred1, coarse_pred2, fine_pred], name='adaptative_concat_net')\n","\n","model.summary()"],"execution_count":43,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input (InputLayer)              (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 32, 32, 64)   256         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 32, 32, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","block1_conv3 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 16, 16, 128)  512         block1_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv4 (Conv2D)           (None, 16, 16, 128)  147584      batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 16, 16, 128)  512         block1_conv4[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","block1_conv5 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 8, 8, 256)    1024        block1_conv5[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv6 (Conv2D)           (None, 8, 8, 256)    590080      batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 8, 8, 256)    1024        block1_conv6[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","block1_conv7 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 4, 4, 512)    2048        block1_conv7[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv8 (Conv2D)           (None, 4, 4, 512)    2359808     batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","c1_flatten (Flatten)            (None, 8192)         0           block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","c2_flatten (Flatten)            (None, 4096)         0           block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 4, 4, 512)    2048        block1_conv8[0][0]               \n","__________________________________________________________________________________________________\n","c1_fc_1 (Dense)                 (None, 256)          2097408     c1_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","c2_fc_1 (Dense)                 (None, 512)          2097664     c2_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 8192)         0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 256)          1024        c1_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 512)          2048        c2_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","fc_1 (Dense)                    (None, 1024)         8389632     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 256)          0           batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 512)          0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 1024)         4096        fc_1[0][0]                       \n","__________________________________________________________________________________________________\n","dropout_31 (Dropout)            (None, 256)          0           activation_31[0][0]              \n","__________________________________________________________________________________________________\n","dropout_33 (Dropout)            (None, 512)          0           activation_33[0][0]              \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 1024)         0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","c1_fc_2 (Dense)                 (None, 256)          65792       dropout_31[0][0]                 \n","__________________________________________________________________________________________________\n","c2_fc_2 (Dense)                 (None, 512)          262656      dropout_33[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_35 (Dropout)            (None, 1024)         0           activation_35[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 256)          1024        c1_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 512)          2048        c2_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","fc_2 (Dense)                    (None, 1024)         1049600     dropout_35[0][0]                 \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 256)          0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 512)          0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 1024)         4096        fc_2[0][0]                       \n","__________________________________________________________________________________________________\n","dropout_32 (Dropout)            (None, 256)          0           activation_32[0][0]              \n","__________________________________________________________________________________________________\n","dropout_34 (Dropout)            (None, 512)          0           activation_34[0][0]              \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 1024)         0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_11 (Concatenate)    (None, 768)          0           dropout_34[0][0]                 \n","                                                                 dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","dropout_36 (Dropout)            (None, 1024)         0           activation_36[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_12 (Concatenate)    (None, 1792)         0           dropout_36[0][0]                 \n","                                                                 concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","predictions_coarse1 (Dense)     (None, 9)            2313        dropout_32[0][0]                 \n","__________________________________________________________________________________________________\n","predictions_coarse2 (Dense)     (None, 19)           14611       concatenate_11[0][0]             \n","__________________________________________________________________________________________________\n","predictions_fine (Dense)        (None, 100)          179300      concatenate_12[0][0]             \n","==================================================================================================\n","Total params: 18,866,368\n","Trainable params: 18,855,360\n","Non-trainable params: 11,008\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"kyk-6ImMfk37","colab_type":"code","colab":{}},"cell_type":"code","source":["alpha = K.variable(value=0.9, dtype=\"float32\", name=\"alpha\") \n","beta = K.variable(value=0.1, dtype=\"float32\", name=\"beta\") \n","gamma = K.variable(value=0, dtype=\"float32\", name=\"gamma\") \n","\n","sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=sgd,\n","              loss_weights=[alpha, beta, gamma],\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gnv5m8Pdfk4d","colab_type":"code","colab":{}},"cell_type":"code","source":["clr_cb = ReduceLROnPlateau(monitor='val_predictions_fine_loss', factor=0.5, patience=10, verbose=1, min_lr=3.125e-05)\n","time_cb = TimingCallback()\n","change_lw = AdaptativeLossWeightsModifier3Vars(alpha, beta, gamma, decay_rate=0.05)\n","csv_cb = CSVLogger('drive/TCC-ITAU/cifar-100/training-data/concat-net/adaptative-concat-net.csv', separator=',', append=False)\n","\n","\n","cbks = [clr_cb, time_cb, change_lw, csv_cb]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JKWSYhQ2fk5D","colab_type":"code","outputId":"057cff26-d034-40e8-e733-6c2b9319bb11","executionInfo":{"status":"ok","timestamp":1544217431798,"user_tz":120,"elapsed":1882531,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":2842}},"cell_type":"code","source":["epochs = 50\n","start_time = time()\n","training = model.fit(train_features, [y_train_c_cat1, y_train_c_cat2, y_train_cat],\n","                     validation_data=(vali_features, [y_val_c_cat1, y_val_c_cat2, y_val_cat]),\n","                     epochs=epochs,\n","                     batch_size=256, \n","                     callbacks=cbks,\n","                     verbose=1)\n","training_time = time() - start_time"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Train on 45000 samples, validate on 5000 samples\n","Epoch 1/50\n","45000/45000 [==============================] - 43s 953us/step - loss: 2.2623 - predictions_coarse1_loss: 2.1264 - predictions_coarse2_loss: 3.4852 - predictions_fine_loss: 5.5151 - predictions_coarse1_acc: 0.3039 - predictions_coarse2_acc: 0.0779 - predictions_fine_acc: 0.0091 - val_loss: 1.8258 - val_predictions_coarse1_loss: 1.7247 - val_predictions_coarse2_loss: 2.7361 - val_predictions_fine_loss: 4.8916 - val_predictions_coarse1_acc: 0.4248 - val_predictions_coarse2_acc: 0.1700 - val_predictions_fine_acc: 0.0076\n","Epoch 2/50\n","45000/45000 [==============================] - 36s 806us/step - loss: 1.9175 - predictions_coarse1_loss: 1.7842 - predictions_coarse2_loss: 3.1172 - predictions_fine_loss: 5.5051 - predictions_coarse1_acc: 0.4022 - predictions_coarse2_acc: 0.1222 - predictions_fine_acc: 0.0091 - val_loss: 1.6966 - val_predictions_coarse1_loss: 1.6004 - val_predictions_coarse2_loss: 2.5628 - val_predictions_fine_loss: 4.8388 - val_predictions_coarse1_acc: 0.4626 - val_predictions_coarse2_acc: 0.2242 - val_predictions_fine_acc: 0.0094\n","Changing loss weights to: coarse1 = 0.940811038017273, coarse2 = 0.05918896943330765, fine = 0.0\n","Epoch 3/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 1.7381 - predictions_coarse1_loss: 1.6614 - predictions_coarse2_loss: 2.9582 - predictions_fine_loss: 5.5115 - predictions_coarse1_acc: 0.4430 - predictions_coarse2_acc: 0.1542 - predictions_fine_acc: 0.0098 - val_loss: 1.5527 - val_predictions_coarse1_loss: 1.4937 - val_predictions_coarse2_loss: 2.4902 - val_predictions_fine_loss: 4.8205 - val_predictions_coarse1_acc: 0.4980 - val_predictions_coarse2_acc: 0.2416 - val_predictions_fine_acc: 0.0102\n","Changing loss weights to: coarse1 = 0.8422201871871948, coarse2 = 0.15777984261512756, fine = 0.0\n","Epoch 4/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 1.7759 - predictions_coarse1_loss: 1.5790 - predictions_coarse2_loss: 2.8270 - predictions_fine_loss: 5.5016 - predictions_coarse1_acc: 0.4734 - predictions_coarse2_acc: 0.1830 - predictions_fine_acc: 0.0090 - val_loss: 1.5710 - val_predictions_coarse1_loss: 1.4264 - val_predictions_coarse2_loss: 2.3434 - val_predictions_fine_loss: 4.8370 - val_predictions_coarse1_acc: 0.5304 - val_predictions_coarse2_acc: 0.2952 - val_predictions_fine_acc: 0.0070\n","Changing loss weights to: coarse1 = 0.7139307260513306, coarse2 = 0.2860693037509918, fine = 0.0\n","Epoch 5/50\n","45000/45000 [==============================] - 36s 810us/step - loss: 1.8358 - predictions_coarse1_loss: 1.5125 - predictions_coarse2_loss: 2.6428 - predictions_fine_loss: 5.5017 - predictions_coarse1_acc: 0.4930 - predictions_coarse2_acc: 0.2251 - predictions_fine_acc: 0.0095 - val_loss: 1.6161 - val_predictions_coarse1_loss: 1.3794 - val_predictions_coarse2_loss: 2.2069 - val_predictions_fine_loss: 4.8249 - val_predictions_coarse1_acc: 0.5426 - val_predictions_coarse2_acc: 0.3274 - val_predictions_fine_acc: 0.0070\n","Changing loss weights to: coarse1 = 0.5720502734184265, coarse2 = 0.4279496967792511, fine = 0.0\n","Epoch 6/50\n","45000/45000 [==============================] - 36s 810us/step - loss: 1.8995 - predictions_coarse1_loss: 1.4688 - predictions_coarse2_loss: 2.4753 - predictions_fine_loss: 5.4948 - predictions_coarse1_acc: 0.5075 - predictions_coarse2_acc: 0.2630 - predictions_fine_acc: 0.0090 - val_loss: 1.6853 - val_predictions_coarse1_loss: 1.3667 - val_predictions_coarse2_loss: 2.1112 - val_predictions_fine_loss: 4.8256 - val_predictions_coarse1_acc: 0.5450 - val_predictions_coarse2_acc: 0.3526 - val_predictions_fine_acc: 0.0086\n","Changing loss weights to: coarse1 = 0.4238148331642151, coarse2 = 0.5761851668357849, fine = 0.0\n","Epoch 7/50\n","45000/45000 [==============================] - 36s 811us/step - loss: 1.9482 - predictions_coarse1_loss: 1.4320 - predictions_coarse2_loss: 2.3279 - predictions_fine_loss: 5.4947 - predictions_coarse1_acc: 0.5230 - predictions_coarse2_acc: 0.2969 - predictions_fine_acc: 0.0100 - val_loss: 1.7819 - val_predictions_coarse1_loss: 1.3943 - val_predictions_coarse2_loss: 2.0670 - val_predictions_fine_loss: 4.8216 - val_predictions_coarse1_acc: 0.5216 - val_predictions_coarse2_acc: 0.3574 - val_predictions_fine_acc: 0.0094\n","Changing loss weights to: coarse1 = 0.287635862827301, coarse2 = 0.712364137172699, fine = 0.0\n","Epoch 8/50\n","45000/45000 [==============================] - 36s 808us/step - loss: 1.9655 - predictions_coarse1_loss: 1.4079 - predictions_coarse2_loss: 2.1907 - predictions_fine_loss: 5.4970 - predictions_coarse1_acc: 0.5310 - predictions_coarse2_acc: 0.3308 - predictions_fine_acc: 0.0096 - val_loss: 1.7471 - val_predictions_coarse1_loss: 1.3112 - val_predictions_coarse2_loss: 1.9231 - val_predictions_fine_loss: 4.8069 - val_predictions_coarse1_acc: 0.5714 - val_predictions_coarse2_acc: 0.4048 - val_predictions_fine_acc: 0.0072\n","Changing loss weights to: coarse1 = 0.1786343902349472, coarse2 = 0.8213655948638916, fine = 0.0\n","Epoch 9/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 1.9536 - predictions_coarse1_loss: 1.3853 - predictions_coarse2_loss: 2.0772 - predictions_fine_loss: 5.5010 - predictions_coarse1_acc: 0.5389 - predictions_coarse2_acc: 0.3592 - predictions_fine_acc: 0.0096 - val_loss: 1.9412 - val_predictions_coarse1_loss: 1.3835 - val_predictions_coarse2_loss: 2.0625 - val_predictions_fine_loss: 4.8509 - val_predictions_coarse1_acc: 0.5322 - val_predictions_coarse2_acc: 0.3694 - val_predictions_fine_acc: 0.0094\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0, fine = 0.0\n","Epoch 10/50\n","45000/45000 [==============================] - 36s 810us/step - loss: 1.9783 - predictions_coarse1_loss: 1.3751 - predictions_coarse2_loss: 1.9783 - predictions_fine_loss: 5.4911 - predictions_coarse1_acc: 0.5414 - predictions_coarse2_acc: 0.3865 - predictions_fine_acc: 0.0101 - val_loss: 1.8833 - val_predictions_coarse1_loss: 1.3179 - val_predictions_coarse2_loss: 1.8833 - val_predictions_fine_loss: 4.8090 - val_predictions_coarse1_acc: 0.5610 - val_predictions_coarse2_acc: 0.4100 - val_predictions_fine_acc: 0.0092\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.9185487031936646, fine = 0.08145129680633545\n","Epoch 11/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 2.1746 - predictions_coarse1_loss: 1.3733 - predictions_coarse2_loss: 1.8971 - predictions_fine_loss: 5.3042 - predictions_coarse1_acc: 0.5409 - predictions_coarse2_acc: 0.4071 - predictions_fine_acc: 0.0128 - val_loss: 2.0510 - val_predictions_coarse1_loss: 1.2931 - val_predictions_coarse2_loss: 1.8340 - val_predictions_fine_loss: 4.4983 - val_predictions_coarse1_acc: 0.5702 - val_predictions_coarse2_acc: 0.4344 - val_predictions_fine_acc: 0.0310\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8736292123794556, fine = 0.12637080252170563\n","Epoch 12/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 2.2155 - predictions_coarse1_loss: 1.3661 - predictions_coarse2_loss: 1.8259 - predictions_fine_loss: 4.9088 - predictions_coarse1_acc: 0.5433 - predictions_coarse2_acc: 0.4250 - predictions_fine_acc: 0.0287 - val_loss: 2.0863 - val_predictions_coarse1_loss: 1.3016 - val_predictions_coarse2_loss: 1.7824 - val_predictions_fine_loss: 4.1869 - val_predictions_coarse1_acc: 0.5696 - val_predictions_coarse2_acc: 0.4496 - val_predictions_fine_acc: 0.0794\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8214278221130371, fine = 0.1785721778869629\n","Epoch 13/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 2.2599 - predictions_coarse1_loss: 1.3500 - predictions_coarse2_loss: 1.7656 - predictions_fine_loss: 4.5339 - predictions_coarse1_acc: 0.5461 - predictions_coarse2_acc: 0.4423 - predictions_fine_acc: 0.0532 - val_loss: 2.0871 - val_predictions_coarse1_loss: 1.2695 - val_predictions_coarse2_loss: 1.6948 - val_predictions_fine_loss: 3.8921 - val_predictions_coarse1_acc: 0.5918 - val_predictions_coarse2_acc: 0.4652 - val_predictions_fine_acc: 0.1358\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.756565272808075, fine = 0.24343474209308624\n","Epoch 14/50\n","45000/45000 [==============================] - 36s 810us/step - loss: 2.3202 - predictions_coarse1_loss: 1.3509 - predictions_coarse2_loss: 1.7148 - predictions_fine_loss: 4.2019 - predictions_coarse1_acc: 0.5452 - predictions_coarse2_acc: 0.4573 - predictions_fine_acc: 0.0881 - val_loss: 2.1016 - val_predictions_coarse1_loss: 1.2293 - val_predictions_coarse2_loss: 1.6225 - val_predictions_fine_loss: 3.5904 - val_predictions_coarse1_acc: 0.6062 - val_predictions_coarse2_acc: 0.4954 - val_predictions_fine_acc: 0.1840\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.6840843558311462, fine = 0.31591564416885376\n","Epoch 15/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 2.3839 - predictions_coarse1_loss: 1.3397 - predictions_coarse2_loss: 1.6738 - predictions_fine_loss: 3.9217 - predictions_coarse1_acc: 0.5521 - predictions_coarse2_acc: 0.4700 - predictions_fine_acc: 0.1208 - val_loss: 2.2058 - val_predictions_coarse1_loss: 1.2616 - val_predictions_coarse2_loss: 1.6508 - val_predictions_fine_loss: 3.4076 - val_predictions_coarse1_acc: 0.5826 - val_predictions_coarse2_acc: 0.4880 - val_predictions_fine_acc: 0.2244\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.6065812706947327, fine = 0.39341869950294495\n","Epoch 16/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 2.4321 - predictions_coarse1_loss: 1.3475 - predictions_coarse2_loss: 1.6330 - predictions_fine_loss: 3.6642 - predictions_coarse1_acc: 0.5484 - predictions_coarse2_acc: 0.4820 - predictions_fine_acc: 0.1549 - val_loss: 2.2372 - val_predictions_coarse1_loss: 1.2400 - val_predictions_coarse2_loss: 1.6108 - val_predictions_fine_loss: 3.2029 - val_predictions_coarse1_acc: 0.6034 - val_predictions_coarse2_acc: 0.4948 - val_predictions_fine_acc: 0.2472\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.5271825790405273, fine = 0.47281742095947266\n","Epoch 17/50\n","45000/45000 [==============================] - 37s 823us/step - loss: 2.4735 - predictions_coarse1_loss: 1.3354 - predictions_coarse2_loss: 1.6074 - predictions_fine_loss: 3.4392 - predictions_coarse1_acc: 0.5535 - predictions_coarse2_acc: 0.4876 - predictions_fine_acc: 0.1875 - val_loss: 2.2721 - val_predictions_coarse1_loss: 1.2388 - val_predictions_coarse2_loss: 1.5793 - val_predictions_fine_loss: 3.0446 - val_predictions_coarse1_acc: 0.6050 - val_predictions_coarse2_acc: 0.4986 - val_predictions_fine_acc: 0.2800\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.4483496844768524, fine = 0.55165034532547\n","Epoch 18/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.4934 - predictions_coarse1_loss: 1.3394 - predictions_coarse2_loss: 1.5798 - predictions_fine_loss: 3.2360 - predictions_coarse1_acc: 0.5513 - predictions_coarse2_acc: 0.4967 - predictions_fine_acc: 0.2206 - val_loss: 2.3010 - val_predictions_coarse1_loss: 1.2101 - val_predictions_coarse2_loss: 1.5699 - val_predictions_fine_loss: 2.8951 - val_predictions_coarse1_acc: 0.6066 - val_predictions_coarse2_acc: 0.5098 - val_predictions_fine_acc: 0.2896\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.3704017996788025, fine = 0.6295982003211975\n","Epoch 19/50\n","45000/45000 [==============================] - 36s 810us/step - loss: 2.5155 - predictions_coarse1_loss: 1.3343 - predictions_coarse2_loss: 1.5613 - predictions_fine_loss: 3.0769 - predictions_coarse1_acc: 0.5528 - predictions_coarse2_acc: 0.5005 - predictions_fine_acc: 0.2450 - val_loss: 2.3966 - val_predictions_coarse1_loss: 1.2264 - val_predictions_coarse2_loss: 1.6135 - val_predictions_fine_loss: 2.8573 - val_predictions_coarse1_acc: 0.6050 - val_predictions_coarse2_acc: 0.4920 - val_predictions_fine_acc: 0.2996\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.2987178862094879, fine = 0.7012820839881897\n","Epoch 20/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.5109 - predictions_coarse1_loss: 1.3399 - predictions_coarse2_loss: 1.5448 - predictions_fine_loss: 2.9224 - predictions_coarse1_acc: 0.5506 - predictions_coarse2_acc: 0.5084 - predictions_fine_acc: 0.2720 - val_loss: 2.4392 - val_predictions_coarse1_loss: 1.2617 - val_predictions_coarse2_loss: 1.5955 - val_predictions_fine_loss: 2.7987 - val_predictions_coarse1_acc: 0.5808 - val_predictions_coarse2_acc: 0.4976 - val_predictions_fine_acc: 0.3044\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.23547112941741943, fine = 0.7645288705825806\n","Epoch 21/50\n","45000/45000 [==============================] - 37s 829us/step - loss: 2.4845 - predictions_coarse1_loss: 1.3418 - predictions_coarse2_loss: 1.5278 - predictions_fine_loss: 2.7791 - predictions_coarse1_acc: 0.5496 - predictions_coarse2_acc: 0.5136 - predictions_fine_acc: 0.2976 - val_loss: 2.3482 - val_predictions_coarse1_loss: 1.2198 - val_predictions_coarse2_loss: 1.5106 - val_predictions_fine_loss: 2.6061 - val_predictions_coarse1_acc: 0.6088 - val_predictions_coarse2_acc: 0.5284 - val_predictions_fine_acc: 0.3512\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.17942243814468384, fine = 0.8205775618553162\n","Epoch 22/50\n","45000/45000 [==============================] - 36s 809us/step - loss: 2.4538 - predictions_coarse1_loss: 1.3341 - predictions_coarse2_loss: 1.5186 - predictions_fine_loss: 2.6583 - predictions_coarse1_acc: 0.5509 - predictions_coarse2_acc: 0.5150 - predictions_fine_acc: 0.3242 - val_loss: 2.3293 - val_predictions_coarse1_loss: 1.2331 - val_predictions_coarse2_loss: 1.4976 - val_predictions_fine_loss: 2.5111 - val_predictions_coarse1_acc: 0.6000 - val_predictions_coarse2_acc: 0.5284 - val_predictions_fine_acc: 0.3702\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.13260886073112488, fine = 0.8673911690711975\n","Epoch 23/50\n","45000/45000 [==============================] - 36s 809us/step - loss: 2.3996 - predictions_coarse1_loss: 1.3387 - predictions_coarse2_loss: 1.5039 - predictions_fine_loss: 2.5366 - predictions_coarse1_acc: 0.5504 - predictions_coarse2_acc: 0.5186 - predictions_fine_acc: 0.3453 - val_loss: 2.3109 - val_predictions_coarse1_loss: 1.2290 - val_predictions_coarse2_loss: 1.4853 - val_predictions_fine_loss: 2.4371 - val_predictions_coarse1_acc: 0.5992 - val_predictions_coarse2_acc: 0.5270 - val_predictions_fine_acc: 0.3746\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.094759501516819, fine = 0.9052404761314392\n","Epoch 24/50\n","45000/45000 [==============================] - 36s 810us/step - loss: 2.3367 - predictions_coarse1_loss: 1.3460 - predictions_coarse2_loss: 1.4977 - predictions_fine_loss: 2.4246 - predictions_coarse1_acc: 0.5473 - predictions_coarse2_acc: 0.5192 - predictions_fine_acc: 0.3684 - val_loss: 2.3437 - val_predictions_coarse1_loss: 1.2349 - val_predictions_coarse2_loss: 1.5008 - val_predictions_fine_loss: 2.4319 - val_predictions_coarse1_acc: 0.6032 - val_predictions_coarse2_acc: 0.5290 - val_predictions_fine_acc: 0.3770\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.06539767235517502, fine = 0.9346023201942444\n","Epoch 25/50\n","45000/45000 [==============================] - 36s 807us/step - loss: 2.2786 - predictions_coarse1_loss: 1.3405 - predictions_coarse2_loss: 1.4926 - predictions_fine_loss: 2.3336 - predictions_coarse1_acc: 0.5509 - predictions_coarse2_acc: 0.5226 - predictions_fine_acc: 0.3913 - val_loss: 2.2968 - val_predictions_coarse1_loss: 1.2103 - val_predictions_coarse2_loss: 1.4704 - val_predictions_fine_loss: 2.3546 - val_predictions_coarse1_acc: 0.6024 - val_predictions_coarse2_acc: 0.5406 - val_predictions_fine_acc: 0.3880\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.04284105822443962, fine = 0.9571589231491089\n","Epoch 26/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 2.2097 - predictions_coarse1_loss: 1.3407 - predictions_coarse2_loss: 1.4820 - predictions_fine_loss: 2.2423 - predictions_coarse1_acc: 0.5493 - predictions_coarse2_acc: 0.5245 - predictions_fine_acc: 0.4074 - val_loss: 2.2587 - val_predictions_coarse1_loss: 1.2330 - val_predictions_coarse2_loss: 1.4698 - val_predictions_fine_loss: 2.2940 - val_predictions_coarse1_acc: 0.6028 - val_predictions_coarse2_acc: 0.5396 - val_predictions_fine_acc: 0.4024\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.027383431792259216, fine = 0.9726165533065796\n","Epoch 27/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 2.1353 - predictions_coarse1_loss: 1.3372 - predictions_coarse2_loss: 1.4813 - predictions_fine_loss: 2.1537 - predictions_coarse1_acc: 0.5496 - predictions_coarse2_acc: 0.5234 - predictions_fine_acc: 0.4291 - val_loss: 2.2240 - val_predictions_coarse1_loss: 1.2181 - val_predictions_coarse2_loss: 1.4542 - val_predictions_fine_loss: 2.2456 - val_predictions_coarse1_acc: 0.6012 - val_predictions_coarse2_acc: 0.5418 - val_predictions_fine_acc: 0.4198\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.016883185133337975, fine = 0.9831168055534363\n","Epoch 28/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 2.0562 - predictions_coarse1_loss: 1.3423 - predictions_coarse2_loss: 1.4743 - predictions_fine_loss: 2.0662 - predictions_coarse1_acc: 0.5498 - predictions_coarse2_acc: 0.5262 - predictions_fine_acc: 0.4489 - val_loss: 2.1963 - val_predictions_coarse1_loss: 1.2202 - val_predictions_coarse2_loss: 1.4496 - val_predictions_fine_loss: 2.2091 - val_predictions_coarse1_acc: 0.6044 - val_predictions_coarse2_acc: 0.5434 - val_predictions_fine_acc: 0.4204\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.009633789770305157, fine = 0.9903662204742432\n","Epoch 29/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 1.9741 - predictions_coarse1_loss: 1.3408 - predictions_coarse2_loss: 1.4632 - predictions_fine_loss: 1.9791 - predictions_coarse1_acc: 0.5482 - predictions_coarse2_acc: 0.5283 - predictions_fine_acc: 0.4673 - val_loss: 2.1989 - val_predictions_coarse1_loss: 1.2264 - val_predictions_coarse2_loss: 1.4627 - val_predictions_fine_loss: 2.2061 - val_predictions_coarse1_acc: 0.6052 - val_predictions_coarse2_acc: 0.5362 - val_predictions_fine_acc: 0.4268\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.005277224816381931, fine = 0.9947227835655212\n","Epoch 30/50\n","45000/45000 [==============================] - 36s 811us/step - loss: 1.8995 - predictions_coarse1_loss: 1.3478 - predictions_coarse2_loss: 1.4663 - predictions_fine_loss: 1.9018 - predictions_coarse1_acc: 0.5451 - predictions_coarse2_acc: 0.5284 - predictions_fine_acc: 0.4868 - val_loss: 2.1065 - val_predictions_coarse1_loss: 1.2197 - val_predictions_coarse2_loss: 1.4215 - val_predictions_fine_loss: 2.1101 - val_predictions_coarse1_acc: 0.6046 - val_predictions_coarse2_acc: 0.5538 - val_predictions_fine_acc: 0.4438\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0027503392193466425, fine = 0.9972496628761292\n","Epoch 31/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 1.8236 - predictions_coarse1_loss: 1.3420 - predictions_coarse2_loss: 1.4582 - predictions_fine_loss: 1.8246 - predictions_coarse1_acc: 0.5476 - predictions_coarse2_acc: 0.5324 - predictions_fine_acc: 0.5059 - val_loss: 2.1348 - val_predictions_coarse1_loss: 1.2282 - val_predictions_coarse2_loss: 1.4399 - val_predictions_fine_loss: 2.1368 - val_predictions_coarse1_acc: 0.6030 - val_predictions_coarse2_acc: 0.5488 - val_predictions_fine_acc: 0.4388\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0012942146277055144, fine = 0.9987058043479919\n","Epoch 32/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 1.7479 - predictions_coarse1_loss: 1.3473 - predictions_coarse2_loss: 1.4575 - predictions_fine_loss: 1.7482 - predictions_coarse1_acc: 0.5456 - predictions_coarse2_acc: 0.5317 - predictions_fine_acc: 0.5209 - val_loss: 2.0613 - val_predictions_coarse1_loss: 1.2133 - val_predictions_coarse2_loss: 1.4155 - val_predictions_fine_loss: 2.0622 - val_predictions_coarse1_acc: 0.6088 - val_predictions_coarse2_acc: 0.5550 - val_predictions_fine_acc: 0.4532\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0005917535163462162, fine = 0.9994082450866699\n","Epoch 33/50\n","45000/45000 [==============================] - 36s 808us/step - loss: 1.6807 - predictions_coarse1_loss: 1.3515 - predictions_coarse2_loss: 1.4501 - predictions_fine_loss: 1.6809 - predictions_coarse1_acc: 0.5436 - predictions_coarse2_acc: 0.5325 - predictions_fine_acc: 0.5387 - val_loss: 2.0401 - val_predictions_coarse1_loss: 1.2136 - val_predictions_coarse2_loss: 1.4159 - val_predictions_fine_loss: 2.0405 - val_predictions_coarse1_acc: 0.6112 - val_predictions_coarse2_acc: 0.5576 - val_predictions_fine_acc: 0.4620\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.00023944451822899282, fine = 0.9997605681419373\n","Epoch 34/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 1.6072 - predictions_coarse1_loss: 1.3471 - predictions_coarse2_loss: 1.4446 - predictions_fine_loss: 1.6073 - predictions_coarse1_acc: 0.5473 - predictions_coarse2_acc: 0.5341 - predictions_fine_acc: 0.5575 - val_loss: 2.0503 - val_predictions_coarse1_loss: 1.2247 - val_predictions_coarse2_loss: 1.4317 - val_predictions_fine_loss: 2.0504 - val_predictions_coarse1_acc: 0.6052 - val_predictions_coarse2_acc: 0.5500 - val_predictions_fine_acc: 0.4580\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.585493535269052e-05, fine = 0.9999041557312012\n","Epoch 35/50\n","45000/45000 [==============================] - 38s 834us/step - loss: 1.5358 - predictions_coarse1_loss: 1.3464 - predictions_coarse2_loss: 1.4389 - predictions_fine_loss: 1.5358 - predictions_coarse1_acc: 0.5458 - predictions_coarse2_acc: 0.5373 - predictions_fine_acc: 0.5753 - val_loss: 1.9937 - val_predictions_coarse1_loss: 1.2114 - val_predictions_coarse2_loss: 1.3995 - val_predictions_fine_loss: 1.9937 - val_predictions_coarse1_acc: 0.6084 - val_predictions_coarse2_acc: 0.5606 - val_predictions_fine_acc: 0.4728\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.316854781587608e-05, fine = 0.9999668598175049\n","Epoch 36/50\n","45000/45000 [==============================] - 37s 825us/step - loss: 1.4599 - predictions_coarse1_loss: 1.3472 - predictions_coarse2_loss: 1.4372 - predictions_fine_loss: 1.4599 - predictions_coarse1_acc: 0.5458 - predictions_coarse2_acc: 0.5373 - predictions_fine_acc: 0.5983 - val_loss: 2.0047 - val_predictions_coarse1_loss: 1.2219 - val_predictions_coarse2_loss: 1.4120 - val_predictions_fine_loss: 2.0047 - val_predictions_coarse1_acc: 0.6052 - val_predictions_coarse2_acc: 0.5648 - val_predictions_fine_acc: 0.4678\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.036695630318718e-05, fine = 0.9999896287918091\n","Epoch 37/50\n","45000/45000 [==============================] - 37s 828us/step - loss: 1.3869 - predictions_coarse1_loss: 1.3511 - predictions_coarse2_loss: 1.4249 - predictions_fine_loss: 1.3869 - predictions_coarse1_acc: 0.5439 - predictions_coarse2_acc: 0.5405 - predictions_fine_acc: 0.6155 - val_loss: 1.9887 - val_predictions_coarse1_loss: 1.2104 - val_predictions_coarse2_loss: 1.4054 - val_predictions_fine_loss: 1.9887 - val_predictions_coarse1_acc: 0.6088 - val_predictions_coarse2_acc: 0.5632 - val_predictions_fine_acc: 0.4770\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.632946916492074e-06, fine = 0.9999973773956299\n","Epoch 38/50\n","45000/45000 [==============================] - 37s 827us/step - loss: 1.3264 - predictions_coarse1_loss: 1.3446 - predictions_coarse2_loss: 1.4228 - predictions_fine_loss: 1.3264 - predictions_coarse1_acc: 0.5478 - predictions_coarse2_acc: 0.5390 - predictions_fine_acc: 0.6306 - val_loss: 1.9844 - val_predictions_coarse1_loss: 1.2226 - val_predictions_coarse2_loss: 1.4112 - val_predictions_fine_loss: 1.9844 - val_predictions_coarse1_acc: 0.6064 - val_predictions_coarse2_acc: 0.5534 - val_predictions_fine_acc: 0.4736\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 6.438739887926204e-07, fine = 0.9999993443489075\n","Epoch 39/50\n","45000/45000 [==============================] - 37s 825us/step - loss: 1.2570 - predictions_coarse1_loss: 1.3529 - predictions_coarse2_loss: 1.4211 - predictions_fine_loss: 1.2570 - predictions_coarse1_acc: 0.5443 - predictions_coarse2_acc: 0.5415 - predictions_fine_acc: 0.6477 - val_loss: 1.9643 - val_predictions_coarse1_loss: 1.2221 - val_predictions_coarse2_loss: 1.4121 - val_predictions_fine_loss: 1.9643 - val_predictions_coarse1_acc: 0.6022 - val_predictions_coarse2_acc: 0.5564 - val_predictions_fine_acc: 0.4756\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.3801736997720582e-07, fine = 0.9999998807907104\n","Epoch 40/50\n","45000/45000 [==============================] - 37s 823us/step - loss: 1.1900 - predictions_coarse1_loss: 1.3477 - predictions_coarse2_loss: 1.4197 - predictions_fine_loss: 1.1900 - predictions_coarse1_acc: 0.5466 - predictions_coarse2_acc: 0.5399 - predictions_fine_acc: 0.6674 - val_loss: 1.9271 - val_predictions_coarse1_loss: 1.2364 - val_predictions_coarse2_loss: 1.4077 - val_predictions_fine_loss: 1.9271 - val_predictions_coarse1_acc: 0.6006 - val_predictions_coarse2_acc: 0.5648 - val_predictions_fine_acc: 0.4846\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.189710990307958e-08, fine = 1.0\n","Epoch 41/50\n","45000/45000 [==============================] - 37s 823us/step - loss: 1.1176 - predictions_coarse1_loss: 1.3492 - predictions_coarse2_loss: 1.4162 - predictions_fine_loss: 1.1176 - predictions_coarse1_acc: 0.5445 - predictions_coarse2_acc: 0.5424 - predictions_fine_acc: 0.6901 - val_loss: 1.9382 - val_predictions_coarse1_loss: 1.2171 - val_predictions_coarse2_loss: 1.3959 - val_predictions_fine_loss: 1.9382 - val_predictions_coarse1_acc: 0.6072 - val_predictions_coarse2_acc: 0.5632 - val_predictions_fine_acc: 0.4848\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.8241611271795364e-09, fine = 1.0\n","Epoch 42/50\n","45000/45000 [==============================] - 37s 820us/step - loss: 1.0531 - predictions_coarse1_loss: 1.3437 - predictions_coarse2_loss: 1.4111 - predictions_fine_loss: 1.0531 - predictions_coarse1_acc: 0.5460 - predictions_coarse2_acc: 0.5458 - predictions_fine_acc: 0.7081 - val_loss: 1.9100 - val_predictions_coarse1_loss: 1.2235 - val_predictions_coarse2_loss: 1.4023 - val_predictions_fine_loss: 1.9100 - val_predictions_coarse1_acc: 0.6054 - val_predictions_coarse2_acc: 0.5624 - val_predictions_fine_acc: 0.4898\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.5727384111995377e-10, fine = 1.0\n","Epoch 43/50\n","45000/45000 [==============================] - 37s 828us/step - loss: 0.9936 - predictions_coarse1_loss: 1.3489 - predictions_coarse2_loss: 1.4118 - predictions_fine_loss: 0.9936 - predictions_coarse1_acc: 0.5445 - predictions_coarse2_acc: 0.5427 - predictions_fine_acc: 0.7250 - val_loss: 1.9444 - val_predictions_coarse1_loss: 1.2231 - val_predictions_coarse2_loss: 1.4058 - val_predictions_fine_loss: 1.9444 - val_predictions_coarse1_acc: 0.6082 - val_predictions_coarse2_acc: 0.5596 - val_predictions_fine_acc: 0.4846\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 2.0273144274440824e-11, fine = 1.0\n","Epoch 44/50\n","45000/45000 [==============================] - 37s 823us/step - loss: 0.9235 - predictions_coarse1_loss: 1.3495 - predictions_coarse2_loss: 1.4041 - predictions_fine_loss: 0.9235 - predictions_coarse1_acc: 0.5443 - predictions_coarse2_acc: 0.5463 - predictions_fine_acc: 0.7455 - val_loss: 1.9007 - val_predictions_coarse1_loss: 1.2206 - val_predictions_coarse2_loss: 1.3919 - val_predictions_fine_loss: 1.9007 - val_predictions_coarse1_acc: 0.6074 - val_predictions_coarse2_acc: 0.5690 - val_predictions_fine_acc: 0.4902\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.1486030225896227e-12, fine = 1.0\n","Epoch 45/50\n","45000/45000 [==============================] - 37s 816us/step - loss: 0.8569 - predictions_coarse1_loss: 1.3489 - predictions_coarse2_loss: 1.3993 - predictions_fine_loss: 0.8569 - predictions_coarse1_acc: 0.5433 - predictions_coarse2_acc: 0.5467 - predictions_fine_acc: 0.7648 - val_loss: 1.8817 - val_predictions_coarse1_loss: 1.2176 - val_predictions_coarse2_loss: 1.3877 - val_predictions_fine_loss: 1.8817 - val_predictions_coarse1_acc: 0.6080 - val_predictions_coarse2_acc: 0.5668 - val_predictions_fine_acc: 0.5002\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.653584799609942e-14, fine = 1.0\n","Epoch 46/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 0.8059 - predictions_coarse1_loss: 1.3492 - predictions_coarse2_loss: 1.4035 - predictions_fine_loss: 0.8059 - predictions_coarse1_acc: 0.5437 - predictions_coarse2_acc: 0.5445 - predictions_fine_acc: 0.7814 - val_loss: 1.9128 - val_predictions_coarse1_loss: 1.2188 - val_predictions_coarse2_loss: 1.3941 - val_predictions_fine_loss: 1.9128 - val_predictions_coarse1_acc: 0.6082 - val_predictions_coarse2_acc: 0.5708 - val_predictions_fine_acc: 0.4872\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 6.929144025288739e-16, fine = 1.0\n","Epoch 47/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 0.7490 - predictions_coarse1_loss: 1.3521 - predictions_coarse2_loss: 1.3957 - predictions_fine_loss: 0.7490 - predictions_coarse1_acc: 0.5436 - predictions_coarse2_acc: 0.5493 - predictions_fine_acc: 0.7988 - val_loss: 1.8913 - val_predictions_coarse1_loss: 1.2237 - val_predictions_coarse2_loss: 1.3901 - val_predictions_fine_loss: 1.8913 - val_predictions_coarse1_acc: 0.6076 - val_predictions_coarse2_acc: 0.5688 - val_predictions_fine_acc: 0.5048\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0960946308702406e-17, fine = 1.0\n","Epoch 48/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 0.6942 - predictions_coarse1_loss: 1.3521 - predictions_coarse2_loss: 1.3871 - predictions_fine_loss: 0.6942 - predictions_coarse1_acc: 0.5433 - predictions_coarse2_acc: 0.5498 - predictions_fine_acc: 0.8152 - val_loss: 1.9046 - val_predictions_coarse1_loss: 1.2180 - val_predictions_coarse2_loss: 1.3931 - val_predictions_fine_loss: 1.9046 - val_predictions_coarse1_acc: 0.6044 - val_predictions_coarse2_acc: 0.5688 - val_predictions_fine_acc: 0.4978\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.572797731658239e-20, fine = 1.0\n","Epoch 49/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 0.6370 - predictions_coarse1_loss: 1.3497 - predictions_coarse2_loss: 1.3882 - predictions_fine_loss: 0.6370 - predictions_coarse1_acc: 0.5453 - predictions_coarse2_acc: 0.5517 - predictions_fine_acc: 0.8344 - val_loss: 1.8933 - val_predictions_coarse1_loss: 1.2186 - val_predictions_coarse2_loss: 1.3824 - val_predictions_fine_loss: 1.8933 - val_predictions_coarse1_acc: 0.6054 - val_predictions_coarse2_acc: 0.5684 - val_predictions_fine_acc: 0.5044\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.494811803011139e-22, fine = 1.0\n","Epoch 50/50\n","45000/45000 [==============================] - 37s 821us/step - loss: 0.5841 - predictions_coarse1_loss: 1.3502 - predictions_coarse2_loss: 1.3907 - predictions_fine_loss: 0.5841 - predictions_coarse1_acc: 0.5442 - predictions_coarse2_acc: 0.5492 - predictions_fine_acc: 0.8501 - val_loss: 1.9093 - val_predictions_coarse1_loss: 1.2288 - val_predictions_coarse2_loss: 1.3968 - val_predictions_fine_loss: 1.9093 - val_predictions_coarse1_acc: 0.6028 - val_predictions_coarse2_acc: 0.5632 - val_predictions_fine_acc: 0.5022\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.506888569272476e-25, fine = 1.0\n"],"name":"stdout"}]},{"metadata":{"id":"nS5DnAtyfk5P","colab_type":"code","outputId":"a73b23fb-3201-43e5-da42-469bf186ee40","executionInfo":{"status":"ok","timestamp":1544217446298,"user_tz":120,"elapsed":6680,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"cell_type":"code","source":["model.evaluate(test_features, [y_test_c_cat1,y_test_c_cat2, y_test_cat])"],"execution_count":47,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 6s 593us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.831979097366333,\n"," 1.1977967735290527,\n"," 1.3575804466247559,\n"," 1.831979097366333,\n"," 0.6151,\n"," 0.5737,\n"," 0.5143]"]},"metadata":{"tags":[]},"execution_count":47}]},{"metadata":{"id":"9FfKMwTxfk56","colab_type":"code","outputId":"f613edf8-78d8-419f-c7b0-06b406cb8e43","executionInfo":{"status":"ok","timestamp":1544217463367,"user_tz":120,"elapsed":812,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["print('Total training time: {}'.format(training_time))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Total training time: 1881.653599023819\n"],"name":"stdout"}]},{"metadata":{"id":"CDU9_2B6fk6E","colab_type":"code","outputId":"514b8538-cb53-4c41-e0e1-a12cc39b6160","executionInfo":{"status":"error","timestamp":1544217492860,"user_tz":120,"elapsed":18509,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":1111}},"cell_type":"code","source":["model.save('drive/TCC-ITAU/cifar-100/models/adaptative-concat-net.h5')"],"execution_count":49,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-372bd8dfbc3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/TCC-ITAU/cifar-100/models/adaptative-concat-net.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;34m'sample_weight_mode'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0;34m'loss_weights'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             }, default=get_json_type).encode('utf8')\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msymbolic_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Not JSON Serializable: <tf.Variable 'alpha_5:0' shape=() dtype=float32_ref>"]}]},{"metadata":{"id":"8pGBC_BGfk6V","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}