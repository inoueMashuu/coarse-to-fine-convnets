{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adaptative-branch-net.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"eUKnB3_Kf2nw","colab_type":"text"},"cell_type":"markdown","source":["## Adaptative Branch-net"]},{"metadata":{"id":"g4kw7gLefk1I","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z49ZaCkofk1U","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q9i0kVvPfk1i","colab_type":"text"},"cell_type":"markdown","source":["## Loading the data"]},{"metadata":{"id":"eKoyWRCOfk1l","colab_type":"code","outputId":"de79056a-dc53-41e0-83f3-18b01c756a0c","executionInfo":{"status":"ok","timestamp":1544221024130,"user_tz":120,"elapsed":1986,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["from time import time\n","import os\n","import gzip\n","import numpy as np\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","from keras.datasets import cifar100"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"r295GDqKfk10","colab_type":"code","colab":{}},"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n","                                                  test_size=0.1, \n","                                                  random_state=1974,\n","                                                  stratify = y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fu3pH4M4fk15","colab_type":"code","colab":{}},"cell_type":"code","source":["train_features = X_train.reshape(X_train.shape[0], 32, 32, 3)/255\n","vali_features = X_val.reshape(X_val.shape[0], 32, 32, 3)/255\n","test_features = X_test.reshape(X_test.shape[0], 32, 32, 3)/255\n","\n","y_train_cat = np_utils.to_categorical(y_train)\n","y_val_cat = np_utils.to_categorical(y_val)\n","y_test_cat = np_utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3ED5tc9Cfk2H","colab_type":"text"},"cell_type":"markdown","source":["## Defining coarse labels"]},{"metadata":{"id":"uIT8HRXGfk2L","colab_type":"code","colab":{}},"cell_type":"code","source":["dict_coarse2 = {0: 4,  1: 1,  2: 14,  3: 8,  4: 12,  5: 6,  6: 7,  7: 7,  8: 18,  9: 3,  10: 3,\n","                11: 14,  12: 9,  13: 18,  14: 7,  15: 11,  16: 3,  17: 9,  18: 7,  19: 11,  20: 6,\n","                21: 11,  22: 5,  23: 10,  24: 7,  25: 6,  26: 13,  27: 15,  28: 3,  29: 15,  30: 0,\n","                31: 11,  32: 1,  33: 10,  34: 12,  35: 14,  36: 16,  37: 9,  38: 11,  39: 5,  40: 5,\n","                41: 18,  42: 8,  43: 8,  44: 15,  45: 13,  46: 14,  47: 17,  48: 18,  49: 10,  50: 16,\n","                51: 4,  52: 17,  53: 4,  54: 2,  55: 12,  56: 17,  57: 4,  58: 18,  59: 17,  60: 10,\n","                61: 3,  62: 2,  63: 12,  64: 12,  65: 16,  66: 12,  67: 1,  68: 9,  69: 18,  70: 2,\n","                71: 10,  72: 12,  73: 1,  74: 16,  75: 12,  76: 9,  77: 13,  78: 15,  79: 13,  80: 16,\n","                81: 18,  82: 2,  83: 4,  84: 6,  85: 18,  86: 5,  87: 5,  88: 8,  89: 18,  90: 18,\n","                91: 1,  92: 2,  93: 15,  94: 6,  95: 0,  96: 17,  97: 8,  98: 14,  99: 13}\n","\n","\n","dict_coarse1 = {0: 0,\n","              1: 0,\n","              2: 1,\n","              3: 2,\n","              4: 1,\n","              5: 2,\n","              6: 2,\n","              7: 3,\n","              8: 4,\n","              9: 5,\n","              10: 5,\n","              11: 4,\n","              12: 4,\n","              13: 3,\n","              14: 6,\n","              15: 7,\n","              16: 4,\n","              17: 1,\n","              18: 8}\n","\n","y_train_coarse2 = np.vectorize(dict_coarse2.get)(y_train)\n","y_val_coarse2 = np.vectorize(dict_coarse2.get)(y_val)\n","y_test_coarse2 = np.vectorize(dict_coarse2.get)(y_test)\n","\n","y_train_coarse1 = np.vectorize(dict_coarse1.get)(y_train_coarse2)\n","y_val_coarse1 = np.vectorize(dict_coarse1.get)(y_val_coarse2)\n","y_test_coarse1 = np.vectorize(dict_coarse1.get)(y_test_coarse2)\n","\n","\n","y_train_c_cat1 = np_utils.to_categorical(y_train_coarse1)\n","y_val_c_cat1 = np_utils.to_categorical(y_val_coarse1)\n","y_test_c_cat1 = np_utils.to_categorical(y_test_coarse1)\n","\n","y_train_c_cat2 = np_utils.to_categorical(y_train_coarse2)\n","y_val_c_cat2 = np_utils.to_categorical(y_val_coarse2)\n","y_test_c_cat2 = np_utils.to_categorical(y_test_coarse2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aH6u_LmMfk2W","colab_type":"text"},"cell_type":"markdown","source":["## Training the model"]},{"metadata":{"id":"YCg3M4BJfk2a","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, Input\n","from keras import optimizers\n","from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger\n","from keras.layers.normalization import BatchNormalization\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bYV1g0qbfk2x","colab_type":"code","colab":{}},"cell_type":"code","source":["class TimingCallback(keras.callbacks.Callback):\n","  \"\"\"Callback that saves the time elapsed of each epoch to the log.\n","  \"\"\"  \n","  def on_epoch_begin(self, epoch, logs={}):\n","    self.starttime=time()\n","  def on_epoch_end(self, epoch, logs={}):\n","    logs['time_elapsed'] = (time()-self.starttime)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J8sBqu1Afk27","colab_type":"code","colab":{}},"cell_type":"code","source":["class AdaptativeLossWeightsModifier3Vars(keras.callbacks.Callback):\n","  def __init__(self, alpha, beta, gamma, decay_rate=0.5):\n","    self.alpha = alpha\n","    self.beta = beta\n","    self.gamma = gamma\n","    self.decay_rate = decay_rate\n","    self.offset_epoch = 0\n","    self.par_reduce = [0, 1]\n","  \n","  def calculate_exponential(self, ratio, decay_rate, epoch):\n","    return np.exp(-ratio*decay_rate*epoch)\n","\n","  def on_epoch_end(self, epoch, logs={}):\n","    list_vars = [K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)]\n","    if epoch < 1:\n","      pass\n","    \n","    else:\n","      loss_coarse1 = self.model.history.history['predictions_coarse1_loss'][-1]\n","      loss_coarse2 = self.model.history.history['predictions_coarse2_loss'][-1]\n","      loss_fine = self.model.history.history['predictions_fine_loss'][-1]\n","      \n","      losses_classes = [loss_coarse1, loss_coarse2, loss_fine]\n","      ratio = losses_classes[self.par_reduce[0]] / losses_classes[self.par_reduce[1]] *(epoch + 1 - self.offset_epoch) \n","      \n","      decaying = self.calculate_exponential(ratio, self.decay_rate/(max(self.par_reduce)**2), epoch)\n","      increasing = 1 - decaying\n","    \n","    \n","      if (1 - increasing) < 0.1 and (self.par_reduce[1] < len(list_vars) - 1):\n","        list_vars[self.par_reduce[0]] = 0\n","        list_vars[self.par_reduce[1]] = 1\n","        self.par_reduce = [i + 1 for i in self.par_reduce]\n","        self.offset_epoch = self.offset_epoch + epoch\n","\n","      else:\n","       list_vars[self.par_reduce[0]] = decaying\n","       list_vars[self.par_reduce[1]] = increasing\n","\n","        \n","      K.set_value(self.alpha, list_vars[0])\n","      K.set_value(self.beta, list_vars[1])\n","      K.set_value(self.gamma, list_vars[2])\n","        \n","      print('Changing loss weights to: coarse1 = {}, coarse2 = {}, fine = {}'.format(K.eval(self.alpha), K.eval(self.beta), K.eval(self.gamma)))\n","    \n","    logs['alpha'] = K.eval(self.alpha)\n","    logs['beta'] = K.eval(self.beta) \n","    logs['gamma'] = K.eval(self.gamma) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"JyX0adEjfk3N","colab_type":"code","colab":{}},"cell_type":"code","source":["img_rows, img_cols = 32, 32\n","input_shape = (img_rows, img_cols, 3)\n","\n","num_classes_coarse1 = 9\n","num_classes_coarse2 = 19\n","num_classes_fine = 100\n","\n","img_input = Input(shape=input_shape, name='input')\n","\n","\n","\n","x = Conv2D(64, (3, 3), activation='relu', name='block1_conv1', padding='same')(img_input)\n","x = BatchNormalization()(x)\n","x = Conv2D(64, (3, 3), activation='relu', name='block1_conv2', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block1_pool')(x)\n","\n","x = Conv2D(128, (3, 3), activation='relu', name='block1_conv3', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(128, (3, 3), activation='relu', name='block1_conv4', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block2_pool')(x)\n","\n","\n","#---- coarse branch 1 ----\n","coarse1 = Flatten(name='c1_flatten')(x)\n","coarse1 = Dense(256, name='c1_fc_1')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","coarse1 = Dense(256, name='c1_fc_2')(coarse1)\n","coarse1 = BatchNormalization()(coarse1)\n","coarse1 = Activation('relu')(coarse1)\n","coarse1 = Dropout(0.5)(coarse1)\n","\n","coarse_pred1 = Dense(num_classes_coarse1, activation='softmax', name='predictions_coarse1')(coarse1)\n","\n","\n","x = Conv2D(256, (3, 3), activation='relu', name='block1_conv5', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(256, (3, 3), activation='relu', name='block1_conv6', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = MaxPooling2D((2, 2), name='block3_pool')(x)\n","\n","\n","#---- coarse branch 2 ----\n","coarse2 = Flatten(name='c2_flatten')(x)\n","coarse2 = Dense(512, name='c2_fc_1')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","coarse2 = Dense(512, name='c2_fc_2')(coarse2)\n","coarse2 = BatchNormalization()(coarse2)\n","coarse2 = Activation('relu')(coarse2)\n","coarse2 = Dropout(0.5)(coarse2)\n","\n","coarse_pred2 = Dense(num_classes_coarse2, activation='softmax', name='predictions_coarse2')(coarse2)\n","\n","\n","x = Conv2D(512, (3, 3), activation='relu', name='block1_conv7', padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Conv2D(512, (3, 3), activation='relu', name='block1_conv8', padding='same')(x)\n","x = BatchNormalization()(x)\n","\n","\n","x = Flatten(name='flatten')(x)\n","x = Dense(1024, name='fc_1')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","\n","x = Dense(1024, name='fc_2')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dropout(0.5)(x)\n","\n","\n","fine_pred = Dense(num_classes_fine, activation='softmax', name='predictions_fine')(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"taLUCrQIfk3X","colab_type":"code","outputId":"f21ab5b7-43ae-4a2d-8e0a-6f2ca9c51603","executionInfo":{"status":"ok","timestamp":1544221055447,"user_tz":120,"elapsed":805,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":2038}},"cell_type":"code","source":["model = Model(inputs=img_input, outputs= [coarse_pred1, coarse_pred2, fine_pred], name='adaptative_branch_net')\n","\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input (InputLayer)              (None, 32, 32, 3)    0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 32, 32, 64)   1792        input[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 32, 32, 64)   36928       batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block1_conv3 (Conv2D)           (None, 16, 16, 128)  73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 16, 16, 128)  512         block1_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv4 (Conv2D)           (None, 16, 16, 128)  147584      batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 16, 16, 128)  512         block1_conv4[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 8, 8, 128)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","block1_conv5 (Conv2D)           (None, 8, 8, 256)    295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 8, 8, 256)    1024        block1_conv5[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv6 (Conv2D)           (None, 8, 8, 256)    590080      batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 8, 8, 256)    1024        block1_conv6[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","block1_conv7 (Conv2D)           (None, 4, 4, 512)    1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 4, 4, 512)    2048        block1_conv7[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv8 (Conv2D)           (None, 4, 4, 512)    2359808     batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 4, 4, 512)    2048        block1_conv8[0][0]               \n","__________________________________________________________________________________________________\n","c1_flatten (Flatten)            (None, 8192)         0           block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","c2_flatten (Flatten)            (None, 4096)         0           block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 8192)         0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","c1_fc_1 (Dense)                 (None, 256)          2097408     c1_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","c2_fc_1 (Dense)                 (None, 512)          2097664     c2_flatten[0][0]                 \n","__________________________________________________________________________________________________\n","fc_1 (Dense)                    (None, 1024)         8389632     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 256)          1024        c1_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 512)          2048        c2_fc_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 1024)         4096        fc_1[0][0]                       \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256)          0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 512)          0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 1024)         0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 256)          0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 512)          0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 1024)         0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","c1_fc_2 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","c2_fc_2 (Dense)                 (None, 512)          262656      dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","fc_2 (Dense)                    (None, 1024)         1049600     dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 256)          1024        c1_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 512)          2048        c2_fc_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 1024)         4096        fc_2[0][0]                       \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 256)          0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 512)          0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 1024)         0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 256)          0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 512)          0           activation_4[0][0]               \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 1024)         0           activation_6[0][0]               \n","__________________________________________________________________________________________________\n","predictions_coarse1 (Dense)     (None, 9)            2313        dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","predictions_coarse2 (Dense)     (None, 19)           9747        dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","predictions_fine (Dense)        (None, 100)          102500      dropout_6[0][0]                  \n","==================================================================================================\n","Total params: 18,784,704\n","Trainable params: 18,773,696\n","Non-trainable params: 11,008\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"kyk-6ImMfk37","colab_type":"code","colab":{}},"cell_type":"code","source":["alpha = K.variable(value=0.9, dtype=\"float32\", name=\"alpha\") \n","beta = K.variable(value=0.1, dtype=\"float32\", name=\"beta\") \n","gamma = K.variable(value=0, dtype=\"float32\", name=\"gamma\") \n","\n","sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=sgd,\n","              loss_weights=[alpha, beta, gamma],\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gnv5m8Pdfk4d","colab_type":"code","colab":{}},"cell_type":"code","source":["clr_cb = ReduceLROnPlateau(monitor='val_predictions_fine_loss', factor=0.5, patience=10, verbose=1, min_lr=3.125e-05)\n","time_cb = TimingCallback()\n","change_lw = AdaptativeLossWeightsModifier3Vars(alpha, beta, gamma, decay_rate=0.05)\n","csv_cb = CSVLogger('drive/TCC-ITAU/cifar-100/training-data/branch-net/adaptative-branch-net.csv', separator=',', append=False)\n","\n","\n","cbks = [clr_cb, time_cb, change_lw, csv_cb]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JKWSYhQ2fk5D","colab_type":"code","outputId":"dee71e8a-ccb0-4be4-bd24-fdf6fab83f14","executionInfo":{"status":"ok","timestamp":1544222994588,"user_tz":120,"elapsed":1885441,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":2842}},"cell_type":"code","source":["epochs = 50\n","start_time = time()\n","training = model.fit(train_features, [y_train_c_cat1, y_train_c_cat2, y_train_cat],\n","                     validation_data=(vali_features, [y_val_c_cat1, y_val_c_cat2, y_val_cat]),\n","                     epochs=epochs,\n","                     batch_size=256, \n","                     callbacks=cbks,\n","                     verbose=1)\n","training_time = time() - start_time"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train on 45000 samples, validate on 5000 samples\n","Epoch 1/50\n","45000/45000 [==============================] - 46s 1ms/step - loss: 2.2630 - predictions_coarse1_loss: 2.1338 - predictions_coarse2_loss: 3.4261 - predictions_fine_loss: 5.4521 - predictions_coarse1_acc: 0.3049 - predictions_coarse2_acc: 0.0778 - predictions_fine_acc: 0.0100 - val_loss: 1.8322 - val_predictions_coarse1_loss: 1.7244 - val_predictions_coarse2_loss: 2.8029 - val_predictions_fine_loss: 4.8340 - val_predictions_coarse1_acc: 0.4168 - val_predictions_coarse2_acc: 0.1498 - val_predictions_fine_acc: 0.0082\n","Epoch 2/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 1.9241 - predictions_coarse1_loss: 1.7963 - predictions_coarse2_loss: 3.0750 - predictions_fine_loss: 5.4512 - predictions_coarse1_acc: 0.4036 - predictions_coarse2_acc: 0.1312 - predictions_fine_acc: 0.0103 - val_loss: 1.6403 - val_predictions_coarse1_loss: 1.5376 - val_predictions_coarse2_loss: 2.5643 - val_predictions_fine_loss: 4.8192 - val_predictions_coarse1_acc: 0.4752 - val_predictions_coarse2_acc: 0.2352 - val_predictions_fine_acc: 0.0114\n","Changing loss weights to: coarse1 = 0.9396188855171204, coarse2 = 0.060381121933460236, fine = 0.0\n","Epoch 3/50\n","45000/45000 [==============================] - 36s 811us/step - loss: 1.7452 - predictions_coarse1_loss: 1.6695 - predictions_coarse2_loss: 2.9224 - predictions_fine_loss: 5.4451 - predictions_coarse1_acc: 0.4444 - predictions_coarse2_acc: 0.1597 - predictions_fine_acc: 0.0099 - val_loss: 1.5601 - val_predictions_coarse1_loss: 1.4995 - val_predictions_coarse2_loss: 2.5029 - val_predictions_fine_loss: 4.8191 - val_predictions_coarse1_acc: 0.5012 - val_predictions_coarse2_acc: 0.2500 - val_predictions_fine_acc: 0.0102\n","Changing loss weights to: coarse1 = 0.8392509818077087, coarse2 = 0.16074903309345245, fine = 0.0\n","Epoch 4/50\n","45000/45000 [==============================] - 36s 810us/step - loss: 1.7738 - predictions_coarse1_loss: 1.5772 - predictions_coarse2_loss: 2.8004 - predictions_fine_loss: 5.4454 - predictions_coarse1_acc: 0.4744 - predictions_coarse2_acc: 0.1875 - predictions_fine_acc: 0.0095 - val_loss: 1.5653 - val_predictions_coarse1_loss: 1.4134 - val_predictions_coarse2_loss: 2.3584 - val_predictions_fine_loss: 4.8046 - val_predictions_coarse1_acc: 0.5296 - val_predictions_coarse2_acc: 0.2884 - val_predictions_fine_acc: 0.0104\n","Changing loss weights to: coarse1 = 0.7098067402839661, coarse2 = 0.29019322991371155, fine = 0.0\n","Epoch 5/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 1.8394 - predictions_coarse1_loss: 1.5165 - predictions_coarse2_loss: 2.6291 - predictions_fine_loss: 5.4390 - predictions_coarse1_acc: 0.4940 - predictions_coarse2_acc: 0.2278 - predictions_fine_acc: 0.0100 - val_loss: 1.7895 - val_predictions_coarse1_loss: 1.5513 - val_predictions_coarse2_loss: 2.3721 - val_predictions_fine_loss: 4.8188 - val_predictions_coarse1_acc: 0.4662 - val_predictions_coarse2_acc: 0.2684 - val_predictions_fine_acc: 0.0088\n","Changing loss weights to: coarse1 = 0.5693740844726562, coarse2 = 0.43062591552734375, fine = 0.0\n","Epoch 6/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 1.9068 - predictions_coarse1_loss: 1.4763 - predictions_coarse2_loss: 2.4760 - predictions_fine_loss: 5.4365 - predictions_coarse1_acc: 0.5105 - predictions_coarse2_acc: 0.2612 - predictions_fine_acc: 0.0095 - val_loss: 1.6771 - val_predictions_coarse1_loss: 1.3337 - val_predictions_coarse2_loss: 2.1311 - val_predictions_fine_loss: 4.7907 - val_predictions_coarse1_acc: 0.5544 - val_predictions_coarse2_acc: 0.3386 - val_predictions_fine_acc: 0.0094\n","Changing loss weights to: coarse1 = 0.420954167842865, coarse2 = 0.579045832157135, fine = 0.0\n","Epoch 7/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 1.9656 - predictions_coarse1_loss: 1.4448 - predictions_coarse2_loss: 2.3443 - predictions_fine_loss: 5.4399 - predictions_coarse1_acc: 0.5184 - predictions_coarse2_acc: 0.2931 - predictions_fine_acc: 0.0095 - val_loss: 1.7440 - val_predictions_coarse1_loss: 1.3127 - val_predictions_coarse2_loss: 2.0576 - val_predictions_fine_loss: 4.8178 - val_predictions_coarse1_acc: 0.5696 - val_predictions_coarse2_acc: 0.3720 - val_predictions_fine_acc: 0.0090\n","Changing loss weights to: coarse1 = 0.28590163588523865, coarse2 = 0.7140983939170837, fine = 0.0\n","Epoch 8/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 1.9950 - predictions_coarse1_loss: 1.4270 - predictions_coarse2_loss: 2.2225 - predictions_fine_loss: 5.4486 - predictions_coarse1_acc: 0.5269 - predictions_coarse2_acc: 0.3257 - predictions_fine_acc: 0.0093 - val_loss: 2.0897 - val_predictions_coarse1_loss: 1.6102 - val_predictions_coarse2_loss: 2.2817 - val_predictions_fine_loss: 4.8315 - val_predictions_coarse1_acc: 0.4724 - val_predictions_coarse2_acc: 0.3180 - val_predictions_fine_acc: 0.0100\n","Changing loss weights to: coarse1 = 0.17805932462215424, coarse2 = 0.8219406604766846, fine = 0.0\n","Epoch 9/50\n","45000/45000 [==============================] - 36s 809us/step - loss: 1.9924 - predictions_coarse1_loss: 1.4023 - predictions_coarse2_loss: 2.1202 - predictions_fine_loss: 5.4519 - predictions_coarse1_acc: 0.5322 - predictions_coarse2_acc: 0.3514 - predictions_fine_acc: 0.0099 - val_loss: 1.7838 - val_predictions_coarse1_loss: 1.2858 - val_predictions_coarse2_loss: 1.8917 - val_predictions_fine_loss: 4.8094 - val_predictions_coarse1_acc: 0.5828 - val_predictions_coarse2_acc: 0.4184 - val_predictions_fine_acc: 0.0090\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0, fine = 0.0\n","Epoch 10/50\n","45000/45000 [==============================] - 37s 815us/step - loss: 2.0131 - predictions_coarse1_loss: 1.3969 - predictions_coarse2_loss: 2.0131 - predictions_fine_loss: 5.4479 - predictions_coarse1_acc: 0.5350 - predictions_coarse2_acc: 0.3779 - predictions_fine_acc: 0.0098 - val_loss: 1.9052 - val_predictions_coarse1_loss: 1.3336 - val_predictions_coarse2_loss: 1.9052 - val_predictions_fine_loss: 4.7894 - val_predictions_coarse1_acc: 0.5538 - val_predictions_coarse2_acc: 0.4094 - val_predictions_fine_acc: 0.0078\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.9162184000015259, fine = 0.08378159999847412\n","Epoch 11/50\n","45000/45000 [==============================] - 37s 824us/step - loss: 2.2065 - predictions_coarse1_loss: 1.4051 - predictions_coarse2_loss: 1.9326 - predictions_fine_loss: 5.2014 - predictions_coarse1_acc: 0.5337 - predictions_coarse2_acc: 0.3991 - predictions_fine_acc: 0.0164 - val_loss: 2.1016 - val_predictions_coarse1_loss: 1.3652 - val_predictions_coarse2_loss: 1.8849 - val_predictions_fine_loss: 4.4712 - val_predictions_coarse1_acc: 0.5504 - val_predictions_coarse2_acc: 0.4220 - val_predictions_fine_acc: 0.0476\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8705994486808777, fine = 0.1294005811214447\n","Epoch 12/50\n","45000/45000 [==============================] - 37s 823us/step - loss: 2.2320 - predictions_coarse1_loss: 1.3966 - predictions_coarse2_loss: 1.8552 - predictions_fine_loss: 4.7671 - predictions_coarse1_acc: 0.5359 - predictions_coarse2_acc: 0.4237 - predictions_fine_acc: 0.0378 - val_loss: 2.0291 - val_predictions_coarse1_loss: 1.2956 - val_predictions_coarse2_loss: 1.7215 - val_predictions_fine_loss: 4.0989 - val_predictions_coarse1_acc: 0.5740 - val_predictions_coarse2_acc: 0.4590 - val_predictions_fine_acc: 0.1016\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.8151692748069763, fine = 0.1848307102918625\n","Epoch 13/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 2.2749 - predictions_coarse1_loss: 1.3905 - predictions_coarse2_loss: 1.7922 - predictions_fine_loss: 4.4040 - predictions_coarse1_acc: 0.5392 - predictions_coarse2_acc: 0.4380 - predictions_fine_acc: 0.0665 - val_loss: 2.0700 - val_predictions_coarse1_loss: 1.2590 - val_predictions_coarse2_loss: 1.6703 - val_predictions_fine_loss: 3.8329 - val_predictions_coarse1_acc: 0.5866 - val_predictions_coarse2_acc: 0.4782 - val_predictions_fine_acc: 0.1434\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.7468671798706055, fine = 0.25313282012939453\n","Epoch 14/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 2.3386 - predictions_coarse1_loss: 1.3841 - predictions_coarse2_loss: 1.7357 - predictions_fine_loss: 4.1175 - predictions_coarse1_acc: 0.5406 - predictions_coarse2_acc: 0.4530 - predictions_fine_acc: 0.0959 - val_loss: 2.1325 - val_predictions_coarse1_loss: 1.2490 - val_predictions_coarse2_loss: 1.6472 - val_predictions_fine_loss: 3.5642 - val_predictions_coarse1_acc: 0.5862 - val_predictions_coarse2_acc: 0.4880 - val_predictions_fine_acc: 0.2008\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.6724850535392761, fine = 0.3275149166584015\n","Epoch 15/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 2.4020 - predictions_coarse1_loss: 1.3884 - predictions_coarse2_loss: 1.6893 - predictions_fine_loss: 3.8653 - predictions_coarse1_acc: 0.5374 - predictions_coarse2_acc: 0.4670 - predictions_fine_acc: 0.1290 - val_loss: 2.2917 - val_predictions_coarse1_loss: 1.3353 - val_predictions_coarse2_loss: 1.7177 - val_predictions_fine_loss: 3.4703 - val_predictions_coarse1_acc: 0.5600 - val_predictions_coarse2_acc: 0.4642 - val_predictions_fine_acc: 0.2020\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.5966665744781494, fine = 0.403333455324173\n","Epoch 16/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 2.4477 - predictions_coarse1_loss: 1.3865 - predictions_coarse2_loss: 1.6490 - predictions_fine_loss: 3.6293 - predictions_coarse1_acc: 0.5400 - predictions_coarse2_acc: 0.4785 - predictions_fine_acc: 0.1636 - val_loss: 2.2326 - val_predictions_coarse1_loss: 1.2394 - val_predictions_coarse2_loss: 1.5971 - val_predictions_fine_loss: 3.1727 - val_predictions_coarse1_acc: 0.5924 - val_predictions_coarse2_acc: 0.4984 - val_predictions_fine_acc: 0.2558\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.519145131111145, fine = 0.48085489869117737\n","Epoch 17/50\n","45000/45000 [==============================] - 37s 816us/step - loss: 2.4851 - predictions_coarse1_loss: 1.3886 - predictions_coarse2_loss: 1.6109 - predictions_fine_loss: 3.4290 - predictions_coarse1_acc: 0.5364 - predictions_coarse2_acc: 0.4904 - predictions_fine_acc: 0.1939 - val_loss: 2.2696 - val_predictions_coarse1_loss: 1.2464 - val_predictions_coarse2_loss: 1.5684 - val_predictions_fine_loss: 3.0267 - val_predictions_coarse1_acc: 0.5874 - val_predictions_coarse2_acc: 0.5078 - val_predictions_fine_acc: 0.2780\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.44136834144592285, fine = 0.5586316585540771\n","Epoch 18/50\n","45000/45000 [==============================] - 37s 817us/step - loss: 2.5119 - predictions_coarse1_loss: 1.3874 - predictions_coarse2_loss: 1.5886 - predictions_fine_loss: 3.2414 - predictions_coarse1_acc: 0.5381 - predictions_coarse2_acc: 0.4973 - predictions_fine_acc: 0.2220 - val_loss: 2.3068 - val_predictions_coarse1_loss: 1.2464 - val_predictions_coarse2_loss: 1.5571 - val_predictions_fine_loss: 2.8992 - val_predictions_coarse1_acc: 0.5956 - val_predictions_coarse2_acc: 0.5128 - val_predictions_fine_acc: 0.2974\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.36851876974105835, fine = 0.6314812302589417\n","Epoch 19/50\n","45000/45000 [==============================] - 37s 819us/step - loss: 2.5152 - predictions_coarse1_loss: 1.3901 - predictions_coarse2_loss: 1.5718 - predictions_fine_loss: 3.0657 - predictions_coarse1_acc: 0.5378 - predictions_coarse2_acc: 0.5029 - predictions_fine_acc: 0.2513 - val_loss: 2.3242 - val_predictions_coarse1_loss: 1.2389 - val_predictions_coarse2_loss: 1.5345 - val_predictions_fine_loss: 2.7850 - val_predictions_coarse1_acc: 0.5952 - val_predictions_coarse2_acc: 0.5204 - val_predictions_fine_acc: 0.3134\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.2972928583621979, fine = 0.7027071714401245\n","Epoch 20/50\n","45000/45000 [==============================] - 37s 819us/step - loss: 2.5185 - predictions_coarse1_loss: 1.3928 - predictions_coarse2_loss: 1.5536 - predictions_fine_loss: 2.9268 - predictions_coarse1_acc: 0.5364 - predictions_coarse2_acc: 0.5051 - predictions_fine_acc: 0.2790 - val_loss: 2.3307 - val_predictions_coarse1_loss: 1.2338 - val_predictions_coarse2_loss: 1.5311 - val_predictions_fine_loss: 2.6690 - val_predictions_coarse1_acc: 0.5962 - val_predictions_coarse2_acc: 0.5210 - val_predictions_fine_acc: 0.3252\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.23196899890899658, fine = 0.7680310010910034\n","Epoch 21/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 2.4896 - predictions_coarse1_loss: 1.3960 - predictions_coarse2_loss: 1.5325 - predictions_fine_loss: 2.7787 - predictions_coarse1_acc: 0.5348 - predictions_coarse2_acc: 0.5125 - predictions_fine_acc: 0.3029 - val_loss: 2.3458 - val_predictions_coarse1_loss: 1.2491 - val_predictions_coarse2_loss: 1.5183 - val_predictions_fine_loss: 2.5957 - val_predictions_coarse1_acc: 0.5920 - val_predictions_coarse2_acc: 0.5214 - val_predictions_fine_acc: 0.3486\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.1781306266784668, fine = 0.8218693733215332\n","Epoch 22/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 2.4528 - predictions_coarse1_loss: 1.3943 - predictions_coarse2_loss: 1.5168 - predictions_fine_loss: 2.6556 - predictions_coarse1_acc: 0.5365 - predictions_coarse2_acc: 0.5162 - predictions_fine_acc: 0.3294 - val_loss: 2.4660 - val_predictions_coarse1_loss: 1.2698 - val_predictions_coarse2_loss: 1.6066 - val_predictions_fine_loss: 2.6523 - val_predictions_coarse1_acc: 0.5892 - val_predictions_coarse2_acc: 0.4984 - val_predictions_fine_acc: 0.3436\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.1317615509033203, fine = 0.8682384490966797\n","Epoch 23/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 2.4080 - predictions_coarse1_loss: 1.3961 - predictions_coarse2_loss: 1.5166 - predictions_fine_loss: 2.5433 - predictions_coarse1_acc: 0.5363 - predictions_coarse2_acc: 0.5189 - predictions_fine_acc: 0.3529 - val_loss: 2.3767 - val_predictions_coarse1_loss: 1.2780 - val_predictions_coarse2_loss: 1.5382 - val_predictions_fine_loss: 2.5040 - val_predictions_coarse1_acc: 0.5810 - val_predictions_coarse2_acc: 0.5192 - val_predictions_fine_acc: 0.3718\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.09479831159114838, fine = 0.9052016735076904\n","Epoch 24/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 2.3423 - predictions_coarse1_loss: 1.3978 - predictions_coarse2_loss: 1.5038 - predictions_fine_loss: 2.4301 - predictions_coarse1_acc: 0.5362 - predictions_coarse2_acc: 0.5193 - predictions_fine_acc: 0.3750 - val_loss: 2.3571 - val_predictions_coarse1_loss: 1.2561 - val_predictions_coarse2_loss: 1.4964 - val_predictions_fine_loss: 2.4472 - val_predictions_coarse1_acc: 0.5874 - val_predictions_coarse2_acc: 0.5366 - val_predictions_fine_acc: 0.3674\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.06438092887401581, fine = 0.935619056224823\n","Epoch 25/50\n","45000/45000 [==============================] - 37s 811us/step - loss: 2.2637 - predictions_coarse1_loss: 1.4031 - predictions_coarse2_loss: 1.4932 - predictions_fine_loss: 2.3167 - predictions_coarse1_acc: 0.5319 - predictions_coarse2_acc: 0.5246 - predictions_fine_acc: 0.3978 - val_loss: 2.3095 - val_predictions_coarse1_loss: 1.2487 - val_predictions_coarse2_loss: 1.4963 - val_predictions_fine_loss: 2.3655 - val_predictions_coarse1_acc: 0.5936 - val_predictions_coarse2_acc: 0.5322 - val_predictions_fine_acc: 0.3916\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.04259040206670761, fine = 0.9574096202850342\n","Epoch 26/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 2.1972 - predictions_coarse1_loss: 1.3984 - predictions_coarse2_loss: 1.4955 - predictions_fine_loss: 2.2284 - predictions_coarse1_acc: 0.5324 - predictions_coarse2_acc: 0.5217 - predictions_fine_acc: 0.4133 - val_loss: 2.2663 - val_predictions_coarse1_loss: 1.2524 - val_predictions_coarse2_loss: 1.4671 - val_predictions_fine_loss: 2.3018 - val_predictions_coarse1_acc: 0.5854 - val_predictions_coarse2_acc: 0.5352 - val_predictions_fine_acc: 0.4052\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.02663341909646988, fine = 0.9733665585517883\n","Epoch 27/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 2.1201 - predictions_coarse1_loss: 1.4021 - predictions_coarse2_loss: 1.4939 - predictions_fine_loss: 2.1372 - predictions_coarse1_acc: 0.5320 - predictions_coarse2_acc: 0.5226 - predictions_fine_acc: 0.4373 - val_loss: 2.1790 - val_predictions_coarse1_loss: 1.2309 - val_predictions_coarse2_loss: 1.4351 - val_predictions_fine_loss: 2.1993 - val_predictions_coarse1_acc: 0.5966 - val_predictions_coarse2_acc: 0.5468 - val_predictions_fine_acc: 0.4288\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.01585722342133522, fine = 0.9841427803039551\n","Epoch 28/50\n","45000/45000 [==============================] - 37s 821us/step - loss: 2.0327 - predictions_coarse1_loss: 1.3993 - predictions_coarse2_loss: 1.4913 - predictions_fine_loss: 2.0415 - predictions_coarse1_acc: 0.5341 - predictions_coarse2_acc: 0.5224 - predictions_fine_acc: 0.4571 - val_loss: 2.1994 - val_predictions_coarse1_loss: 1.2390 - val_predictions_coarse2_loss: 1.4612 - val_predictions_fine_loss: 2.2113 - val_predictions_coarse1_acc: 0.5944 - val_predictions_coarse2_acc: 0.5368 - val_predictions_fine_acc: 0.4230\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.00893050990998745, fine = 0.991069495677948\n","Epoch 29/50\n","45000/45000 [==============================] - 37s 820us/step - loss: 1.9513 - predictions_coarse1_loss: 1.4037 - predictions_coarse2_loss: 1.4963 - predictions_fine_loss: 1.9554 - predictions_coarse1_acc: 0.5314 - predictions_coarse2_acc: 0.5200 - predictions_fine_acc: 0.4766 - val_loss: 2.1463 - val_predictions_coarse1_loss: 1.2466 - val_predictions_coarse2_loss: 1.4496 - val_predictions_fine_loss: 2.1526 - val_predictions_coarse1_acc: 0.5970 - val_predictions_coarse2_acc: 0.5444 - val_predictions_fine_acc: 0.4394\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.004657353740185499, fine = 0.9953426718711853\n","Epoch 30/50\n","45000/45000 [==============================] - 37s 822us/step - loss: 1.8571 - predictions_coarse1_loss: 1.4092 - predictions_coarse2_loss: 1.4915 - predictions_fine_loss: 1.8588 - predictions_coarse1_acc: 0.5302 - predictions_coarse2_acc: 0.5230 - predictions_fine_acc: 0.5005 - val_loss: 2.1125 - val_predictions_coarse1_loss: 1.2267 - val_predictions_coarse2_loss: 1.4372 - val_predictions_fine_loss: 2.1157 - val_predictions_coarse1_acc: 0.5970 - val_predictions_coarse2_acc: 0.5448 - val_predictions_fine_acc: 0.4412\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0022367965430021286, fine = 0.9977632164955139\n","Epoch 31/50\n","45000/45000 [==============================] - 37s 816us/step - loss: 1.7762 - predictions_coarse1_loss: 1.4109 - predictions_coarse2_loss: 1.4839 - predictions_fine_loss: 1.7768 - predictions_coarse1_acc: 0.5304 - predictions_coarse2_acc: 0.5251 - predictions_fine_acc: 0.5188 - val_loss: 2.1238 - val_predictions_coarse1_loss: 1.2474 - val_predictions_coarse2_loss: 1.4605 - val_predictions_fine_loss: 2.1253 - val_predictions_coarse1_acc: 0.5900 - val_predictions_coarse2_acc: 0.5350 - val_predictions_fine_acc: 0.4426\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.0009869786445051432, fine = 0.9990130066871643\n","Epoch 32/50\n","45000/45000 [==============================] - 37s 820us/step - loss: 1.6847 - predictions_coarse1_loss: 1.4091 - predictions_coarse2_loss: 1.4854 - predictions_fine_loss: 1.6849 - predictions_coarse1_acc: 0.5285 - predictions_coarse2_acc: 0.5233 - predictions_fine_acc: 0.5426 - val_loss: 2.0581 - val_predictions_coarse1_loss: 1.2365 - val_predictions_coarse2_loss: 1.4308 - val_predictions_fine_loss: 2.0587 - val_predictions_coarse1_acc: 0.5940 - val_predictions_coarse2_acc: 0.5472 - val_predictions_fine_acc: 0.4538\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.00042346687405370176, fine = 0.9995765089988708\n","Epoch 33/50\n","45000/45000 [==============================] - 37s 817us/step - loss: 1.6094 - predictions_coarse1_loss: 1.4119 - predictions_coarse2_loss: 1.4816 - predictions_fine_loss: 1.6095 - predictions_coarse1_acc: 0.5298 - predictions_coarse2_acc: 0.5245 - predictions_fine_acc: 0.5619 - val_loss: 2.0316 - val_predictions_coarse1_loss: 1.2437 - val_predictions_coarse2_loss: 1.4316 - val_predictions_fine_loss: 2.0319 - val_predictions_coarse1_acc: 0.5922 - val_predictions_coarse2_acc: 0.5528 - val_predictions_fine_acc: 0.4666\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 0.00014837965136393905, fine = 0.999851644039154\n","Epoch 34/50\n","45000/45000 [==============================] - 37s 816us/step - loss: 1.5267 - predictions_coarse1_loss: 1.4134 - predictions_coarse2_loss: 1.4790 - predictions_fine_loss: 1.5267 - predictions_coarse1_acc: 0.5273 - predictions_coarse2_acc: 0.5258 - predictions_fine_acc: 0.5805 - val_loss: 1.9986 - val_predictions_coarse1_loss: 1.2334 - val_predictions_coarse2_loss: 1.4217 - val_predictions_fine_loss: 1.9987 - val_predictions_coarse1_acc: 0.5938 - val_predictions_coarse2_acc: 0.5470 - val_predictions_fine_acc: 0.4698\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 5.1561790314735845e-05, fine = 0.9999484419822693\n","Epoch 35/50\n","45000/45000 [==============================] - 37s 820us/step - loss: 1.4452 - predictions_coarse1_loss: 1.4119 - predictions_coarse2_loss: 1.4851 - predictions_fine_loss: 1.4452 - predictions_coarse1_acc: 0.5321 - predictions_coarse2_acc: 0.5249 - predictions_fine_acc: 0.6022 - val_loss: 1.9816 - val_predictions_coarse1_loss: 1.2333 - val_predictions_coarse2_loss: 1.4209 - val_predictions_fine_loss: 1.9816 - val_predictions_coarse1_acc: 0.5962 - val_predictions_coarse2_acc: 0.5444 - val_predictions_fine_acc: 0.4692\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.4865764569549356e-05, fine = 0.9999851584434509\n","Epoch 36/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 1.3690 - predictions_coarse1_loss: 1.4173 - predictions_coarse2_loss: 1.4783 - predictions_fine_loss: 1.3690 - predictions_coarse1_acc: 0.5286 - predictions_coarse2_acc: 0.5264 - predictions_fine_acc: 0.6235 - val_loss: 1.9820 - val_predictions_coarse1_loss: 1.2426 - val_predictions_coarse2_loss: 1.4335 - val_predictions_fine_loss: 1.9820 - val_predictions_coarse1_acc: 0.5884 - val_predictions_coarse2_acc: 0.5430 - val_predictions_fine_acc: 0.4716\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.411257239349652e-06, fine = 0.9999966025352478\n","Epoch 37/50\n","45000/45000 [==============================] - 37s 823us/step - loss: 1.2884 - predictions_coarse1_loss: 1.4120 - predictions_coarse2_loss: 1.4776 - predictions_fine_loss: 1.2884 - predictions_coarse1_acc: 0.5280 - predictions_coarse2_acc: 0.5266 - predictions_fine_acc: 0.6450 - val_loss: 1.9577 - val_predictions_coarse1_loss: 1.2328 - val_predictions_coarse2_loss: 1.4098 - val_predictions_fine_loss: 1.9577 - val_predictions_coarse1_acc: 0.5936 - val_predictions_coarse2_acc: 0.5580 - val_predictions_fine_acc: 0.4776\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 7.582028729302692e-07, fine = 0.9999992251396179\n","Epoch 38/50\n","45000/45000 [==============================] - 37s 817us/step - loss: 1.2180 - predictions_coarse1_loss: 1.4148 - predictions_coarse2_loss: 1.4814 - predictions_fine_loss: 1.2180 - predictions_coarse1_acc: 0.5292 - predictions_coarse2_acc: 0.5247 - predictions_fine_acc: 0.6616 - val_loss: 1.9410 - val_predictions_coarse1_loss: 1.2382 - val_predictions_coarse2_loss: 1.4160 - val_predictions_fine_loss: 1.9410 - val_predictions_coarse1_acc: 0.5932 - val_predictions_coarse2_acc: 0.5538 - val_predictions_fine_acc: 0.4864\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.2275771155145776e-07, fine = 0.9999998807907104\n","Epoch 39/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 1.1279 - predictions_coarse1_loss: 1.4133 - predictions_coarse2_loss: 1.4761 - predictions_fine_loss: 1.1279 - predictions_coarse1_acc: 0.5270 - predictions_coarse2_acc: 0.5235 - predictions_fine_acc: 0.6888 - val_loss: 1.9244 - val_predictions_coarse1_loss: 1.2342 - val_predictions_coarse2_loss: 1.4084 - val_predictions_fine_loss: 1.9244 - val_predictions_coarse1_acc: 0.5950 - val_predictions_coarse2_acc: 0.5598 - val_predictions_fine_acc: 0.4860\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.66748126417815e-08, fine = 1.0\n","Epoch 40/50\n","45000/45000 [==============================] - 37s 816us/step - loss: 1.0528 - predictions_coarse1_loss: 1.4142 - predictions_coarse2_loss: 1.4780 - predictions_fine_loss: 1.0528 - predictions_coarse1_acc: 0.5275 - predictions_coarse2_acc: 0.5254 - predictions_fine_acc: 0.7094 - val_loss: 1.9401 - val_predictions_coarse1_loss: 1.2294 - val_predictions_coarse2_loss: 1.4136 - val_predictions_fine_loss: 1.9401 - val_predictions_coarse1_acc: 0.5954 - val_predictions_coarse2_acc: 0.5498 - val_predictions_fine_acc: 0.4864\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.35973976522763e-09, fine = 1.0\n","Epoch 41/50\n","45000/45000 [==============================] - 37s 816us/step - loss: 0.9742 - predictions_coarse1_loss: 1.4227 - predictions_coarse2_loss: 1.4792 - predictions_fine_loss: 0.9742 - predictions_coarse1_acc: 0.5258 - predictions_coarse2_acc: 0.5245 - predictions_fine_acc: 0.7321 - val_loss: 1.9368 - val_predictions_coarse1_loss: 1.2436 - val_predictions_coarse2_loss: 1.4258 - val_predictions_fine_loss: 1.9368 - val_predictions_coarse1_acc: 0.5920 - val_predictions_coarse2_acc: 0.5462 - val_predictions_fine_acc: 0.4862\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 8.722701033692104e-11, fine = 1.0\n","Epoch 42/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 0.9068 - predictions_coarse1_loss: 1.4163 - predictions_coarse2_loss: 1.4857 - predictions_fine_loss: 0.9068 - predictions_coarse1_acc: 0.5282 - predictions_coarse2_acc: 0.5216 - predictions_fine_acc: 0.7539 - val_loss: 1.9033 - val_predictions_coarse1_loss: 1.2373 - val_predictions_coarse2_loss: 1.4123 - val_predictions_fine_loss: 1.9033 - val_predictions_coarse1_acc: 0.5922 - val_predictions_coarse2_acc: 0.5580 - val_predictions_fine_acc: 0.4976\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 3.232444693856973e-12, fine = 1.0\n","Epoch 43/50\n","45000/45000 [==============================] - 37s 817us/step - loss: 0.8473 - predictions_coarse1_loss: 1.4170 - predictions_coarse2_loss: 1.4839 - predictions_fine_loss: 0.8473 - predictions_coarse1_acc: 0.5250 - predictions_coarse2_acc: 0.5228 - predictions_fine_acc: 0.7695 - val_loss: 1.9286 - val_predictions_coarse1_loss: 1.2334 - val_predictions_coarse2_loss: 1.4228 - val_predictions_fine_loss: 1.9286 - val_predictions_coarse1_acc: 0.5914 - val_predictions_coarse2_acc: 0.5460 - val_predictions_fine_acc: 0.4872\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 8.424624252335519e-14, fine = 1.0\n","Epoch 44/50\n","45000/45000 [==============================] - 37s 823us/step - loss: 0.7787 - predictions_coarse1_loss: 1.4233 - predictions_coarse2_loss: 1.4863 - predictions_fine_loss: 0.7787 - predictions_coarse1_acc: 0.5249 - predictions_coarse2_acc: 0.5232 - predictions_fine_acc: 0.7932 - val_loss: 1.8975 - val_predictions_coarse1_loss: 1.2321 - val_predictions_coarse2_loss: 1.4144 - val_predictions_fine_loss: 1.8975 - val_predictions_coarse1_acc: 0.5972 - val_predictions_coarse2_acc: 0.5518 - val_predictions_fine_acc: 0.4948\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.9176900041220244e-15, fine = 1.0\n","Epoch 45/50\n","45000/45000 [==============================] - 37s 813us/step - loss: 0.7108 - predictions_coarse1_loss: 1.4162 - predictions_coarse2_loss: 1.4775 - predictions_fine_loss: 0.7108 - predictions_coarse1_acc: 0.5261 - predictions_coarse2_acc: 0.5253 - predictions_fine_acc: 0.8117 - val_loss: 1.9225 - val_predictions_coarse1_loss: 1.2370 - val_predictions_coarse2_loss: 1.4253 - val_predictions_fine_loss: 1.9225 - val_predictions_coarse1_acc: 0.5936 - val_predictions_coarse2_acc: 0.5528 - val_predictions_fine_acc: 0.4970\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.3535585669943107e-17, fine = 1.0\n","Epoch 46/50\n","45000/45000 [==============================] - 37s 818us/step - loss: 0.6576 - predictions_coarse1_loss: 1.4180 - predictions_coarse2_loss: 1.4833 - predictions_fine_loss: 0.6576 - predictions_coarse1_acc: 0.5263 - predictions_coarse2_acc: 0.5243 - predictions_fine_acc: 0.8280 - val_loss: 1.9115 - val_predictions_coarse1_loss: 1.2370 - val_predictions_coarse2_loss: 1.4205 - val_predictions_fine_loss: 1.9115 - val_predictions_coarse1_acc: 0.5970 - val_predictions_coarse2_acc: 0.5470 - val_predictions_fine_acc: 0.5032\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 5.037857248401265e-20, fine = 1.0\n","Epoch 47/50\n","45000/45000 [==============================] - 37s 821us/step - loss: 0.5979 - predictions_coarse1_loss: 1.4105 - predictions_coarse2_loss: 1.4841 - predictions_fine_loss: 0.5979 - predictions_coarse1_acc: 0.5262 - predictions_coarse2_acc: 0.5241 - predictions_fine_acc: 0.8460 - val_loss: 1.9115 - val_predictions_coarse1_loss: 1.2359 - val_predictions_coarse2_loss: 1.4075 - val_predictions_fine_loss: 1.9115 - val_predictions_coarse1_acc: 0.5964 - val_predictions_coarse2_acc: 0.5576 - val_predictions_fine_acc: 0.4978\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 1.0824041259894198e-22, fine = 1.0\n","Epoch 48/50\n","45000/45000 [==============================] - 37s 820us/step - loss: 0.5476 - predictions_coarse1_loss: 1.4160 - predictions_coarse2_loss: 1.4872 - predictions_fine_loss: 0.5476 - predictions_coarse1_acc: 0.5261 - predictions_coarse2_acc: 0.5223 - predictions_fine_acc: 0.8612 - val_loss: 1.9538 - val_predictions_coarse1_loss: 1.2456 - val_predictions_coarse2_loss: 1.4348 - val_predictions_fine_loss: 1.9538 - val_predictions_coarse1_acc: 0.5924 - val_predictions_coarse2_acc: 0.5498 - val_predictions_fine_acc: 0.4892\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 4.6426673699088746e-26, fine = 1.0\n","Epoch 49/50\n","45000/45000 [==============================] - 37s 817us/step - loss: 0.5019 - predictions_coarse1_loss: 1.4222 - predictions_coarse2_loss: 1.4827 - predictions_fine_loss: 0.5019 - predictions_coarse1_acc: 0.5258 - predictions_coarse2_acc: 0.5239 - predictions_fine_acc: 0.8749 - val_loss: 1.9259 - val_predictions_coarse1_loss: 1.2360 - val_predictions_coarse2_loss: 1.4126 - val_predictions_fine_loss: 1.9259 - val_predictions_coarse1_acc: 0.5998 - val_predictions_coarse2_acc: 0.5502 - val_predictions_fine_acc: 0.5036\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.616445064754974e-30, fine = 1.0\n","Epoch 50/50\n","45000/45000 [==============================] - 37s 812us/step - loss: 0.4611 - predictions_coarse1_loss: 1.4159 - predictions_coarse2_loss: 1.4877 - predictions_fine_loss: 0.4611 - predictions_coarse1_acc: 0.5276 - predictions_coarse2_acc: 0.5220 - predictions_fine_acc: 0.8878 - val_loss: 1.9346 - val_predictions_coarse1_loss: 1.2341 - val_predictions_coarse2_loss: 1.4164 - val_predictions_fine_loss: 1.9346 - val_predictions_coarse1_acc: 0.5926 - val_predictions_coarse2_acc: 0.5510 - val_predictions_fine_acc: 0.5000\n","Changing loss weights to: coarse1 = 0.0, coarse2 = 9.841233194954422e-34, fine = 1.0\n"],"name":"stdout"}]},{"metadata":{"id":"nS5DnAtyfk5P","colab_type":"code","outputId":"b2bb23e2-3b45-4b6b-b61d-1d8b853ec4be","executionInfo":{"status":"ok","timestamp":1544223047115,"user_tz":120,"elapsed":6694,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"cell_type":"code","source":["model.evaluate(test_features, [y_test_c_cat1,y_test_c_cat2, y_test_cat])"],"execution_count":14,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 6s 599us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.8758676189422607,\n"," 1.2141164560317994,\n"," 1.3910779220581055,\n"," 1.8758676189422607,\n"," 0.6047,\n"," 0.5637,\n"," 0.5157]"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"9FfKMwTxfk56","colab_type":"code","outputId":"8476559e-0298-4a18-edaa-0e7a7f3701d3","executionInfo":{"status":"ok","timestamp":1544223071860,"user_tz":120,"elapsed":769,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["print('Total training time: {}'.format(training_time))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Total training time: 1884.5135569572449\n"],"name":"stdout"}]},{"metadata":{"id":"CDU9_2B6fk6E","colab_type":"code","outputId":"0c812295-ec6b-441d-e895-45e44acd1e45","executionInfo":{"status":"error","timestamp":1544223103717,"user_tz":120,"elapsed":8117,"user":{"displayName":"Matheus Inoue","photoUrl":"https://lh5.googleusercontent.com/-QAhMvjxDob8/AAAAAAAAAAI/AAAAAAAAAX0/8QKimNgmoYI/s64/photo.jpg","userId":"15307514117626512886"}},"colab":{"base_uri":"https://localhost:8080/","height":1111}},"cell_type":"code","source":["model.save('drive/TCC-ITAU/cifar-100/models/adaptative-branch-net.h5')"],"execution_count":16,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-1ac6b4d5c0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/TCC-ITAU/cifar-100/models/adaptative-branch-net.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, f, include_optimizer)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;34m'sample_weight_mode'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0;34m'loss_weights'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             }, default=get_json_type).encode('utf8')\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msymbolic_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mget_json_type\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not JSON Serializable: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Not JSON Serializable: <tf.Variable 'alpha:0' shape=() dtype=float32_ref>"]}]},{"metadata":{"id":"8pGBC_BGfk6V","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}